{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["@fatfingererr","case","introduction〉","issu","learning:","part1","part2","studi","告知和指教","在此僅針對該書中的","如果您對本專案有興趣或疑問，歡迎提","有興趣者請自行閱讀","特別紀錄筆記","目前本專案的規劃配合","目錄與說明","與","與朋友的讀書會持續進行","閱讀的書籍是〈reinforc","關於起頭的綜述與結尾的"],"2-1-多臂拉霸機的學習問題.html":["&","1","1000","2","=","action","e(r|a=a)","exploit","explor","greedi","k","q","q(a)","「利用」行為能最大化你的預期報酬，使你盡可能地提高你每個行為給予的回饋。","不確定性","你如何在這","你現在有","來表示。","個拉桿的拉霸機，每當你拉下其中一個拉桿的時候，拉霸機就會給你一串數字。","假如你不採取一個能得到更高期望報酬的動作，而採取任何一個其他動作，都屬於非貪婪（nongreedy）動作。","假如我們能知道每個拉桿的期望報酬，對於","假設你面前擺著有","假設拉桿","利用與探索","因此，我們會先假設每個拉桿會給予我們個別的【期望報酬】，用","因為你可以使用部分時間進行「探索」，並在最後的時間發現一個更高的總報酬。","因為你始終可以拉動有","因為你正在利用你學習到的知識，進而採取一個能得到最直接與你有利的結果。","在","在「利用」與「探索」之間，這兩者是有著根本性的矛盾問題，你無法充分同好這兩件事。","在動態的練習過程中，每一回合勢必都會有個動作，會對應到最高的期望報酬。","在這一章，我們將會從最基本的學習問題開始討論，最後連結到","增強學習。","多臂拉霸機","多臂拉霸機的學習問題","容易中獎，代表拉動拉桿","後續將會開始介紹許多數學方法，來幫助我們決定如何採取更合適的行為，以達到更好的學習成果。","才會發現這件事情，所以我們的期望報酬可以表達成：","探索與利用之間的平衡","換個角度來說，你也可能因為探索而做白工，因為你每次只能選擇一個動作，做錯一步都是浪費。","既然無法充分做好這兩件事，我們可以試著在這兩者之間進行一個權衡。","最高期望報酬","會為我們帶來較高的期望報酬。","期望報酬","次盡己所能，在看似隨機的問題上面做最充分的準備？","次練習之後將迎來正式的賭博機會。","次練習的機會，在","此時如果你有很多時間可以不斷嘗試的話，你就可以對於要採取貪婪或非貪婪有更多的信心。","此時就是說明你正在探索更多可能，這個行為也被稱作「探索（exploring）」。","然而「探索」行為可能會帶給你更大的總報酬，從長遠來說也可能是更值得嘗試的動作。","由於我們必須拉動拉桿","由於環境的不確定性，你無法確定是否有其他動作能在最終帶給你比貪婪動作更高的報酬。","當你透過你學習到的知識，進而採取了一個能得到更高期望報酬的動作，這個行為被稱作「利用（exploiting）」。","的那根拉桿。","臂拉霸機的問題中，我們唯一能賭的就是去找到有哪根拉桿被拉動時，中獎機率是比較高的。","臂拉霸機的問題也就迎刃而解了。","臂拉霸機的學習問題","貪婪動作","這串數字如果全部相同，則說明你中了大獎，反之就是什麼獎都沒有。","那每一次都選擇最高的期望報酬的話，就是所謂的貪婪（greedy）動作。"],"2-2-動作值方法.html":["(sampl","/","0","1","2","=",">",">inf","a_t","a_t=argmax_a(q_t(a))","action","averag","average)","epsilon","greedi","k","method","nonstationari","optim","q*(a)","q_t(a)","q_t(a_t)=max_a(q_t(a))","reward","t","tbd:","一個簡單的平均報酬計算方法，就是透過每一次採取該動作之後的總報酬，除以採取該動作的總次數。","上式中的","也可以寫作：","也就是說，我們可以假定一個很小的機率","也就是說，我們在","什麼時候應該使用","使得行為有機會隨機選擇非貪婪的其他動作。","來得適合。","函數則為每個動作","動作值方法","反之，如果採取不同動作的報酬變異數接近","同時這個方法也被稱作","呢？","圖","對應的價值函數，簡稱動作值函數。","就會比","就能知道所有動作的真實價值。","很簡單一個想法就是，如果存在一個動作","我們接著會來嘗試評估採取一個動作的價值，正如前面所提到，動作的正確評估來自於採取該動作之後獲取的平均報酬。","所以我們能選到最佳動作的機率是大於","所以這才是我們需要一個更進階且完備的數學理論去處理他，因為我們必須時時刻刻去平衡探索與利用之間的問題。","是一種動作值函數的估計。","時點前採取動作","時點前的採取動作","時點採取的動作","會符合：","樣本平均法","然而真實世界中，我們採取的每個動作其中的真實價值往往會隨時間而改變。","由於原本的貪婪動作能保證：","由於這個動作中完全沒有一絲的「探索」行為，所以我們可以為這個方法再添增一點探索行為。","的。","的平均報酬比其他動作高非常多，而只是欠缺探索的話。","的總報酬","的總次數","貪婪動作永遠都是利用我們學習到的當前所有知識。","透過探索行為，可能能幫助我們找到更大的總報酬可能。","透過這個方法揭露出來的動作值，會使得我們只能採取一種合理行為，就是採取貪婪動作。","那","，那麼只要在每個動作上採取一次行為，greedi"],"2-3-遞增式的算法實作.html":["(","(1/n)[",")","+","...","/","1","1/n","2","3","=","]","alpha","n","newestim","oldestim","q_n","q_n+1","r_1","r_2","r_n","stepsiz","中被隱藏了起來。","做表示。","其中的","則在","可以看成是我們在上一回合的估計誤差（error）。","在前面","對於某個特定動作","對於這個第","很大時，我們會需要很多的資源空間存放前","我們在此將這種遞增式的算法實作，表達成一個更廣義的通式：","我們已經做過了","所以對於","次來計算觀察到的平均報酬：","次動作。","次是否要做，我們可以透過前","次的每次報酬才能計算平均報酬。","次，接著要評估是否適合採取第","現在我們要來進一步討論，我們如何對樣本平均做更有效率的估算。","由於當","的式子中是","的更好的計算方法，應該是每次有新獲得的報酬時，就直接更新平均報酬。","目前我們對於動作值函數的估計，是採取對觀察到的獲得報酬進行樣本平均。","而其中的","與次數","舉例來說，target","觀察上面的式子，我們可以觀察到更多有意思的事情。","這樣子我們只需要每次存放當前的報酬","遞增式的算法實作","遞增式算法實作","，同時也只需要很小的計算量。","，我們在此以"],"2-4-處理非平穩問題.html":["(1","*","+","0","1","1/n","2","4","=",">","[","[alpha_n(a)]^2","]","alpha","alpha)^(n","alpha)^n","alpha_n(a)","average）：","i)","inf","n","q*","q_1","q_n","q_n+1","r_i","r_n","stepsiz","stepsize=1/n","sum(i=1)(n){","sum(n=1)(inf)","weight","}","不會受制於初始的","之間。","也因此","也就是你相信應該根據環境的變化，採取對應的動作，不會有哪個動作值得一直執行","也就是說每個動作的期望報酬都是存在。","也就是說越久以前所獲得的報酬，對於當前採取的動作能參考的價值越小。","也就是說，當","也就是說，當你用常數的","事實上多數問題面對的環境，是會不斷變化，這樣前面討論的內容就會不太適用。","代表在第","你某種程度就放棄認為你採取的每個動作都會有一個對應的期望報酬","來面對非平穩問題時","其中","到","動態","因此假如我們令","因為原本我們使用的","常數","常數，介在","很合理的可以發現，會隨時間變化的環境，更重要的是如何把握當前的可能獲得的報酬。","意思是：","是","時我們的動作值函數能正確的逼近每個動作的期望報酬。","最常用的方法之一，就是定義","最後會收斂到","會變成一個過往獲得報酬的指數加權平均（exponeti","會隨著","有時候我們可以在每一回合動態調整我們的","次採取動作","為一個常數。","當回合執行次數趨近於無限大，則採取動作","的","目前為止討論的問題，在穩定的環境中是沒有什麼問題。","總和也要無限大","總和要收斂","而整個乘起來越小。","處理非平穩問題","被定義成一個","越小於","這個式子中可以留意，alpha","這個條件主要是為了限制動作","這個條件主要是要保證","這兩個條件很像大數法則的條件，因為他就是要確保大數法則能讓","這兩個條件限制了動態","這樣子我們可以改寫增量式算法實作架構變成：","這樣就可以在每一個回合更聚焦在當前環境，與前幾次環境給予的反饋來做決定。","這樣會隨時間變化的學習問題，我們稱為非平穩（nonstationary）問題。","這邊要特別提到，如果使用常數的","那麼要如何確保他的收斂性呢？他必須符合兩個條件式：","，則前述的條件二會不符合","，為什麼有這個想法呢？","，這能保證我們收斂到動作值的真實數值。"],"2-5-樂觀初始值的設置.html":["(1","*","+","2","5","=","alpha","alpha)^(n","alpha)^n","i)","q_1","q_n","q_n+1","r_i","sum(i=1)(n){","}","。","並且在盡可能多的動作上面進行探索，使得最後就算開始不斷的做貪婪動作，也有足夠的探索。","之前，你並未採取任何動作，也就是說","也就是說樂觀初始值的設置方法，並非是一個很有用的一般性提升探索行為的技巧。","但是理解這些觀念是很重要的，許多人會在使用複雜高端的模型後忘記這些基本觀念。","又或者反過來說，你也可以對環境不做任何假設，使得給值","可以表示成：","因為你抱持一個「樂觀」態度開始，對學習有較高的期待。","在下一回合的","在前一節我們談到了動作值","實際問題中，這種偏誤（bias）不一定不好，有時候也是非常有幫助，如果你對環境能先做些有用的假設。","很大程度取決於初始動作值的估計，也就是","換句話說，剛開始的每一回合的學習得到的反饋，都會使你「失望」。","是一個需要先驗給定的。","是常數還是變數，我們都可以從上式發現一件事。","是鼓勵探索行為的。","會使得學習剛開始的過程中，前期的","樂觀初始值的設置","無論","的設定不會有太多幫助。","而在","較大的","這樣子在初期的行為選擇上，動作值函數會更加地鼓勵探索行為，這就是所謂的「樂觀初始值」設置。","通常環境都是複雜且不確定，所以在前期鼓勵探索是很重要的事情，因此通常我們會給予一個較大的","關於非平穩環境","顯得較不重要。","顯然在非平穩環境中，q_1"],"2-6-UCB-信賴區間上緣.html":["(ucb)","(upper","/","0","2","6","=",">","a_t","argmax_a(q_t(a)+c*\\sqrt(log_t","bound,","c","confid","epsilon","exploration）係數，而整項的公式則叫做信賴區間上緣。","greedi","log_t","n_t(a)","n_t(a)))","q_t(a)","ucb)","上式的操作就是所謂的","並不能用此來代表，你就很有信心這個動作是不值得被採取的（因為","信賴區間上緣","信賴區間上緣(ucb)","值做一個加權再來做動作選擇。","做一點加成，作為每次行為選擇的參考。","可能也很小）","同樣的，這邊我們可以發現這一項對於非平穩問題仍舊不會有太有幫助。","因為在非平穩問題中，每一次採取相同的動作而得到的報酬，並不能等同而論。","如果在越長的時間（log_t","我們已經知道貪婪行為是目前看起來最好的決策選擇方式，我們也知道不能一直貪婪。","所以一種更好的方法，就是對於非貪婪的其他選擇，做一點挑選或處理。","所以可能有一個動作在很長時間沒有被選取，但單純只是因為當時的環境不適合採取該動作。","所以我們很清楚可能","是一個探索度（degre","是不值得採取的，因此我們對他的原始","會很小，而","會更好一點，但是強迫一個隨機機率採取非貪婪的行為，似乎也不太有道理。","根號後面那一項，衡量的是採取動作","的動作次數越少（n_t(a)","的動作選擇方法","給予的每次報酬的不確定性。","而式子中的","舉例來說，我們可以對","說明你沒有足夠的信心可以認為動作","越大）中，採取到","越小）則帶根號那一項就會越大。","關於非平穩問題"],"2-7-選擇偏好與梯度演算法.html":["(","(stochast","+","1","2","3","39","41","7","=","a)","a_t","alpha","alpha(r_t","ascent,","avg_r_t","avg_r_t)(","avg_r_t)*pi_t(a)","distribution）表示成：","e^(h_t(a))/(sum(b=1)(k){e^(h_t(b))})","gradient","h_1(a)=0","h_t(a)","h_t(a_t)","h_t+1(a)","h_t+1(a_t)","p_r(a_t","pi_t(a)","pi_t(a_t))","q_t(a)","r_t","sga)","size","step","t","之前的總報酬平均。","但是我們如何衡量每個動作相對之間的關係呢？如何衡量我們更想選貪婪選擇呢？","使得所有動作的初始選擇偏好相同。","到","參數","否則偏好不會提升。","因此我們要引入一個觀念，也就是選擇偏好（preference）h_t(a)","在每一回合我們得到新的行為","我們有一個方法來更新我們的偏好","是","時點選擇動作","根據","為整體所有動作在時點","的大小作為動作選擇的依據，的確是一個很不錯的方法。","的機率，同時我們也可以設定","的遞增式的算法實作架構，其中","而","與新的回報","表達了我們在","這個公式中我們可以發現，除非報酬顯著高於平均總報酬","這個公式完全如同我們在","這邊的","選擇偏好把動作選擇用機率表示，透過或波茲曼分布（boltzmann","選擇偏好與梯度演算法","關於公式的由來，可以閱讀書籍中的","隨機梯度上升","頁的證明，在此不再多做贅述。"],"2-8-關聯搜索.html":["2","2，而選擇到紅色機台時不要選擇拉桿","3","8","n","tasks）的範疇。","。","也就是說我們要做的是去學習如何在特定情境中，做出符合該情境的最佳動作。","也就是說，我們都沒有考慮的動作與環境之間可能有所關聯，並且面對特定環境可能存在特定動作能獲得最大報酬。","但是如果我們假設，你可以獲得到這","你就可以學習到一個策略，在選擇到藍色機台時選擇拉桿","例如藍色機台的拉桿","假設我們面對","台的多臂拉霸機和採取的拉桿編號之間的關係。","台的多臂拉霸機，你每一次必須在不同的拉霸機前做選擇，並且選擇之後要再選擇拉桿。","因此我們就更往前一步，從平穩問題到非平穩問題，從非關聯性的處理到關聯搜索。","在一般的增強學習任務之中，我們面對的就是多元變化的情境，因此我們的真正目標是去學習一種","多台多臂拉霸機","始終給予零報酬，假如你能觀察到這些線索。","對你來說，每一回合所採取的動作，和你獲得的報酬之間的關係變得更為複雜。","然而隨著時間變化，真實世界中的環境往往會隨著你的動作而有所更新，也就是說環境中的情境可能不只一種。","目前為止我們可慮的所有動作選擇方法，都屬於非關聯性任務（nonassoci","策略（policy）","能給予最大報酬、紅色機台的拉桿","這些進階的處理，我們將會在後續幾章到結束不斷地深入進行探討。","這就是一個關聯搜索的任務，這個任務的目標首先是要找到報酬與情境之間的關聯性。","進階問題","關聯搜索","除此之外，目前考慮的動作只會對當前報酬產生影響，但如果行為會對後續回合的報酬產生影響，那問題也會更為複雜。"],"3-1-代理與環境的界限.html":["1","3","\\in","\\real","a(s_t)","a_t","make","pi_t","pi_t(a|s)","polici","r","r_t+1","s","s_t","s_t+1","t","t+1","t=0,1,2,3...","task），這個任務可以被簡化到極致，變成三個子任務：","tbd:","。","【這很重要，例如代理可以知道環境給予的獎勵的隨機程度，卻無法最大化他的獎勵。】","並且接收到新一回合的環境資訊","並在動作執行後的時間，接收動作產生的獎勵，稱做","介面的靈活性","代理可以採取什麼行為（動作）","代理可以透過自己學習到的經驗改變其策略，基本的學習目標就是在長期能獲得最大的總獎勵。","代理如何理解環境（狀態）","代理如何知道學習目標（獎勵）","代理很有可能能理解環境如何給予他獎勵，但仍舊無法最大化他的獎勵。","代理接收到一些環境資訊，用狀態（state）表示為","代理環境交互示意圖","代理與環境之間的界限，並不是以代理和環境本身的物理邊界做區隔。","代理與環境介面","代理與環境的界限","你也可以注意到，我們是用「代理」這個詞，意思就是它可以是不屬於代理個體本身的其他元件。","例如一個機器人除了他本身，也可以接收到配置在環境中的傳感器蒐集的資訊，顯然外部的傳感器不屬於機器人個體。","其中","前述的基礎定義給予我們一個增強學習框架，這個框架是非常靈活且抽象的，可以用不同的方式應用到不同的問題裡面。","動作選擇的抽象程度：代理可以根據基礎的條件動作，也可以根據定義的高級抽象狀態條件採取行為","反饋不一定要有外顯影響：當環境給予代理反饋時，代理可以是內在性的調整（例如修正選擇機率）","因為獎勵的高低變化的規則與邏輯，不能被代理任意的改變與調整，這才能定義成代理需要學習的任務。","在增強學習理論中，學習與動作決策者被稱作代理（agent）而與代理互動的其他的事物，都被稱作環境（environment）代理選擇的動作會影響環境，而環境會給予代理獎勵，代理嘗試最大化獲得的獎勵則稱為學習（learning），因此如何完整規範環境，並且定義一個學習任務，增強學習就必須先給予一個基礎框架。","在實際應用中，我們往往是透過定義狀態、動作與獎勵之後，就確定了代理與環境之間的界限，因此就確定了一個決策任務（decis","在模擬的環境中，獎勵的計算方法可以透過一些系統性的定義來做計算，但是他仍舊屬於環境範疇。","在每次離散時間","定義：策略","底下是代理環境介面的示意圖：","指的是在時點","時接收到的環境狀態","時間間隔的自由度：沒有要求離散時間時點之間的相隔","時點採取動作","最基本的界線判斷就是，代理人無法依照自己想要的規則改變的事物，就屬於其外部。","每個回合中，代理從狀態到動作的選擇過程，可以用一個機率表示，被稱為策略（policy）並寫成","為所有代理能接收到的環境資訊集合，並且在此基礎上選擇一個動作","狀態、動作與獎勵，定義了界限","狀態可以是任何有用的資訊：狀態由於是從環境得到的資訊，因此可以細粒度的去規範獲得的狀態內容","獎勵的外部性","的機率。","這個靈活性體現在幾個面向：","那我們怎麼區分代理人與環境呢？","首先我們先認識到，由於代理與環境之間是互相反饋，所以彼此互相的影響是以離散時間表達，也就是說：","，會在"],"3-2-目標與獎勵.html":["+1","1","2","3","\\real","hypothesis）：","r_t","。","代理人的內在獎勵","代理的目標就是要最大化本身的期望獎勵，進而能使其本身累積到最高的總獎勵","代理的目標是去掌握環境給予獎勵的規則，在每個學習回合中，獎勵是一個數字","但是這不代表代理人本身不能有一個內在獎勵的計算方式。","例如前面的棋盤遊戲例子中，我們可以將「對弈的主控權」當作是代理主觀理解環境後，","例如在棋盤遊戲中，獲得在對弈中的主控權是贏得遊戲的重要手段，但遊戲的最終目的是為了勝利。","假如我們定義獎勵是以對弈中的主控權表示，最大化獎勵就變成最大化自己的主控權。","區分學習目的與方法","因此我們在增強學習中，迎來了第一個假設，也就是獎勵獎設（reward","在前一節我們提到，獎勵應該是屬於代理外部的環境範疇。","在定義獎勵的時候，務必留意我們是要讓代理學習如何實現學習目標，而不是僅僅為了獲得最高獎勵。","如何定義環境給予的獎勵，在增強學習中給予很大的操作空間，這也是增強學習理論的特徵之一。","定義獎勵的靈活性","我們可以舉機器人走迷宮的例子，如果機器人要走出迷宮，我們可以定義每一步獎勵都要","或是在棋盤遊戲中，如果輸掉一盤棋獎勵記為","所以如何將你的學習目標，切割成環境反饋的獎勵和代理內在的獎勵，是處理代理與環境界限的重要問題。","根據我們在前一章探討到的問題，我們可能會犧牲短期可能獲得的獎勵，來換取長期可以累積更高的總獎勵的機會。","目標與獎勵","簡言之，代理就是要最大化他能收到的總獎勵。","而其中我們對獎勵的定義方式，應該是與我們想要實現的學習目標盡可能相關聯。","而贏棋則記為","自己定義的內在獎勵，但是環境給予的獎勵依舊是從勝負計算而得，代理依舊要最大化環境反饋得獎勵。","這可能不會導致代理去贏得勝利，而是使得他在棋盤上胡亂移動棋子，以表現出「最大的主控權」。","，這鼓勵他必須給快脫離環境。"],"3-3-回報.html":["*","+","...","0","1","3","=","\\sum_{k=0}^{inf}","g_t","gamma","gamma=0","gamma^2","gamma^k","r_t","r_t+1","r_t+2","r_t+3","r_t+k+1","rate），他決定了未來各時點的回報對於現在時點的價值。","return）","t","tasks）","且一旦學習過程抵達後就停止的，我們則稱作情境性任務（episod","像這樣有一個最終時點","其中","則會讓代理只關注下期回報，忽略未來的所有可能回報。","回報","因此這邊我們會引入一個概念，叫做折扣（discount）也就是說，對於持續性任務而言，我們是要最大化我們的折扣回報（discount","就是所謂的折扣率（discount","就是未來所有時點獲得的獎勵總和。","持續性任務","是最終的總獎勵，而","時，代理越會把未來的回報看得和下一期回報一樣重要，更重視未來的可能獎勵。","會讓上式存在一個固定的數值，而","有時候我們定義的代理環境框架中，可以不設定一個最終時點","每一輪的結果彼此都是無關，只有累積下來的策略會被保存到下一輪繼續使用。","然而這樣子總報酬可能會趨近於正負無限大，我們希望最大總獎勵就算在持續任務中，應該也要能收斂到一個數值。","用數學表示為：","當學習過程從最初到最終結束，我們稱之為情境（episodes）。","當我們在說要在每一回合最大化預期的總獎勵，那每一回合具體要最大化什麼呢？","當每一輪結束之後，我們會利用這一輪中學習到的知識，重新開始一次學習過程。","而","而當","觀察","越接近","這邊我們就要定義報酬（return），也就是未來總獎勵為：","，而是讓代理不斷累積總報酬，這種學習任務稱作持續性任務（continu"],"3-4-馬可夫性質.html":[")",",","...","1,","3","4","=","a_0,","a_t","independent）。","p(s',r|s,a)=p(s_t+1","p(s_t+1=s',","property）","r","r_1,","r_t+1","r_t+1=r","r_t,","s","s',","s,","s_0,","s_t","s_t,","t","|","並且得到獎勵","也就是說，我們不能說代理處於「下一張牌是紅心q」的狀態。","代理可以從環境去歸納、學習，但我們定義的狀態不能直接保證未來特定情況會發生。","但不能超過過去所有訊息的歷史紀錄，這就是所謂的馬可夫性質（markov","但是代理可不可以從環境中觀察出「下一張牌是紅心q」？當然可以。","例如說棋盤遊戲中，我們考慮把棋盤上當前排列組合當作狀態。","依據馬可夫性質為基礎所設計的各種增強學習演算法，也就可以在一定程度去使用","假如現在在","又或是飛彈發射後的當前座標與速度，總結了過去從發射到現在的飛彈飛行情況。","同時棋盤上當前的排列組合，沒有對未來可能發生的特定情況做出任何保證。","同時飛彈當前的座標與速度，也沒有保證未來飛彈可能落於任何地方的保證。","因此馬可夫性質只是一種逼近、近似的方法，也不是增強學習唯一的近似方法","因為代理不能從環境中的狀態，直接推論出下一張牌是什麼。","在代理—環境的增強學習框架中，代理會根據環境的狀態來選擇動作。","如果一個環境狀態是具有馬可夫性質的，意思就是說","如果我們說狀態具有馬可夫性質的話，那上式可以寫成","想當然爾，真實環境中的狀態和動作之間的關係，不可能完全只取決於前一回合的動作與狀態。","我們能根據當前的環境狀態和行動來選擇動作，並預期我們下一個狀態和獎勵為何。","所以我們必須先了解，狀態（state）不可以對未來的訊息作保證。","所以我們理想的狀態設計原則，應該是他能總結過去觀察到的環境訊息，","接下來我們並不會討論怎麼從環境中觀察和設計出合理的狀態","接下來我們會說明增強學習中的馬可夫性質如何表示","換句話說，環境都可能潛藏各種能揭露未來的訊息，但是我們不能將其設計為一種狀態","時點，我們可以選擇動作","本節會來討一種特別有意義的狀態，叫做馬可夫性質（markov","棋盤上當前的排列組合，總結了過去每一回合的彼此下棋的結果。","此外，先掌握馬可夫性質與相關演算法之後，是往非馬可夫性質的增強學習建模的基礎","為了使得近似能更精確，所以我們必須充分的提供環境中的可能的狀態訊息，","為了數學表示上的方便，在此我們先考慮環境有限的狀態和獎勵","為了達到這個目的，我們會在本節中對狀態做一些限制與規範","環境狀態","當代理在玩二十一點的時候，代理不能知道下一張牌為何。","真實環境的近似","而是會希望盡可能地關注如何建立能對應任何狀態的動作選擇策略","要避免這個問題的話，我們傾向於讓代理能察覺到當前環境訊息，然後立刻忘記他","這種性質也叫做路徑獨立（path","那麼選擇該動作的機率可以表示為：","馬可夫性質"],"3-5-馬可夫決策過程.html":["(s,a)",")","3","5","90%","=","a_t=a)","action","decis","mdp）","next","p(","p(s',r|s,a)","p(s'|s,a)=p(s_t+1=s'|s_t=s,a_t=a)","pairs）","process,","r(s,a)=e(r_t+1|s_t=s,","r(s,a,s')=e(r_t+1|s_t=s,a_t=a,s_t+1=s')=","reward）為","s","state","triples）重寫我們的預期獎勵，並且將預期獎勵的條件期望值展開為：","他幾乎是","假如狀態和能採取的動作是離散有限的，也被稱作有限馬可夫決策過程（finit","其中我們稱","前一章打過","因此我們再一次地透過「狀態－動作－下次狀態」元組（state","在給定的狀態","如果我們說增強學習任務是滿足馬可夫性質的話，這個學習任務就被叫做馬可夫決策過程（markov","採取動作","有限馬可夫過程對於增強學習理論來說十分的重要","此外，以狀態動作對來重新描述預期獎勵（expect","為狀態動作對（state","現代增強學習理論的基礎","的情況中，我們表示下個狀態和獲得的獎勵為","而狀態轉移的機率也可以表示為：","馬可夫決策過程"],"3-6-動作值函數.html":["2","3","6","=","a\\ina(s)","e_pi","e_pi(g_t|s_t=s)","equation）","function","function）","mdp","pi","pi(a|s)","pi）","polici","q_pi","q_pi(s,a)","q_pi(s,a)=e_pi(g_t|s_t=s,at=a)","s","v_pi","v_pi(s)","valu","下不同的動作","下根據策略","下獲得的獎勵平均值會收斂到","不會收斂，可能代表不同的動作個別有各自的動作值函數。","中提到的動作值方法，我們關心的是採取每個動作帶給我們的價值為何","中，我們會定義","也就是說，在遵守策略","代表代理在狀態","值函數的估計","其中","動作值函數","同樣的道理，假設在這個狀態","和動作","在","在狀態","對於狀態值函數的估計，可以看成是遵守策略","我們已經知道這個價值可以用預期獎勵來表示，現在我們要為每一個策略定義動作值函數","採取動作","是從狀態","是策略","時，遵守策略","會收斂到動作值函數","正如我們在","為","為動作值函數（action","然後調整參數來產生正確的估計，這很大程度取決於我們參數化的方式","然而如果一個固定的狀態下，v_pi(s)","的期望回報，這裡的","的機率函數","的狀態值函數（state","的過程中在狀態","的過程中無論採取什麼動作，","的預期回報可以寫作","考慮一個策略","貝爾曼方程","貝爾曼方程（bellman","這個我們稱","這時候我們就會將動作值函數與策略值函數參數化（parameterize），使其參數總數少於狀態總數","這種方法我們叫做蒙地卡羅法。","顯然在一連串的學習過程中，狀態值和動作值函數可以從經驗中進行估計","顯然當狀態非常多的時候，每個狀態得到的獎勵都十分稀疏，用平均來計算就顯得不太合適。","，這個是最簡易的情況。"]},"length":15},"tokenStore":{"root":{"0":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}},"1":{"0":{"0":{"0":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.04838709677419355}}},"docs":{}},"docs":{}},"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":3.333333333333333},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.06666666666666667},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":3.333333333333333},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.0625},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}},"/":{"docs":{},"n":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703}}}},"2":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":3.333333333333333},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":6.666666666666666},"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":3.333333333333333},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":3.333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":3.333333333333333},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":3.333333333333333},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":3.3474178403755865},"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":3.3666666666666663},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":3.333333333333333},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.02666666666666667}},"，":{"docs":{},"而":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"到":{"docs":{},"紅":{"docs":{},"色":{"docs":{},"機":{"docs":{},"台":{"docs":{},"時":{"docs":{},"不":{"docs":{},"要":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}},"3":{"9":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":3.333333333333333},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521},"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.06666666666666667},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":3.333333333333333},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":3.333333333333333},"3-3-回報.html":{"ref":"3-3-回報.html","tf":6.666666666666666},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":3.333333333333333},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":3.333333333333333},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":3.333333333333333}}},"4":{"1":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":3.333333333333333},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":3.333333333333333}}},"5":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":3.333333333333333},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":3.333333333333333}}},"6":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":3.333333333333333},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":3.333333333333333}}},"7":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":3.333333333333333}}},"8":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":3.333333333333333}}},"9":{"0":{"docs":{},"%":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}},"docs":{}},"docs":{},"@":{"docs":{},"f":{"docs":{},"a":{"docs":{},"t":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}}}}}},"c":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"d":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"〉":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}}}},"f":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}},"d":{"docs":{},"e":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{},"u":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}},")":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}},"o":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"1":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}},"2":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}},"docs":{}}},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"）":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"_":{"docs":{},"r":{"docs":{},"(":{"docs":{},"a":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}},"i":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.08}},"_":{"docs":{},"t":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043}}},"_":{"docs":{},"t":{"docs":{},")":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}},"|":{"docs":{},"s":{"docs":{},")":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}},"(":{"docs":{},"a":{"docs":{},"|":{"docs":{},"s":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}},"）":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}},"(":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}},"s":{"docs":{},"'":{"docs":{},",":{"docs":{},"r":{"docs":{},"|":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},")":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}},"=":{"docs":{},"p":{"docs":{},"(":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}},"docs":{}}}}}}}}}}}}}}},"|":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},")":{"docs":{},"=":{"docs":{},"p":{"docs":{},"(":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{},"=":{"docs":{},"s":{"docs":{},"'":{"docs":{},"|":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"a":{"docs":{},")":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{},"=":{"docs":{},"s":{"docs":{},"'":{"docs":{},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}},"docs":{}}}}}},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"y":{"docs":{},"）":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703}}}}}}}},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},",":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}},"s":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.04411764705882353},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.06666666666666667}},"t":{"docs":{},"u":{"docs":{},"d":{"docs":{},"i":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}},"e":{"docs":{},"p":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.11666666666666667}},"e":{"docs":{},"=":{"1":{"docs":{},"/":{"docs":{},"n":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}},"docs":{}}}}}}}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},")":{"docs":{},"(":{"docs":{},"n":{"docs":{},")":{"docs":{},"{":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}},"docs":{}}},"n":{"docs":{},"=":{"1":{"docs":{},")":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},")":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666}}}}}}}}},"docs":{}}}}}},"g":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}},"_":{"0":{"docs":{},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}},"docs":{},"t":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703}},"+":{"1":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}},"docs":{}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}},"'":{"docs":{},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}},"告":{"docs":{},"知":{"docs":{},"和":{"docs":{},"指":{"docs":{},"教":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}},"在":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"此":{"docs":{},"僅":{"docs":{},"針":{"docs":{},"對":{"docs":{},"該":{"docs":{},"書":{"docs":{},"中":{"docs":{},"的":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}},"「":{"docs":{},"利":{"docs":{},"用":{"docs":{},"」":{"docs":{},"與":{"docs":{},"「":{"docs":{},"探":{"docs":{},"索":{"docs":{},"」":{"docs":{},"之":{"docs":{},"間":{"docs":{},"，":{"docs":{},"這":{"docs":{},"兩":{"docs":{},"者":{"docs":{},"是":{"docs":{},"有":{"docs":{},"著":{"docs":{},"根":{"docs":{},"本":{"docs":{},"性":{"docs":{},"的":{"docs":{},"矛":{"docs":{},"盾":{"docs":{},"問":{"docs":{},"題":{"docs":{},"，":{"docs":{},"你":{"docs":{},"無":{"docs":{},"法":{"docs":{},"充":{"docs":{},"分":{"docs":{},"同":{"docs":{},"好":{"docs":{},"這":{"docs":{},"兩":{"docs":{},"件":{"docs":{},"事":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"動":{"docs":{},"態":{"docs":{},"的":{"docs":{},"練":{"docs":{},"習":{"docs":{},"過":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"勢":{"docs":{},"必":{"docs":{},"都":{"docs":{},"會":{"docs":{},"有":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"會":{"docs":{},"對":{"docs":{},"應":{"docs":{},"到":{"docs":{},"最":{"docs":{},"高":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"一":{"docs":{},"章":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"將":{"docs":{},"會":{"docs":{},"從":{"docs":{},"最":{"docs":{},"基":{"docs":{},"本":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"問":{"docs":{},"題":{"docs":{},"開":{"docs":{},"始":{"docs":{},"討":{"docs":{},"論":{"docs":{},"，":{"docs":{},"最":{"docs":{},"後":{"docs":{},"連":{"docs":{},"結":{"docs":{},"到":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"面":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}},"一":{"docs":{},"節":{"docs":{},"我":{"docs":{},"們":{"docs":{},"談":{"docs":{},"到":{"docs":{},"了":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}},"提":{"docs":{},"到":{"docs":{},"，":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"應":{"docs":{},"該":{"docs":{},"是":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"代":{"docs":{},"理":{"docs":{},"外":{"docs":{},"部":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"範":{"docs":{},"疇":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"我":{"docs":{},"們":{"docs":{},"得":{"docs":{},"到":{"docs":{},"新":{"docs":{},"的":{"docs":{},"行":{"docs":{},"為":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}},"次":{"docs":{},"離":{"docs":{},"散":{"docs":{},"時":{"docs":{},"間":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}},"一":{"docs":{},"般":{"docs":{},"的":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"任":{"docs":{},"務":{"docs":{},"之":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"面":{"docs":{},"對":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"多":{"docs":{},"元":{"docs":{},"變":{"docs":{},"化":{"docs":{},"的":{"docs":{},"情":{"docs":{},"境":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"真":{"docs":{},"正":{"docs":{},"目":{"docs":{},"標":{"docs":{},"是":{"docs":{},"去":{"docs":{},"學":{"docs":{},"習":{"docs":{},"一":{"docs":{},"種":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"理":{"docs":{},"論":{"docs":{},"中":{"docs":{},"，":{"docs":{},"學":{"docs":{},"習":{"docs":{},"與":{"docs":{},"動":{"docs":{},"作":{"docs":{},"決":{"docs":{},"策":{"docs":{},"者":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"代":{"docs":{},"理":{"docs":{},"（":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"而":{"docs":{},"與":{"docs":{},"代":{"docs":{},"理":{"docs":{},"互":{"docs":{},"動":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"的":{"docs":{},"事":{"docs":{},"物":{"docs":{},"，":{"docs":{},"都":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"環":{"docs":{},"境":{"docs":{},"（":{"docs":{},"e":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"代":{"docs":{},"理":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"會":{"docs":{},"影":{"docs":{},"響":{"docs":{},"環":{"docs":{},"境":{"docs":{},"，":{"docs":{},"而":{"docs":{},"環":{"docs":{},"境":{"docs":{},"會":{"docs":{},"給":{"docs":{},"予":{"docs":{},"代":{"docs":{},"理":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"嘗":{"docs":{},"試":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"則":{"docs":{},"稱":{"docs":{},"為":{"docs":{},"學":{"docs":{},"習":{"docs":{},"（":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"）":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"如":{"docs":{},"何":{"docs":{},"完":{"docs":{},"整":{"docs":{},"規":{"docs":{},"範":{"docs":{},"環":{"docs":{},"境":{"docs":{},"，":{"docs":{},"並":{"docs":{},"且":{"docs":{},"定":{"docs":{},"義":{"docs":{},"一":{"docs":{},"個":{"docs":{},"學":{"docs":{},"習":{"docs":{},"任":{"docs":{},"務":{"docs":{},"，":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"就":{"docs":{},"必":{"docs":{},"須":{"docs":{},"先":{"docs":{},"給":{"docs":{},"予":{"docs":{},"一":{"docs":{},"個":{"docs":{},"基":{"docs":{},"礎":{"docs":{},"框":{"docs":{},"架":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"實":{"docs":{},"際":{"docs":{},"應":{"docs":{},"用":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"往":{"docs":{},"往":{"docs":{},"是":{"docs":{},"透":{"docs":{},"過":{"docs":{},"定":{"docs":{},"義":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"、":{"docs":{},"動":{"docs":{},"作":{"docs":{},"與":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"之":{"docs":{},"後":{"docs":{},"，":{"docs":{},"就":{"docs":{},"確":{"docs":{},"定":{"docs":{},"了":{"docs":{},"代":{"docs":{},"理":{"docs":{},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"界":{"docs":{},"限":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"就":{"docs":{},"確":{"docs":{},"定":{"docs":{},"了":{"docs":{},"一":{"docs":{},"個":{"docs":{},"決":{"docs":{},"策":{"docs":{},"任":{"docs":{},"務":{"docs":{},"（":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"擬":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"，":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"計":{"docs":{},"算":{"docs":{},"方":{"docs":{},"法":{"docs":{},"可":{"docs":{},"以":{"docs":{},"透":{"docs":{},"過":{"docs":{},"一":{"docs":{},"些":{"docs":{},"系":{"docs":{},"統":{"docs":{},"性":{"docs":{},"的":{"docs":{},"定":{"docs":{},"義":{"docs":{},"來":{"docs":{},"做":{"docs":{},"計":{"docs":{},"算":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"他":{"docs":{},"仍":{"docs":{},"舊":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"環":{"docs":{},"境":{"docs":{},"範":{"docs":{},"疇":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"定":{"docs":{},"義":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"時":{"docs":{},"候":{"docs":{},"，":{"docs":{},"務":{"docs":{},"必":{"docs":{},"留":{"docs":{},"意":{"docs":{},"我":{"docs":{},"們":{"docs":{},"是":{"docs":{},"要":{"docs":{},"讓":{"docs":{},"代":{"docs":{},"理":{"docs":{},"學":{"docs":{},"習":{"docs":{},"如":{"docs":{},"何":{"docs":{},"實":{"docs":{},"現":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"標":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"僅":{"docs":{},"僅":{"docs":{},"為":{"docs":{},"了":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"最":{"docs":{},"高":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"理":{"docs":{},"—":{"docs":{},"環":{"docs":{},"境":{"docs":{},"的":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"框":{"docs":{},"架":{"docs":{},"中":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"會":{"docs":{},"根":{"docs":{},"據":{"docs":{},"環":{"docs":{},"境":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"來":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"給":{"docs":{},"定":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"狀":{"docs":{},"態":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}},"如":{"docs":{},"果":{"docs":{},"您":{"docs":{},"對":{"docs":{},"本":{"docs":{},"專":{"docs":{},"案":{"docs":{},"有":{"docs":{},"興":{"docs":{},"趣":{"docs":{},"或":{"docs":{},"疑":{"docs":{},"問":{"docs":{},"，":{"docs":{},"歡":{"docs":{},"迎":{"docs":{},"提":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}}}}}}}},"在":{"docs":{},"越":{"docs":{},"長":{"docs":{},"的":{"docs":{},"時":{"docs":{},"間":{"docs":{},"（":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}},"一":{"docs":{},"個":{"docs":{},"環":{"docs":{},"境":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"是":{"docs":{},"具":{"docs":{},"有":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"的":{"docs":{},"，":{"docs":{},"意":{"docs":{},"思":{"docs":{},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"說":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"具":{"docs":{},"有":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"的":{"docs":{},"話":{"docs":{},"，":{"docs":{},"那":{"docs":{},"上":{"docs":{},"式":{"docs":{},"可":{"docs":{},"以":{"docs":{},"寫":{"docs":{},"成":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"任":{"docs":{},"務":{"docs":{},"是":{"docs":{},"滿":{"docs":{},"足":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"的":{"docs":{},"話":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"學":{"docs":{},"習":{"docs":{},"任":{"docs":{},"務":{"docs":{},"就":{"docs":{},"被":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"決":{"docs":{},"策":{"docs":{},"過":{"docs":{},"程":{"docs":{},"（":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"k":{"docs":{},"o":{"docs":{},"v":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"何":{"docs":{},"定":{"docs":{},"義":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"在":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"中":{"docs":{},"給":{"docs":{},"予":{"docs":{},"很":{"docs":{},"大":{"docs":{},"的":{"docs":{},"操":{"docs":{},"作":{"docs":{},"空":{"docs":{},"間":{"docs":{},"，":{"docs":{},"這":{"docs":{},"也":{"docs":{},"是":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"理":{"docs":{},"論":{"docs":{},"的":{"docs":{},"特":{"docs":{},"徵":{"docs":{},"之":{"docs":{},"一":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"興":{"docs":{},"趣":{"docs":{},"者":{"docs":{},"請":{"docs":{},"自":{"docs":{},"行":{"docs":{},"閱":{"docs":{},"讀":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}},"時":{"docs":{},"候":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"動":{"docs":{},"態":{"docs":{},"調":{"docs":{},"整":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}},"定":{"docs":{},"義":{"docs":{},"的":{"docs":{},"代":{"docs":{},"理":{"docs":{},"環":{"docs":{},"境":{"docs":{},"框":{"docs":{},"架":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"不":{"docs":{},"設":{"docs":{},"定":{"docs":{},"一":{"docs":{},"個":{"docs":{},"最":{"docs":{},"終":{"docs":{},"時":{"docs":{},"點":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}},"限":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"過":{"docs":{},"程":{"docs":{},"對":{"docs":{},"於":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"理":{"docs":{},"論":{"docs":{},"來":{"docs":{},"說":{"docs":{},"十":{"docs":{},"分":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}},"特":{"docs":{},"別":{"docs":{},"紀":{"docs":{},"錄":{"docs":{},"筆":{"docs":{},"記":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}},"目":{"docs":{},"前":{"docs":{},"本":{"docs":{},"專":{"docs":{},"案":{"docs":{},"的":{"docs":{},"規":{"docs":{},"劃":{"docs":{},"配":{"docs":{},"合":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"對":{"docs":{},"於":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"，":{"docs":{},"是":{"docs":{},"採":{"docs":{},"取":{"docs":{},"對":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"到":{"docs":{},"的":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"進":{"docs":{},"行":{"docs":{},"樣":{"docs":{},"本":{"docs":{},"平":{"docs":{},"均":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"為":{"docs":{},"止":{"docs":{},"討":{"docs":{},"論":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"，":{"docs":{},"在":{"docs":{},"穩":{"docs":{},"定":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"是":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"問":{"docs":{},"題":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"慮":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"動":{"docs":{},"作":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"都":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"非":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"性":{"docs":{},"任":{"docs":{},"務":{"docs":{},"（":{"docs":{},"n":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"c":{"docs":{},"i":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"錄":{"docs":{},"與":{"docs":{},"說":{"docs":{},"明":{"docs":{"./":{"ref":"./","tf":10.052631578947368}}}}}},"標":{"docs":{},"與":{"docs":{},"獎":{"docs":{},"勵":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":3.364583333333333}}}}}}},"與":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}},"朋":{"docs":{},"友":{"docs":{},"的":{"docs":{},"讀":{"docs":{},"書":{"docs":{},"會":{"docs":{},"持":{"docs":{},"續":{"docs":{},"進":{"docs":{},"行":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}}},"次":{"docs":{},"數":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}},"新":{"docs":{},"的":{"docs":{},"回":{"docs":{},"報":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}},"閱":{"docs":{},"讀":{"docs":{},"的":{"docs":{},"書":{"docs":{},"籍":{"docs":{},"是":{"docs":{},"〈":{"docs":{},"r":{"docs":{},"e":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}}}}}}}},"關":{"docs":{},"於":{"docs":{},"起":{"docs":{},"頭":{"docs":{},"的":{"docs":{},"綜":{"docs":{},"述":{"docs":{},"與":{"docs":{},"結":{"docs":{},"尾":{"docs":{},"的":{"docs":{"./":{"ref":"./","tf":0.05263157894736842}}}}}}}}}}},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"環":{"docs":{},"境":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}},"問":{"docs":{},"題":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}},"公":{"docs":{},"式":{"docs":{},"的":{"docs":{},"由":{"docs":{},"來":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"閱":{"docs":{},"讀":{"docs":{},"書":{"docs":{},"籍":{"docs":{},"中":{"docs":{},"的":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}},"聯":{"docs":{},"搜":{"docs":{},"索":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":3.3666666666666663}}}}}},"&":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}},"=":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.02666666666666667},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.025},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.07042253521126761},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.046153846153846156},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.05405405405405406},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.05405405405405406}}}}}}},"_":{"0":{"docs":{},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}},"docs":{},"t":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.04054054054054054}},"=":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"a":{"docs":{},"(":{"docs":{},"q":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},")":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}},")":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}},"e":{"docs":{},")":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}},"）":{"docs":{},"：":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}},"g":{"docs":{},"_":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043}},")":{"docs":{},"(":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"*":{"docs":{},"p":{"docs":{},"i":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}},"l":{"docs":{},"p":{"docs":{},"h":{"docs":{},"a":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.02666666666666667},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.025},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.03773584905660377},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043}},")":{"docs":{},"^":{"docs":{},"(":{"docs":{},"n":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}},"n":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}},"_":{"docs":{},"n":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666}}}}}}},"(":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}},"r":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"a":{"docs":{},"(":{"docs":{},"q":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},"+":{"docs":{},"c":{"docs":{},"*":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"q":{"docs":{},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"s":{"docs":{},"c":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},",":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}},"(":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},")":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}},"\\":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}},"e":{"docs":{},"(":{"docs":{},"r":{"docs":{},"|":{"docs":{},"a":{"docs":{},"=":{"docs":{},"a":{"docs":{},")":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}},"x":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"i":{"docs":{},"t":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}},"r":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"係":{"docs":{},"數":{"docs":{},"，":{"docs":{},"而":{"docs":{},"整":{"docs":{},"項":{"docs":{},"的":{"docs":{},"公":{"docs":{},"式":{"docs":{},"則":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"信":{"docs":{},"賴":{"docs":{},"區":{"docs":{},"間":{"docs":{},"上":{"docs":{},"緣":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"s":{"docs":{},"i":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.06493506493506493},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"^":{"docs":{},"(":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},")":{"docs":{},"/":{"docs":{},"(":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},"b":{"docs":{},"=":{"1":{"docs":{},")":{"docs":{},"(":{"docs":{},"k":{"docs":{},")":{"docs":{},"{":{"docs":{},"e":{"docs":{},"^":{"docs":{},"(":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"b":{"docs":{},")":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"i":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"(":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"|":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"s":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.05194805194805195},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}},"_":{"docs":{},"t":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.046153846153846156}}}},"a":{"docs":{},"m":{"docs":{},"m":{"docs":{},"a":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.046153846153846156}},"=":{"0":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}},"docs":{}},"^":{"2":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}},"docs":{},"k":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}},"k":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.06451612903225806},"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}},"q":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}},"*":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666}},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"_":{"1":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.1320754716981132}}},"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.03896103896103896},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.06},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"_":{"docs":{},"t":{"docs":{},")":{"docs":{},"=":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"a":{"docs":{},"(":{"docs":{},"q":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},")":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.05333333333333334},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.03333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}},"+":{"1":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.02666666666666667},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.025},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.07547169811320754}}},"docs":{}}},"p":{"docs":{},"i":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"(":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"=":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"i":{"docs":{},"(":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"|":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},"t":{"docs":{},"=":{"docs":{},"a":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"「":{"docs":{},"利":{"docs":{},"用":{"docs":{},"」":{"docs":{},"行":{"docs":{},"為":{"docs":{},"能":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"你":{"docs":{},"的":{"docs":{},"預":{"docs":{},"期":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"使":{"docs":{},"你":{"docs":{},"盡":{"docs":{},"可":{"docs":{},"能":{"docs":{},"地":{"docs":{},"提":{"docs":{},"高":{"docs":{},"你":{"docs":{},"每":{"docs":{},"個":{"docs":{},"行":{"docs":{},"為":{"docs":{},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"回":{"docs":{},"饋":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"不":{"docs":{},"確":{"docs":{},"定":{"docs":{},"性":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}},"會":{"docs":{},"受":{"docs":{},"制":{"docs":{},"於":{"docs":{},"初":{"docs":{},"始":{"docs":{},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}},"收":{"docs":{},"斂":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"代":{"docs":{},"表":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"個":{"docs":{},"別":{"docs":{},"有":{"docs":{},"各":{"docs":{},"自":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"。":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"如":{"docs":{},"何":{"docs":{},"在":{"docs":{},"這":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}},"現":{"docs":{},"在":{"docs":{},"有":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}},"某":{"docs":{},"種":{"docs":{},"程":{"docs":{},"度":{"docs":{},"就":{"docs":{},"放":{"docs":{},"棄":{"docs":{},"認":{"docs":{},"為":{"docs":{},"你":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"都":{"docs":{},"會":{"docs":{},"有":{"docs":{},"一":{"docs":{},"個":{"docs":{},"對":{"docs":{},"應":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"一":{"docs":{},"個":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"在":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"到":{"docs":{},"藍":{"docs":{},"色":{"docs":{},"機":{"docs":{},"台":{"docs":{},"時":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"注":{"docs":{},"意":{"docs":{},"到":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"是":{"docs":{},"用":{"docs":{},"「":{"docs":{},"代":{"docs":{},"理":{"docs":{},"」":{"docs":{},"這":{"docs":{},"個":{"docs":{},"詞":{"docs":{},"，":{"docs":{},"意":{"docs":{},"思":{"docs":{},"就":{"docs":{},"是":{"docs":{},"它":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"不":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"代":{"docs":{},"理":{"docs":{},"個":{"docs":{},"體":{"docs":{},"本":{"docs":{},"身":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"元":{"docs":{},"件":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"來":{"docs":{},"表":{"docs":{},"示":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}},"得":{"docs":{},"適":{"docs":{},"合":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"面":{"docs":{},"對":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{},"時":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}},"個":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"的":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{},"，":{"docs":{},"每":{"docs":{},"當":{"docs":{},"你":{"docs":{},"拉":{"docs":{},"下":{"docs":{},"其":{"docs":{},"中":{"docs":{},"一":{"docs":{},"個":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"的":{"docs":{},"時":{"docs":{},"候":{"docs":{},"，":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{},"就":{"docs":{},"會":{"docs":{},"給":{"docs":{},"你":{"docs":{},"一":{"docs":{},"串":{"docs":{},"數":{"docs":{},"字":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"假":{"docs":{},"如":{"docs":{},"你":{"docs":{},"不":{"docs":{},"採":{"docs":{},"取":{"docs":{},"一":{"docs":{},"個":{"docs":{},"能":{"docs":{},"得":{"docs":{},"到":{"docs":{},"更":{"docs":{},"高":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"而":{"docs":{},"採":{"docs":{},"取":{"docs":{},"任":{"docs":{},"何":{"docs":{},"一":{"docs":{},"個":{"docs":{},"其":{"docs":{},"他":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"都":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"非":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"（":{"docs":{},"n":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"y":{"docs":{},"）":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"能":{"docs":{},"知":{"docs":{},"道":{"docs":{},"每":{"docs":{},"個":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"對":{"docs":{},"於":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}},"定":{"docs":{},"義":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"是":{"docs":{},"以":{"docs":{},"對":{"docs":{},"弈":{"docs":{},"中":{"docs":{},"的":{"docs":{},"主":{"docs":{},"控":{"docs":{},"權":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"就":{"docs":{},"變":{"docs":{},"成":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"主":{"docs":{},"控":{"docs":{},"權":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"現":{"docs":{},"在":{"docs":{},"在":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"能":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"是":{"docs":{},"離":{"docs":{},"散":{"docs":{},"有":{"docs":{},"限":{"docs":{},"的":{"docs":{},"，":{"docs":{},"也":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"有":{"docs":{},"限":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"決":{"docs":{},"策":{"docs":{},"過":{"docs":{},"程":{"docs":{},"（":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"設":{"docs":{},"你":{"docs":{},"面":{"docs":{},"前":{"docs":{},"擺":{"docs":{},"著":{"docs":{},"有":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}},"拉":{"docs":{},"桿":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}},"我":{"docs":{},"們":{"docs":{},"面":{"docs":{},"對":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}},"利":{"docs":{},"用":{"docs":{},"與":{"docs":{},"探":{"docs":{},"索":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"先":{"docs":{},"假":{"docs":{},"設":{"docs":{},"每":{"docs":{},"個":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"會":{"docs":{},"給":{"docs":{},"予":{"docs":{},"我":{"docs":{},"們":{"docs":{},"個":{"docs":{},"別":{"docs":{},"的":{"docs":{},"【":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"】":{"docs":{},"，":{"docs":{},"用":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"假":{"docs":{},"如":{"docs":{},"我":{"docs":{},"們":{"docs":{},"令":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"我":{"docs":{},"們":{"docs":{},"要":{"docs":{},"引":{"docs":{},"入":{"docs":{},"一":{"docs":{},"個":{"docs":{},"觀":{"docs":{},"念":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"偏":{"docs":{},"好":{"docs":{},"（":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"）":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"更":{"docs":{},"往":{"docs":{},"前":{"docs":{},"一":{"docs":{},"步":{"docs":{},"，":{"docs":{},"從":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{},"到":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{},"，":{"docs":{},"從":{"docs":{},"非":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"性":{"docs":{},"的":{"docs":{},"處":{"docs":{},"理":{"docs":{},"到":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"中":{"docs":{},"，":{"docs":{},"迎":{"docs":{},"來":{"docs":{},"了":{"docs":{},"第":{"docs":{},"一":{"docs":{},"個":{"docs":{},"假":{"docs":{},"設":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"獎":{"docs":{},"設":{"docs":{},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"再":{"docs":{},"一":{"docs":{},"次":{"docs":{},"地":{"docs":{},"透":{"docs":{},"過":{"docs":{},"「":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"－":{"docs":{},"動":{"docs":{},"作":{"docs":{},"－":{"docs":{},"下":{"docs":{},"次":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"」":{"docs":{},"元":{"docs":{},"組":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"邊":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"引":{"docs":{},"入":{"docs":{},"一":{"docs":{},"個":{"docs":{},"概":{"docs":{},"念":{"docs":{},"，":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"折":{"docs":{},"扣":{"docs":{},"（":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{},"，":{"docs":{},"對":{"docs":{},"於":{"docs":{},"持":{"docs":{},"續":{"docs":{},"性":{"docs":{},"任":{"docs":{},"務":{"docs":{},"而":{"docs":{},"言":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"是":{"docs":{},"要":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"折":{"docs":{},"扣":{"docs":{},"回":{"docs":{},"報":{"docs":{},"（":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"只":{"docs":{},"是":{"docs":{},"一":{"docs":{},"種":{"docs":{},"逼":{"docs":{},"近":{"docs":{},"、":{"docs":{},"近":{"docs":{},"似":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"也":{"docs":{},"不":{"docs":{},"是":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"唯":{"docs":{},"一":{"docs":{},"的":{"docs":{},"近":{"docs":{},"似":{"docs":{},"方":{"docs":{},"法":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"為":{"docs":{},"你":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"部":{"docs":{},"分":{"docs":{},"時":{"docs":{},"間":{"docs":{},"進":{"docs":{},"行":{"docs":{},"「":{"docs":{},"探":{"docs":{},"索":{"docs":{},"」":{"docs":{},"，":{"docs":{},"並":{"docs":{},"在":{"docs":{},"最":{"docs":{},"後":{"docs":{},"的":{"docs":{},"時":{"docs":{},"間":{"docs":{},"發":{"docs":{},"現":{"docs":{},"一":{"docs":{},"個":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"始":{"docs":{},"終":{"docs":{},"可":{"docs":{},"以":{"docs":{},"拉":{"docs":{},"動":{"docs":{},"有":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}},"正":{"docs":{},"在":{"docs":{},"利":{"docs":{},"用":{"docs":{},"你":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"的":{"docs":{},"知":{"docs":{},"識":{"docs":{},"，":{"docs":{},"進":{"docs":{},"而":{"docs":{},"採":{"docs":{},"取":{"docs":{},"一":{"docs":{},"個":{"docs":{},"能":{"docs":{},"得":{"docs":{},"到":{"docs":{},"最":{"docs":{},"直":{"docs":{},"接":{"docs":{},"與":{"docs":{},"你":{"docs":{},"有":{"docs":{},"利":{"docs":{},"的":{"docs":{},"結":{"docs":{},"果":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"抱":{"docs":{},"持":{"docs":{},"一":{"docs":{},"個":{"docs":{},"「":{"docs":{},"樂":{"docs":{},"觀":{"docs":{},"」":{"docs":{},"態":{"docs":{},"度":{"docs":{},"開":{"docs":{},"始":{"docs":{},"，":{"docs":{},"對":{"docs":{},"學":{"docs":{},"習":{"docs":{},"有":{"docs":{},"較":{"docs":{},"高":{"docs":{},"的":{"docs":{},"期":{"docs":{},"待":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}},"原":{"docs":{},"本":{"docs":{},"我":{"docs":{},"們":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}},"在":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{},"中":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"採":{"docs":{},"取":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"而":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"並":{"docs":{},"不":{"docs":{},"能":{"docs":{},"等":{"docs":{},"同":{"docs":{},"而":{"docs":{},"論":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"高":{"docs":{},"低":{"docs":{},"變":{"docs":{},"化":{"docs":{},"的":{"docs":{},"規":{"docs":{},"則":{"docs":{},"與":{"docs":{},"邏":{"docs":{},"輯":{"docs":{},"，":{"docs":{},"不":{"docs":{},"能":{"docs":{},"被":{"docs":{},"代":{"docs":{},"理":{"docs":{},"任":{"docs":{},"意":{"docs":{},"的":{"docs":{},"改":{"docs":{},"變":{"docs":{},"與":{"docs":{},"調":{"docs":{},"整":{"docs":{},"，":{"docs":{},"這":{"docs":{},"才":{"docs":{},"能":{"docs":{},"定":{"docs":{},"義":{"docs":{},"成":{"docs":{},"代":{"docs":{},"理":{"docs":{},"需":{"docs":{},"要":{"docs":{},"學":{"docs":{},"習":{"docs":{},"的":{"docs":{},"任":{"docs":{},"務":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"理":{"docs":{},"不":{"docs":{},"能":{"docs":{},"從":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"，":{"docs":{},"直":{"docs":{},"接":{"docs":{},"推":{"docs":{},"論":{"docs":{},"出":{"docs":{},"下":{"docs":{},"一":{"docs":{},"張":{"docs":{},"牌":{"docs":{},"是":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}},"多":{"docs":{},"臂":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"問":{"docs":{},"題":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":3.333333333333333}}}}}}}}}}},"台":{"docs":{},"多":{"docs":{},"臂":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}},"容":{"docs":{},"易":{"docs":{},"中":{"docs":{},"獎":{"docs":{},"，":{"docs":{},"代":{"docs":{},"表":{"docs":{},"拉":{"docs":{},"動":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}},"後":{"docs":{},"續":{"docs":{},"將":{"docs":{},"會":{"docs":{},"開":{"docs":{},"始":{"docs":{},"介":{"docs":{},"紹":{"docs":{},"許":{"docs":{},"多":{"docs":{},"數":{"docs":{},"學":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"來":{"docs":{},"幫":{"docs":{},"助":{"docs":{},"我":{"docs":{},"們":{"docs":{},"決":{"docs":{},"定":{"docs":{},"如":{"docs":{},"何":{"docs":{},"採":{"docs":{},"取":{"docs":{},"更":{"docs":{},"合":{"docs":{},"適":{"docs":{},"的":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"以":{"docs":{},"達":{"docs":{},"到":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"成":{"docs":{},"果":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"才":{"docs":{},"會":{"docs":{},"發":{"docs":{},"現":{"docs":{},"這":{"docs":{},"件":{"docs":{},"事":{"docs":{},"情":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"可":{"docs":{},"以":{"docs":{},"表":{"docs":{},"達":{"docs":{},"成":{"docs":{},"：":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}},"探":{"docs":{},"索":{"docs":{},"與":{"docs":{},"利":{"docs":{},"用":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"平":{"docs":{},"衡":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}},"換":{"docs":{},"個":{"docs":{},"角":{"docs":{},"度":{"docs":{},"來":{"docs":{},"說":{"docs":{},"，":{"docs":{},"你":{"docs":{},"也":{"docs":{},"可":{"docs":{},"能":{"docs":{},"因":{"docs":{},"為":{"docs":{},"探":{"docs":{},"索":{"docs":{},"而":{"docs":{},"做":{"docs":{},"白":{"docs":{},"工":{"docs":{},"，":{"docs":{},"因":{"docs":{},"為":{"docs":{},"你":{"docs":{},"每":{"docs":{},"次":{"docs":{},"只":{"docs":{},"能":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"一":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"做":{"docs":{},"錯":{"docs":{},"一":{"docs":{},"步":{"docs":{},"都":{"docs":{},"是":{"docs":{},"浪":{"docs":{},"費":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"句":{"docs":{},"話":{"docs":{},"說":{"docs":{},"，":{"docs":{},"剛":{"docs":{},"開":{"docs":{},"始":{"docs":{},"的":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"，":{"docs":{},"都":{"docs":{},"會":{"docs":{},"使":{"docs":{},"你":{"docs":{},"「":{"docs":{},"失":{"docs":{},"望":{"docs":{},"」":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}},"環":{"docs":{},"境":{"docs":{},"都":{"docs":{},"可":{"docs":{},"能":{"docs":{},"潛":{"docs":{},"藏":{"docs":{},"各":{"docs":{},"種":{"docs":{},"能":{"docs":{},"揭":{"docs":{},"露":{"docs":{},"未":{"docs":{},"來":{"docs":{},"的":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"我":{"docs":{},"們":{"docs":{},"不":{"docs":{},"能":{"docs":{},"將":{"docs":{},"其":{"docs":{},"設":{"docs":{},"計":{"docs":{},"為":{"docs":{},"一":{"docs":{},"種":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"既":{"docs":{},"然":{"docs":{},"無":{"docs":{},"法":{"docs":{},"充":{"docs":{},"分":{"docs":{},"做":{"docs":{},"好":{"docs":{},"這":{"docs":{},"兩":{"docs":{},"件":{"docs":{},"事":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"試":{"docs":{},"著":{"docs":{},"在":{"docs":{},"這":{"docs":{},"兩":{"docs":{},"者":{"docs":{},"之":{"docs":{},"間":{"docs":{},"進":{"docs":{},"行":{"docs":{},"一":{"docs":{},"個":{"docs":{},"權":{"docs":{},"衡":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"高":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"之":{"docs":{},"一":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"定":{"docs":{},"義":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}},"後":{"docs":{},"會":{"docs":{},"收":{"docs":{},"斂":{"docs":{},"到":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"基":{"docs":{},"本":{"docs":{},"的":{"docs":{},"界":{"docs":{},"線":{"docs":{},"判":{"docs":{},"斷":{"docs":{},"就":{"docs":{},"是":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"人":{"docs":{},"無":{"docs":{},"法":{"docs":{},"依":{"docs":{},"照":{"docs":{},"自":{"docs":{},"己":{"docs":{},"想":{"docs":{},"要":{"docs":{},"的":{"docs":{},"規":{"docs":{},"則":{"docs":{},"改":{"docs":{},"變":{"docs":{},"的":{"docs":{},"事":{"docs":{},"物":{"docs":{},"，":{"docs":{},"就":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"其":{"docs":{},"外":{"docs":{},"部":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"會":{"docs":{},"為":{"docs":{},"我":{"docs":{},"們":{"docs":{},"帶":{"docs":{},"來":{"docs":{},"較":{"docs":{},"高":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}},"符":{"docs":{},"合":{"docs":{},"：":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}},"變":{"docs":{},"成":{"docs":{},"一":{"docs":{},"個":{"docs":{},"過":{"docs":{},"往":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"的":{"docs":{},"指":{"docs":{},"數":{"docs":{},"加":{"docs":{},"權":{"docs":{},"平":{"docs":{},"均":{"docs":{},"（":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"i":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}},"隨":{"docs":{},"著":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}},"使":{"docs":{},"得":{"docs":{},"學":{"docs":{},"習":{"docs":{},"剛":{"docs":{},"開":{"docs":{},"始":{"docs":{},"的":{"docs":{},"過":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"前":{"docs":{},"期":{"docs":{},"的":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}},"很":{"docs":{},"小":{"docs":{},"，":{"docs":{},"而":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}},"更":{"docs":{},"好":{"docs":{},"一":{"docs":{},"點":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"強":{"docs":{},"迫":{"docs":{},"一":{"docs":{},"個":{"docs":{},"隨":{"docs":{},"機":{"docs":{},"機":{"docs":{},"率":{"docs":{},"採":{"docs":{},"取":{"docs":{},"非":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"的":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"似":{"docs":{},"乎":{"docs":{},"也":{"docs":{},"不":{"docs":{},"太":{"docs":{},"有":{"docs":{},"道":{"docs":{},"理":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"讓":{"docs":{},"上":{"docs":{},"式":{"docs":{},"存":{"docs":{},"在":{"docs":{},"一":{"docs":{},"個":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"數":{"docs":{},"值":{"docs":{},"，":{"docs":{},"而":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}},"收":{"docs":{},"斂":{"docs":{},"到":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}},"次":{"docs":{},"盡":{"docs":{},"己":{"docs":{},"所":{"docs":{},"能":{"docs":{},"，":{"docs":{},"在":{"docs":{},"看":{"docs":{},"似":{"docs":{},"隨":{"docs":{},"機":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"上":{"docs":{},"面":{"docs":{},"做":{"docs":{},"最":{"docs":{},"充":{"docs":{},"分":{"docs":{},"的":{"docs":{},"準":{"docs":{},"備":{"docs":{},"？":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}},"練":{"docs":{},"習":{"docs":{},"之":{"docs":{},"後":{"docs":{},"將":{"docs":{},"迎":{"docs":{},"來":{"docs":{},"正":{"docs":{},"式":{"docs":{},"的":{"docs":{},"賭":{"docs":{},"博":{"docs":{},"機":{"docs":{},"會":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}},"的":{"docs":{},"機":{"docs":{},"會":{"docs":{},"，":{"docs":{},"在":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}},"來":{"docs":{},"計":{"docs":{},"算":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"到":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"：":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}},"是":{"docs":{},"否":{"docs":{},"要":{"docs":{},"做":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"透":{"docs":{},"過":{"docs":{},"前":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}},"的":{"docs":{},"每":{"docs":{},"次":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"才":{"docs":{},"能":{"docs":{},"計":{"docs":{},"算":{"docs":{},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}},"，":{"docs":{},"接":{"docs":{},"著":{"docs":{},"要":{"docs":{},"評":{"docs":{},"估":{"docs":{},"是":{"docs":{},"否":{"docs":{},"適":{"docs":{},"合":{"docs":{},"採":{"docs":{},"取":{"docs":{},"第":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"此":{"docs":{},"時":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"時":{"docs":{},"間":{"docs":{},"可":{"docs":{},"以":{"docs":{},"不":{"docs":{},"斷":{"docs":{},"嘗":{"docs":{},"試":{"docs":{},"的":{"docs":{},"話":{"docs":{},"，":{"docs":{},"你":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"對":{"docs":{},"於":{"docs":{},"要":{"docs":{},"採":{"docs":{},"取":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"或":{"docs":{},"非":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"有":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"信":{"docs":{},"心":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{},"明":{"docs":{},"你":{"docs":{},"正":{"docs":{},"在":{"docs":{},"探":{"docs":{},"索":{"docs":{},"更":{"docs":{},"多":{"docs":{},"可":{"docs":{},"能":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"行":{"docs":{},"為":{"docs":{},"也":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"「":{"docs":{},"探":{"docs":{},"索":{"docs":{},"（":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"）":{"docs":{},"」":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"外":{"docs":{},"，":{"docs":{},"先":{"docs":{},"掌":{"docs":{},"握":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"與":{"docs":{},"相":{"docs":{},"關":{"docs":{},"演":{"docs":{},"算":{"docs":{},"法":{"docs":{},"之":{"docs":{},"後":{"docs":{},"，":{"docs":{},"是":{"docs":{},"往":{"docs":{},"非":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"的":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"建":{"docs":{},"模":{"docs":{},"的":{"docs":{},"基":{"docs":{},"礎":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"動":{"docs":{},"作":{"docs":{},"對":{"docs":{},"來":{"docs":{},"重":{"docs":{},"新":{"docs":{},"描":{"docs":{},"述":{"docs":{},"預":{"docs":{},"期":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"（":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}}}}},"然":{"docs":{},"而":{"docs":{},"「":{"docs":{},"探":{"docs":{},"索":{"docs":{},"」":{"docs":{},"行":{"docs":{},"為":{"docs":{},"可":{"docs":{},"能":{"docs":{},"會":{"docs":{},"帶":{"docs":{},"給":{"docs":{},"你":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"從":{"docs":{},"長":{"docs":{},"遠":{"docs":{},"來":{"docs":{},"說":{"docs":{},"也":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"更":{"docs":{},"值":{"docs":{},"得":{"docs":{},"嘗":{"docs":{},"試":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"真":{"docs":{},"實":{"docs":{},"世":{"docs":{},"界":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"其":{"docs":{},"中":{"docs":{},"的":{"docs":{},"真":{"docs":{},"實":{"docs":{},"價":{"docs":{},"值":{"docs":{},"往":{"docs":{},"往":{"docs":{},"會":{"docs":{},"隨":{"docs":{},"時":{"docs":{},"間":{"docs":{},"而":{"docs":{},"改":{"docs":{},"變":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"隨":{"docs":{},"著":{"docs":{},"時":{"docs":{},"間":{"docs":{},"變":{"docs":{},"化":{"docs":{},"，":{"docs":{},"真":{"docs":{},"實":{"docs":{},"世":{"docs":{},"界":{"docs":{},"中":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"往":{"docs":{},"往":{"docs":{},"會":{"docs":{},"隨":{"docs":{},"著":{"docs":{},"你":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"而":{"docs":{},"有":{"docs":{},"所":{"docs":{},"更":{"docs":{},"新":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"的":{"docs":{},"情":{"docs":{},"境":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"只":{"docs":{},"一":{"docs":{},"種":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"樣":{"docs":{},"子":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"可":{"docs":{},"能":{"docs":{},"會":{"docs":{},"趨":{"docs":{},"近":{"docs":{},"於":{"docs":{},"正":{"docs":{},"負":{"docs":{},"無":{"docs":{},"限":{"docs":{},"大":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"希":{"docs":{},"望":{"docs":{},"最":{"docs":{},"大":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"就":{"docs":{},"算":{"docs":{},"在":{"docs":{},"持":{"docs":{},"續":{"docs":{},"任":{"docs":{},"務":{"docs":{},"中":{"docs":{},"，":{"docs":{},"應":{"docs":{},"該":{"docs":{},"也":{"docs":{},"要":{"docs":{},"能":{"docs":{},"收":{"docs":{},"斂":{"docs":{},"到":{"docs":{},"一":{"docs":{},"個":{"docs":{},"數":{"docs":{},"值":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"果":{"docs":{},"一":{"docs":{},"個":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"下":{"docs":{},"，":{"docs":{},"v":{"docs":{},"_":{"docs":{},"p":{"docs":{},"i":{"docs":{},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}},"後":{"docs":{},"調":{"docs":{},"整":{"docs":{},"參":{"docs":{},"數":{"docs":{},"來":{"docs":{},"產":{"docs":{},"生":{"docs":{},"正":{"docs":{},"確":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"，":{"docs":{},"這":{"docs":{},"很":{"docs":{},"大":{"docs":{},"程":{"docs":{},"度":{"docs":{},"取":{"docs":{},"決":{"docs":{},"於":{"docs":{},"我":{"docs":{},"們":{"docs":{},"參":{"docs":{},"數":{"docs":{},"化":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"由":{"docs":{},"於":{"docs":{},"我":{"docs":{},"們":{"docs":{},"必":{"docs":{},"須":{"docs":{},"拉":{"docs":{},"動":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}},"環":{"docs":{},"境":{"docs":{},"的":{"docs":{},"不":{"docs":{},"確":{"docs":{},"定":{"docs":{},"性":{"docs":{},"，":{"docs":{},"你":{"docs":{},"無":{"docs":{},"法":{"docs":{},"確":{"docs":{},"定":{"docs":{},"是":{"docs":{},"否":{"docs":{},"有":{"docs":{},"其":{"docs":{},"他":{"docs":{},"動":{"docs":{},"作":{"docs":{},"能":{"docs":{},"在":{"docs":{},"最":{"docs":{},"終":{"docs":{},"帶":{"docs":{},"給":{"docs":{},"你":{"docs":{},"比":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"動":{"docs":{},"作":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"原":{"docs":{},"本":{"docs":{},"的":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"動":{"docs":{},"作":{"docs":{},"能":{"docs":{},"保":{"docs":{},"證":{"docs":{},"：":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}},"這":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"中":{"docs":{},"完":{"docs":{},"全":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"一":{"docs":{},"絲":{"docs":{},"的":{"docs":{},"「":{"docs":{},"探":{"docs":{},"索":{"docs":{},"」":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"為":{"docs":{},"這":{"docs":{},"個":{"docs":{},"方":{"docs":{},"法":{"docs":{},"再":{"docs":{},"添":{"docs":{},"增":{"docs":{},"一":{"docs":{},"點":{"docs":{},"探":{"docs":{},"索":{"docs":{},"行":{"docs":{},"為":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"當":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}},"當":{"docs":{},"你":{"docs":{},"透":{"docs":{},"過":{"docs":{},"你":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"的":{"docs":{},"知":{"docs":{},"識":{"docs":{},"，":{"docs":{},"進":{"docs":{},"而":{"docs":{},"採":{"docs":{},"取":{"docs":{},"了":{"docs":{},"一":{"docs":{},"個":{"docs":{},"能":{"docs":{},"得":{"docs":{},"到":{"docs":{},"更":{"docs":{},"高":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"行":{"docs":{},"為":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"「":{"docs":{},"利":{"docs":{},"用":{"docs":{},"（":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"）":{"docs":{},"」":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"回":{"docs":{},"合":{"docs":{},"執":{"docs":{},"行":{"docs":{},"次":{"docs":{},"數":{"docs":{},"趨":{"docs":{},"近":{"docs":{},"於":{"docs":{},"無":{"docs":{},"限":{"docs":{},"大":{"docs":{},"，":{"docs":{},"則":{"docs":{},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666}}}}}}}}}}}}}}}}}}}},"學":{"docs":{},"習":{"docs":{},"過":{"docs":{},"程":{"docs":{},"從":{"docs":{},"最":{"docs":{},"初":{"docs":{},"到":{"docs":{},"最":{"docs":{},"終":{"docs":{},"結":{"docs":{},"束":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"稱":{"docs":{},"之":{"docs":{},"為":{"docs":{},"情":{"docs":{},"境":{"docs":{},"（":{"docs":{},"e":{"docs":{},"p":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},"）":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{},"說":{"docs":{},"要":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"預":{"docs":{},"期":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"那":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"具":{"docs":{},"體":{"docs":{},"要":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"呢":{"docs":{},"？":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"一":{"docs":{},"輪":{"docs":{},"結":{"docs":{},"束":{"docs":{},"之":{"docs":{},"後":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"利":{"docs":{},"用":{"docs":{},"這":{"docs":{},"一":{"docs":{},"輪":{"docs":{},"中":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"的":{"docs":{},"知":{"docs":{},"識":{"docs":{},"，":{"docs":{},"重":{"docs":{},"新":{"docs":{},"開":{"docs":{},"始":{"docs":{},"一":{"docs":{},"次":{"docs":{},"學":{"docs":{},"習":{"docs":{},"過":{"docs":{},"程":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"理":{"docs":{},"在":{"docs":{},"玩":{"docs":{},"二":{"docs":{},"十":{"docs":{},"一":{"docs":{},"點":{"docs":{},"的":{"docs":{},"時":{"docs":{},"候":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"不":{"docs":{},"能":{"docs":{},"知":{"docs":{},"道":{"docs":{},"下":{"docs":{},"一":{"docs":{},"張":{"docs":{},"牌":{"docs":{},"為":{"docs":{},"何":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.03333333333333333}},"那":{"docs":{},"根":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"比":{"docs":{},"其":{"docs":{},"他":{"docs":{},"動":{"docs":{},"作":{"docs":{},"高":{"docs":{},"非":{"docs":{},"常":{"docs":{},"多":{"docs":{},"，":{"docs":{},"而":{"docs":{},"只":{"docs":{},"是":{"docs":{},"欠":{"docs":{},"缺":{"docs":{},"探":{"docs":{},"索":{"docs":{},"的":{"docs":{},"話":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}},"次":{"docs":{},"數":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}},"式":{"docs":{},"子":{"docs":{},"中":{"docs":{},"是":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"計":{"docs":{},"算":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"應":{"docs":{},"該":{"docs":{},"是":{"docs":{},"每":{"docs":{},"次":{"docs":{},"有":{"docs":{},"新":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"時":{"docs":{},"，":{"docs":{},"就":{"docs":{},"直":{"docs":{},"接":{"docs":{},"更":{"docs":{},"新":{"docs":{},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"設":{"docs":{},"定":{"docs":{},"不":{"docs":{},"會":{"docs":{},"有":{"docs":{},"太":{"docs":{},"多":{"docs":{},"幫":{"docs":{},"助":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}},"動":{"docs":{},"作":{"docs":{},"次":{"docs":{},"數":{"docs":{},"越":{"docs":{},"少":{"docs":{},"（":{"docs":{},"n":{"docs":{},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}},"選":{"docs":{},"擇":{"docs":{},"方":{"docs":{},"法":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"大":{"docs":{},"小":{"docs":{},"作":{"docs":{},"為":{"docs":{},"動":{"docs":{},"作":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"的":{"docs":{},"依":{"docs":{},"據":{"docs":{},"，":{"docs":{},"的":{"docs":{},"確":{"docs":{},"是":{"docs":{},"一":{"docs":{},"個":{"docs":{},"很":{"docs":{},"不":{"docs":{},"錯":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}},"機":{"docs":{},"率":{"docs":{},"，":{"docs":{},"同":{"docs":{},"時":{"docs":{},"我":{"docs":{},"們":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"設":{"docs":{},"定":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}},"函":{"docs":{},"數":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}},"遞":{"docs":{},"增":{"docs":{},"式":{"docs":{},"的":{"docs":{},"算":{"docs":{},"法":{"docs":{},"實":{"docs":{},"作":{"docs":{},"架":{"docs":{},"構":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}},"情":{"docs":{},"況":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"表":{"docs":{},"示":{"docs":{},"下":{"docs":{},"個":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"為":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}},"期":{"docs":{},"望":{"docs":{},"回":{"docs":{},"報":{"docs":{},"，":{"docs":{},"這":{"docs":{},"裡":{"docs":{},"的":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}},"狀":{"docs":{},"態":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}},"過":{"docs":{},"程":{"docs":{},"中":{"docs":{},"在":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}},"無":{"docs":{},"論":{"docs":{},"採":{"docs":{},"取":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}},"預":{"docs":{},"期":{"docs":{},"回":{"docs":{},"報":{"docs":{},"可":{"docs":{},"以":{"docs":{},"寫":{"docs":{},"作":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}},"臂":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"唯":{"docs":{},"一":{"docs":{},"能":{"docs":{},"賭":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"去":{"docs":{},"找":{"docs":{},"到":{"docs":{},"有":{"docs":{},"哪":{"docs":{},"根":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"被":{"docs":{},"拉":{"docs":{},"動":{"docs":{},"時":{"docs":{},"，":{"docs":{},"中":{"docs":{},"獎":{"docs":{},"機":{"docs":{},"率":{"docs":{},"是":{"docs":{},"比":{"docs":{},"較":{"docs":{},"高":{"docs":{},"的":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"也":{"docs":{},"就":{"docs":{},"迎":{"docs":{},"刃":{"docs":{},"而":{"docs":{},"解":{"docs":{},"了":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}},"學":{"docs":{},"習":{"docs":{},"問":{"docs":{},"題":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}},"貪":{"docs":{},"婪":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}},"永":{"docs":{},"遠":{"docs":{},"都":{"docs":{},"是":{"docs":{},"利":{"docs":{},"用":{"docs":{},"我":{"docs":{},"們":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"的":{"docs":{},"當":{"docs":{},"前":{"docs":{},"所":{"docs":{},"有":{"docs":{},"知":{"docs":{},"識":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"串":{"docs":{},"數":{"docs":{},"字":{"docs":{},"如":{"docs":{},"果":{"docs":{},"全":{"docs":{},"部":{"docs":{},"相":{"docs":{},"同":{"docs":{},"，":{"docs":{},"則":{"docs":{},"說":{"docs":{},"明":{"docs":{},"你":{"docs":{},"中":{"docs":{},"了":{"docs":{},"大":{"docs":{},"獎":{"docs":{},"，":{"docs":{},"反":{"docs":{},"之":{"docs":{},"就":{"docs":{},"是":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"獎":{"docs":{},"都":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"樣":{"docs":{},"子":{"docs":{},"我":{"docs":{},"們":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"每":{"docs":{},"次":{"docs":{},"存":{"docs":{},"放":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"改":{"docs":{},"寫":{"docs":{},"增":{"docs":{},"量":{"docs":{},"式":{"docs":{},"算":{"docs":{},"法":{"docs":{},"實":{"docs":{},"作":{"docs":{},"架":{"docs":{},"構":{"docs":{},"變":{"docs":{},"成":{"docs":{},"：":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"初":{"docs":{},"期":{"docs":{},"的":{"docs":{},"行":{"docs":{},"為":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"上":{"docs":{},"，":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"會":{"docs":{},"更":{"docs":{},"加":{"docs":{},"地":{"docs":{},"鼓":{"docs":{},"勵":{"docs":{},"探":{"docs":{},"索":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"這":{"docs":{},"就":{"docs":{},"是":{"docs":{},"所":{"docs":{},"謂":{"docs":{},"的":{"docs":{},"「":{"docs":{},"樂":{"docs":{},"觀":{"docs":{},"初":{"docs":{},"始":{"docs":{},"值":{"docs":{},"」":{"docs":{},"設":{"docs":{},"置":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"個":{"docs":{},"回":{"docs":{},"合":{"docs":{},"更":{"docs":{},"聚":{"docs":{},"焦":{"docs":{},"在":{"docs":{},"當":{"docs":{},"前":{"docs":{},"環":{"docs":{},"境":{"docs":{},"，":{"docs":{},"與":{"docs":{},"前":{"docs":{},"幾":{"docs":{},"次":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"來":{"docs":{},"做":{"docs":{},"決":{"docs":{},"定":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"會":{"docs":{},"隨":{"docs":{},"時":{"docs":{},"間":{"docs":{},"變":{"docs":{},"化":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"問":{"docs":{},"題":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"稱":{"docs":{},"為":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"（":{"docs":{},"n":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"）":{"docs":{},"問":{"docs":{},"題":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"個":{"docs":{},"式":{"docs":{},"子":{"docs":{},"中":{"docs":{},"可":{"docs":{},"以":{"docs":{},"留":{"docs":{},"意":{"docs":{},"，":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"h":{"docs":{},"a":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}},"條":{"docs":{},"件":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"為":{"docs":{},"了":{"docs":{},"限":{"docs":{},"制":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}},"要":{"docs":{},"保":{"docs":{},"證":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}},"公":{"docs":{},"式":{"docs":{},"中":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"發":{"docs":{},"現":{"docs":{},"，":{"docs":{},"除":{"docs":{},"非":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"顯":{"docs":{},"著":{"docs":{},"高":{"docs":{},"於":{"docs":{},"平":{"docs":{},"均":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}},"完":{"docs":{},"全":{"docs":{},"如":{"docs":{},"同":{"docs":{},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}},"靈":{"docs":{},"活":{"docs":{},"性":{"docs":{},"體":{"docs":{},"現":{"docs":{},"在":{"docs":{},"幾":{"docs":{},"個":{"docs":{},"面":{"docs":{},"向":{"docs":{},"：":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"稱":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}},"兩":{"docs":{},"個":{"docs":{},"條":{"docs":{},"件":{"docs":{},"很":{"docs":{},"像":{"docs":{},"大":{"docs":{},"數":{"docs":{},"法":{"docs":{},"則":{"docs":{},"的":{"docs":{},"條":{"docs":{},"件":{"docs":{},"，":{"docs":{},"因":{"docs":{},"為":{"docs":{},"他":{"docs":{},"就":{"docs":{},"是":{"docs":{},"要":{"docs":{},"確":{"docs":{},"保":{"docs":{},"大":{"docs":{},"數":{"docs":{},"法":{"docs":{},"則":{"docs":{},"能":{"docs":{},"讓":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}},"限":{"docs":{},"制":{"docs":{},"了":{"docs":{},"動":{"docs":{},"態":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}},"邊":{"docs":{},"要":{"docs":{},"特":{"docs":{},"別":{"docs":{},"提":{"docs":{},"到":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"使":{"docs":{},"用":{"docs":{},"常":{"docs":{},"數":{"docs":{},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}},"的":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"我":{"docs":{},"們":{"docs":{},"就":{"docs":{},"要":{"docs":{},"定":{"docs":{},"義":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{},"）":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"未":{"docs":{},"來":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"為":{"docs":{},"：":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"些":{"docs":{},"進":{"docs":{},"階":{"docs":{},"的":{"docs":{},"處":{"docs":{},"理":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"將":{"docs":{},"會":{"docs":{},"在":{"docs":{},"後":{"docs":{},"續":{"docs":{},"幾":{"docs":{},"章":{"docs":{},"到":{"docs":{},"結":{"docs":{},"束":{"docs":{},"不":{"docs":{},"斷":{"docs":{},"地":{"docs":{},"深":{"docs":{},"入":{"docs":{},"進":{"docs":{},"行":{"docs":{},"探":{"docs":{},"討":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"一":{"docs":{},"個":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"的":{"docs":{},"任":{"docs":{},"務":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"任":{"docs":{},"務":{"docs":{},"的":{"docs":{},"目":{"docs":{},"標":{"docs":{},"首":{"docs":{},"先":{"docs":{},"是":{"docs":{},"要":{"docs":{},"找":{"docs":{},"到":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"與":{"docs":{},"情":{"docs":{},"境":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"性":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"會":{"docs":{},"導":{"docs":{},"致":{"docs":{},"代":{"docs":{},"理":{"docs":{},"去":{"docs":{},"贏":{"docs":{},"得":{"docs":{},"勝":{"docs":{},"利":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"使":{"docs":{},"得":{"docs":{},"他":{"docs":{},"在":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"上":{"docs":{},"胡":{"docs":{},"亂":{"docs":{},"移":{"docs":{},"動":{"docs":{},"棋":{"docs":{},"子":{"docs":{},"，":{"docs":{},"以":{"docs":{},"表":{"docs":{},"現":{"docs":{},"出":{"docs":{},"「":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{},"主":{"docs":{},"控":{"docs":{},"權":{"docs":{},"」":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"種":{"docs":{},"性":{"docs":{},"質":{"docs":{},"也":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"路":{"docs":{},"徑":{"docs":{},"獨":{"docs":{},"立":{"docs":{},"（":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}},"方":{"docs":{},"法":{"docs":{},"我":{"docs":{},"們":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"蒙":{"docs":{},"地":{"docs":{},"卡":{"docs":{},"羅":{"docs":{},"法":{"docs":{},"。":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"時":{"docs":{},"候":{"docs":{},"我":{"docs":{},"們":{"docs":{},"就":{"docs":{},"會":{"docs":{},"將":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"與":{"docs":{},"策":{"docs":{},"略":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"參":{"docs":{},"數":{"docs":{},"化":{"docs":{},"（":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"）":{"docs":{},"，":{"docs":{},"使":{"docs":{},"其":{"docs":{},"參":{"docs":{},"數":{"docs":{},"總":{"docs":{},"數":{"docs":{},"少":{"docs":{},"於":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"總":{"docs":{},"數":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"那":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"都":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"最":{"docs":{},"高":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"的":{"docs":{},"話":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"所":{"docs":{},"謂":{"docs":{},"的":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"（":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"y":{"docs":{},"）":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-1-多臂拉霸機的學習問題.html":{"ref":"2-1-多臂拉霸機的學習問題.html","tf":0.016129032258064516}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"麼":{"docs":{},"要":{"docs":{},"如":{"docs":{},"何":{"docs":{},"確":{"docs":{},"保":{"docs":{},"他":{"docs":{},"的":{"docs":{},"收":{"docs":{},"斂":{"docs":{},"性":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"他":{"docs":{},"必":{"docs":{},"須":{"docs":{},"符":{"docs":{},"合":{"docs":{},"兩":{"docs":{},"個":{"docs":{},"條":{"docs":{},"件":{"docs":{},"式":{"docs":{},"：":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}},"選":{"docs":{},"擇":{"docs":{},"該":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"機":{"docs":{},"率":{"docs":{},"可":{"docs":{},"以":{"docs":{},"表":{"docs":{},"示":{"docs":{},"為":{"docs":{},"：":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"怎":{"docs":{},"麼":{"docs":{},"區":{"docs":{},"分":{"docs":{},"代":{"docs":{},"理":{"docs":{},"人":{"docs":{},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"呢":{"docs":{},"？":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}},"(":{"1":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.025},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.03773584905660377}},"/":{"docs":{},"n":{"docs":{},")":{"docs":{},"[":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}},"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.02666666666666667},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"t":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}},",":{"docs":{},"a":{"docs":{},")":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}},"u":{"docs":{},"c":{"docs":{},"b":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"/":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.04}}},">":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}},"d":{"docs":{},"p":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"）":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.05405405405405406}}}}}},"n":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.12},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666},"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.06666666666666667}},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}},"e":{"docs":{},"w":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}},"x":{"docs":{},"t":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}},"_":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}},")":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"l":{"docs":{},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}},"r":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703}},"e":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}},"）":{"docs":{},"為":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{},"）":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}},"_":{"1":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}},"2":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}},"docs":{},"n":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.04},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}},"i":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}},"t":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}},"+":{"1":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}},"=":{"docs":{},"r":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}},"2":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077}}},"3":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077}}},"docs":{},"k":{"docs":{},"+":{"1":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}},"docs":{}}}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"，":{"docs":{},"他":{"docs":{},"決":{"docs":{},"定":{"docs":{},"了":{"docs":{},"未":{"docs":{},"來":{"docs":{},"各":{"docs":{},"時":{"docs":{},"點":{"docs":{},"的":{"docs":{},"回":{"docs":{},"報":{"docs":{},"對":{"docs":{},"於":{"docs":{},"現":{"docs":{},"在":{"docs":{},"時":{"docs":{},"點":{"docs":{},"的":{"docs":{},"價":{"docs":{},"值":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},")":{"docs":{},"=":{"docs":{},"e":{"docs":{},"(":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{},"|":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"s":{"docs":{},",":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}},"docs":{}}}}}}}}},",":{"docs":{},"s":{"docs":{},"'":{"docs":{},")":{"docs":{},"=":{"docs":{},"e":{"docs":{},"(":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{},"|":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"s":{"docs":{},",":{"docs":{},"a":{"docs":{},"_":{"docs":{},"t":{"docs":{},"=":{"docs":{},"a":{"docs":{},",":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"1":{"docs":{},"=":{"docs":{},"s":{"docs":{},"'":{"docs":{},")":{"docs":{},"=":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"t":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.05194805194805195},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.046153846153846156},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}},"b":{"docs":{},"d":{"docs":{},":":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.025974025974025976},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"s":{"docs":{},"）":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077}},"的":{"docs":{},"範":{"docs":{},"疇":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}},"）":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"任":{"docs":{},"務":{"docs":{},"可":{"docs":{},"以":{"docs":{},"被":{"docs":{},"簡":{"docs":{},"化":{"docs":{},"到":{"docs":{},"極":{"docs":{},"致":{"docs":{},"，":{"docs":{},"變":{"docs":{},"成":{"docs":{},"三":{"docs":{},"個":{"docs":{},"子":{"docs":{},"任":{"docs":{},"務":{"docs":{},"：":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}},"+":{"1":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}},"docs":{}},"=":{"0":{"docs":{},",":{"1":{"docs":{},",":{"2":{"docs":{},",":{"3":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}},"docs":{}}},"docs":{}}},"docs":{}}},"docs":{}},"r":{"docs":{},"i":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"）":{"docs":{},"重":{"docs":{},"寫":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"預":{"docs":{},"期":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"並":{"docs":{},"且":{"docs":{},"將":{"docs":{},"預":{"docs":{},"期":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"條":{"docs":{},"件":{"docs":{},"期":{"docs":{},"望":{"docs":{},"值":{"docs":{},"展":{"docs":{},"開":{"docs":{},"為":{"docs":{},"：":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"個":{"docs":{},"簡":{"docs":{},"單":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"計":{"docs":{},"算":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"透":{"docs":{},"過":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"採":{"docs":{},"取":{"docs":{},"該":{"docs":{},"動":{"docs":{},"作":{"docs":{},"之":{"docs":{},"後":{"docs":{},"的":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"除":{"docs":{},"以":{"docs":{},"採":{"docs":{},"取":{"docs":{},"該":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"總":{"docs":{},"次":{"docs":{},"數":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"上":{"docs":{},"式":{"docs":{},"中":{"docs":{},"的":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}},"的":{"docs":{},"操":{"docs":{},"作":{"docs":{},"就":{"docs":{},"是":{"docs":{},"所":{"docs":{},"謂":{"docs":{},"的":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"寫":{"docs":{},"作":{"docs":{},"：":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"假":{"docs":{},"定":{"docs":{},"一":{"docs":{},"個":{"docs":{},"很":{"docs":{},"小":{"docs":{},"的":{"docs":{},"機":{"docs":{},"率":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}},"在":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}},"都":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"考":{"docs":{},"慮":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"之":{"docs":{},"間":{"docs":{},"可":{"docs":{},"能":{"docs":{},"有":{"docs":{},"所":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"，":{"docs":{},"並":{"docs":{},"且":{"docs":{},"面":{"docs":{},"對":{"docs":{},"特":{"docs":{},"定":{"docs":{},"環":{"docs":{},"境":{"docs":{},"可":{"docs":{},"能":{"docs":{},"存":{"docs":{},"在":{"docs":{},"特":{"docs":{},"定":{"docs":{},"動":{"docs":{},"作":{"docs":{},"能":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"最":{"docs":{},"大":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"不":{"docs":{},"能":{"docs":{},"說":{"docs":{},"代":{"docs":{},"理":{"docs":{},"處":{"docs":{},"於":{"docs":{},"「":{"docs":{},"下":{"docs":{},"一":{"docs":{},"張":{"docs":{},"牌":{"docs":{},"是":{"docs":{},"紅":{"docs":{},"心":{"docs":{},"q":{"docs":{},"」":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}},"當":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}},"你":{"docs":{},"用":{"docs":{},"常":{"docs":{},"數":{"docs":{},"的":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}},"在":{"docs":{},"遵":{"docs":{},"守":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"都":{"docs":{},"是":{"docs":{},"存":{"docs":{},"在":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}},"越":{"docs":{},"久":{"docs":{},"以":{"docs":{},"前":{"docs":{},"所":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"對":{"docs":{},"於":{"docs":{},"當":{"docs":{},"前":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"能":{"docs":{},"參":{"docs":{},"考":{"docs":{},"的":{"docs":{},"價":{"docs":{},"值":{"docs":{},"越":{"docs":{},"小":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"樂":{"docs":{},"觀":{"docs":{},"初":{"docs":{},"始":{"docs":{},"值":{"docs":{},"的":{"docs":{},"設":{"docs":{},"置":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"並":{"docs":{},"非":{"docs":{},"是":{"docs":{},"一":{"docs":{},"個":{"docs":{},"很":{"docs":{},"有":{"docs":{},"用":{"docs":{},"的":{"docs":{},"一":{"docs":{},"般":{"docs":{},"性":{"docs":{},"提":{"docs":{},"升":{"docs":{},"探":{"docs":{},"索":{"docs":{},"行":{"docs":{},"為":{"docs":{},"的":{"docs":{},"技":{"docs":{},"巧":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"要":{"docs":{},"做":{"docs":{},"的":{"docs":{},"是":{"docs":{},"去":{"docs":{},"學":{"docs":{},"習":{"docs":{},"如":{"docs":{},"何":{"docs":{},"在":{"docs":{},"特":{"docs":{},"定":{"docs":{},"情":{"docs":{},"境":{"docs":{},"中":{"docs":{},"，":{"docs":{},"做":{"docs":{},"出":{"docs":{},"符":{"docs":{},"合":{"docs":{},"該":{"docs":{},"情":{"docs":{},"境":{"docs":{},"的":{"docs":{},"最":{"docs":{},"佳":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"相":{"docs":{},"信":{"docs":{},"應":{"docs":{},"該":{"docs":{},"根":{"docs":{},"據":{"docs":{},"環":{"docs":{},"境":{"docs":{},"的":{"docs":{},"變":{"docs":{},"化":{"docs":{},"，":{"docs":{},"採":{"docs":{},"取":{"docs":{},"對":{"docs":{},"應":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"不":{"docs":{},"會":{"docs":{},"有":{"docs":{},"哪":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"得":{"docs":{},"一":{"docs":{},"直":{"docs":{},"執":{"docs":{},"行":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"此":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}},"什":{"docs":{},"麼":{"docs":{},"時":{"docs":{},"候":{"docs":{},"應":{"docs":{},"該":{"docs":{},"使":{"docs":{},"用":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}},"使":{"docs":{},"得":{"docs":{},"行":{"docs":{},"為":{"docs":{},"有":{"docs":{},"機":{"docs":{},"會":{"docs":{},"隨":{"docs":{},"機":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"非":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}},"所":{"docs":{},"有":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"偏":{"docs":{},"好":{"docs":{},"相":{"docs":{},"同":{"docs":{},"。":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}},"函":{"docs":{},"數":{"docs":{},"則":{"docs":{},"為":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"方":{"docs":{},"法":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":3.346320346320346}}}},"函":{"docs":{},"數":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":3.3466666666666662}}}}},"選":{"docs":{},"擇":{"docs":{},"的":{"docs":{},"抽":{"docs":{},"象":{"docs":{},"程":{"docs":{},"度":{"docs":{},"：":{"docs":{},"代":{"docs":{},"理":{"docs":{},"可":{"docs":{},"以":{"docs":{},"根":{"docs":{},"據":{"docs":{},"基":{"docs":{},"礎":{"docs":{},"的":{"docs":{},"條":{"docs":{},"件":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"根":{"docs":{},"據":{"docs":{},"定":{"docs":{},"義":{"docs":{},"的":{"docs":{},"高":{"docs":{},"級":{"docs":{},"抽":{"docs":{},"象":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"條":{"docs":{},"件":{"docs":{},"採":{"docs":{},"取":{"docs":{},"行":{"docs":{},"為":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"態":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}},"反":{"docs":{},"之":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"採":{"docs":{},"取":{"docs":{},"不":{"docs":{},"同":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"變":{"docs":{},"異":{"docs":{},"數":{"docs":{},"接":{"docs":{},"近":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}},"饋":{"docs":{},"不":{"docs":{},"一":{"docs":{},"定":{"docs":{},"要":{"docs":{},"有":{"docs":{},"外":{"docs":{},"顯":{"docs":{},"影":{"docs":{},"響":{"docs":{},"：":{"docs":{},"當":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"代":{"docs":{},"理":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"時":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"內":{"docs":{},"在":{"docs":{},"性":{"docs":{},"的":{"docs":{},"調":{"docs":{},"整":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"修":{"docs":{},"正":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"機":{"docs":{},"率":{"docs":{},"）":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{},"時":{"docs":{},"這":{"docs":{},"個":{"docs":{},"方":{"docs":{},"法":{"docs":{},"也":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}},"棋":{"docs":{},"盤":{"docs":{},"上":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"排":{"docs":{},"列":{"docs":{},"組":{"docs":{},"合":{"docs":{},"，":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"對":{"docs":{},"未":{"docs":{},"來":{"docs":{},"可":{"docs":{},"能":{"docs":{},"發":{"docs":{},"生":{"docs":{},"的":{"docs":{},"特":{"docs":{},"定":{"docs":{},"情":{"docs":{},"況":{"docs":{},"做":{"docs":{},"出":{"docs":{},"任":{"docs":{},"何":{"docs":{},"保":{"docs":{},"證":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"飛":{"docs":{},"彈":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"座":{"docs":{},"標":{"docs":{},"與":{"docs":{},"速":{"docs":{},"度":{"docs":{},"，":{"docs":{},"也":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"保":{"docs":{},"證":{"docs":{},"未":{"docs":{},"來":{"docs":{},"飛":{"docs":{},"彈":{"docs":{},"可":{"docs":{},"能":{"docs":{},"落":{"docs":{},"於":{"docs":{},"任":{"docs":{},"何":{"docs":{},"地":{"docs":{},"方":{"docs":{},"的":{"docs":{},"保":{"docs":{},"證":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"樣":{"docs":{},"的":{"docs":{},"，":{"docs":{},"這":{"docs":{},"邊":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"發":{"docs":{},"現":{"docs":{},"這":{"docs":{},"一":{"docs":{},"項":{"docs":{},"對":{"docs":{},"於":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{},"仍":{"docs":{},"舊":{"docs":{},"不":{"docs":{},"會":{"docs":{},"有":{"docs":{},"太":{"docs":{},"有":{"docs":{},"幫":{"docs":{},"助":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"道":{"docs":{},"理":{"docs":{},"，":{"docs":{},"假":{"docs":{},"設":{"docs":{},"在":{"docs":{},"這":{"docs":{},"個":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"呢":{"docs":{},"？":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}},"圖":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.025974025974025976}}},"對":{"docs":{},"應":{"docs":{},"的":{"docs":{},"價":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"，":{"docs":{},"簡":{"docs":{},"稱":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}},"於":{"docs":{},"某":{"docs":{},"個":{"docs":{},"特":{"docs":{},"定":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}},"這":{"docs":{},"個":{"docs":{},"第":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}},"狀":{"docs":{},"態":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"成":{"docs":{},"是":{"docs":{},"遵":{"docs":{},"守":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"來":{"docs":{},"說":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"所":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"和":{"docs":{},"你":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"關":{"docs":{},"係":{"docs":{},"變":{"docs":{},"得":{"docs":{},"更":{"docs":{},"為":{"docs":{},"複":{"docs":{},"雜":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"會":{"docs":{},"比":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}},"能":{"docs":{},"知":{"docs":{},"道":{"docs":{},"所":{"docs":{},"有":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"真":{"docs":{},"實":{"docs":{},"價":{"docs":{},"值":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}},"是":{"docs":{},"所":{"docs":{},"謂":{"docs":{},"的":{"docs":{},"折":{"docs":{},"扣":{"docs":{},"率":{"docs":{},"（":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}},"未":{"docs":{},"來":{"docs":{},"所":{"docs":{},"有":{"docs":{},"時":{"docs":{},"點":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"總":{"docs":{},"和":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}},"很":{"docs":{},"簡":{"docs":{},"單":{"docs":{},"一":{"docs":{},"個":{"docs":{},"想":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"存":{"docs":{},"在":{"docs":{},"一":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}},"大":{"docs":{},"時":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"需":{"docs":{},"要":{"docs":{},"很":{"docs":{},"多":{"docs":{},"的":{"docs":{},"資":{"docs":{},"源":{"docs":{},"空":{"docs":{},"間":{"docs":{},"存":{"docs":{},"放":{"docs":{},"前":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}},"程":{"docs":{},"度":{"docs":{},"取":{"docs":{},"決":{"docs":{},"於":{"docs":{},"初":{"docs":{},"始":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}},"合":{"docs":{},"理":{"docs":{},"的":{"docs":{},"可":{"docs":{},"以":{"docs":{},"發":{"docs":{},"現":{"docs":{},"，":{"docs":{},"會":{"docs":{},"隨":{"docs":{},"時":{"docs":{},"間":{"docs":{},"變":{"docs":{},"化":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"，":{"docs":{},"更":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"是":{"docs":{},"如":{"docs":{},"何":{"docs":{},"把":{"docs":{},"握":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"接":{"docs":{},"著":{"docs":{},"會":{"docs":{},"來":{"docs":{},"嘗":{"docs":{},"試":{"docs":{},"評":{"docs":{},"估":{"docs":{},"採":{"docs":{},"取":{"docs":{},"一":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"價":{"docs":{},"值":{"docs":{},"，":{"docs":{},"正":{"docs":{},"如":{"docs":{},"前":{"docs":{},"面":{"docs":{},"所":{"docs":{},"提":{"docs":{},"到":{"docs":{},"，":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"正":{"docs":{},"確":{"docs":{},"評":{"docs":{},"估":{"docs":{},"來":{"docs":{},"自":{"docs":{},"於":{"docs":{},"採":{"docs":{},"取":{"docs":{},"該":{"docs":{},"動":{"docs":{},"作":{"docs":{},"之":{"docs":{},"後":{"docs":{},"獲":{"docs":{},"取":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"此":{"docs":{},"將":{"docs":{},"這":{"docs":{},"種":{"docs":{},"遞":{"docs":{},"增":{"docs":{},"式":{"docs":{},"的":{"docs":{},"算":{"docs":{},"法":{"docs":{},"實":{"docs":{},"作":{"docs":{},"，":{"docs":{},"表":{"docs":{},"達":{"docs":{},"成":{"docs":{},"一":{"docs":{},"個":{"docs":{},"更":{"docs":{},"廣":{"docs":{},"義":{"docs":{},"的":{"docs":{},"通":{"docs":{},"式":{"docs":{},"：":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}},"已":{"docs":{},"經":{"docs":{},"做":{"docs":{},"過":{"docs":{},"了":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}},"知":{"docs":{},"道":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"行":{"docs":{},"為":{"docs":{},"是":{"docs":{},"目":{"docs":{},"前":{"docs":{},"看":{"docs":{},"起":{"docs":{},"來":{"docs":{},"最":{"docs":{},"好":{"docs":{},"的":{"docs":{},"決":{"docs":{},"策":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"也":{"docs":{},"知":{"docs":{},"道":{"docs":{},"不":{"docs":{},"能":{"docs":{},"一":{"docs":{},"直":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"個":{"docs":{},"價":{"docs":{},"值":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"預":{"docs":{},"期":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"來":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"現":{"docs":{},"在":{"docs":{},"我":{"docs":{},"們":{"docs":{},"要":{"docs":{},"為":{"docs":{},"每":{"docs":{},"一":{"docs":{},"個":{"docs":{},"策":{"docs":{},"略":{"docs":{},"定":{"docs":{},"義":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"一":{"docs":{},"個":{"docs":{},"方":{"docs":{},"法":{"docs":{},"來":{"docs":{},"更":{"docs":{},"新":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"好":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"舉":{"docs":{},"機":{"docs":{},"器":{"docs":{},"人":{"docs":{},"走":{"docs":{},"迷":{"docs":{},"宮":{"docs":{},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"機":{"docs":{},"器":{"docs":{},"人":{"docs":{},"要":{"docs":{},"走":{"docs":{},"出":{"docs":{},"迷":{"docs":{},"宮":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"定":{"docs":{},"義":{"docs":{},"每":{"docs":{},"一":{"docs":{},"步":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"都":{"docs":{},"要":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"根":{"docs":{},"據":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"行":{"docs":{},"動":{"docs":{},"來":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"並":{"docs":{},"預":{"docs":{},"期":{"docs":{},"我":{"docs":{},"們":{"docs":{},"下":{"docs":{},"一":{"docs":{},"個":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"為":{"docs":{},"何":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"們":{"docs":{},"能":{"docs":{},"選":{"docs":{},"到":{"docs":{},"最":{"docs":{},"佳":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"機":{"docs":{},"率":{"docs":{},"是":{"docs":{},"大":{"docs":{},"於":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}},"很":{"docs":{},"清":{"docs":{},"楚":{"docs":{},"可":{"docs":{},"能":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}},"必":{"docs":{},"須":{"docs":{},"先":{"docs":{},"了":{"docs":{},"解":{"docs":{},"，":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"不":{"docs":{},"可":{"docs":{},"以":{"docs":{},"對":{"docs":{},"未":{"docs":{},"來":{"docs":{},"的":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"作":{"docs":{},"保":{"docs":{},"證":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"理":{"docs":{},"想":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"設":{"docs":{},"計":{"docs":{},"原":{"docs":{},"則":{"docs":{},"，":{"docs":{},"應":{"docs":{},"該":{"docs":{},"是":{"docs":{},"他":{"docs":{},"能":{"docs":{},"總":{"docs":{},"結":{"docs":{},"過":{"docs":{},"去":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"到":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"，":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"才":{"docs":{},"是":{"docs":{},"我":{"docs":{},"們":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"個":{"docs":{},"更":{"docs":{},"進":{"docs":{},"階":{"docs":{},"且":{"docs":{},"完":{"docs":{},"備":{"docs":{},"的":{"docs":{},"數":{"docs":{},"學":{"docs":{},"理":{"docs":{},"論":{"docs":{},"去":{"docs":{},"處":{"docs":{},"理":{"docs":{},"他":{"docs":{},"，":{"docs":{},"因":{"docs":{},"為":{"docs":{},"我":{"docs":{},"們":{"docs":{},"必":{"docs":{},"須":{"docs":{},"時":{"docs":{},"時":{"docs":{},"刻":{"docs":{},"刻":{"docs":{},"去":{"docs":{},"平":{"docs":{},"衡":{"docs":{},"探":{"docs":{},"索":{"docs":{},"與":{"docs":{},"利":{"docs":{},"用":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"對":{"docs":{},"於":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}},"一":{"docs":{},"種":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"對":{"docs":{},"於":{"docs":{},"非":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"，":{"docs":{},"做":{"docs":{},"一":{"docs":{},"點":{"docs":{},"挑":{"docs":{},"選":{"docs":{},"或":{"docs":{},"處":{"docs":{},"理":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"能":{"docs":{},"有":{"docs":{},"一":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"在":{"docs":{},"很":{"docs":{},"長":{"docs":{},"時":{"docs":{},"間":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"被":{"docs":{},"選":{"docs":{},"取":{"docs":{},"，":{"docs":{},"但":{"docs":{},"單":{"docs":{},"純":{"docs":{},"只":{"docs":{},"是":{"docs":{},"因":{"docs":{},"為":{"docs":{},"當":{"docs":{},"時":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"不":{"docs":{},"適":{"docs":{},"合":{"docs":{},"採":{"docs":{},"取":{"docs":{},"該":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"將":{"docs":{},"你":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"標":{"docs":{},"，":{"docs":{},"切":{"docs":{},"割":{"docs":{},"成":{"docs":{},"環":{"docs":{},"境":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"和":{"docs":{},"代":{"docs":{},"理":{"docs":{},"內":{"docs":{},"在":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"是":{"docs":{},"處":{"docs":{},"理":{"docs":{},"代":{"docs":{},"理":{"docs":{},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"界":{"docs":{},"限":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"問":{"docs":{},"題":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}},"一":{"docs":{},"種":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}},"個":{"docs":{},"需":{"docs":{},"要":{"docs":{},"先":{"docs":{},"驗":{"docs":{},"給":{"docs":{},"定":{"docs":{},"的":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}},"探":{"docs":{},"索":{"docs":{},"度":{"docs":{},"（":{"docs":{},"d":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}},"常":{"docs":{},"數":{"docs":{},"還":{"docs":{},"是":{"docs":{},"變":{"docs":{},"數":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"都":{"docs":{},"可":{"docs":{},"以":{"docs":{},"從":{"docs":{},"上":{"docs":{},"式":{"docs":{},"發":{"docs":{},"現":{"docs":{},"一":{"docs":{},"件":{"docs":{},"事":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}},"鼓":{"docs":{},"勵":{"docs":{},"探":{"docs":{},"索":{"docs":{},"行":{"docs":{},"為":{"docs":{},"的":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}},"不":{"docs":{},"值":{"docs":{},"得":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"我":{"docs":{},"們":{"docs":{},"對":{"docs":{},"他":{"docs":{},"的":{"docs":{},"原":{"docs":{},"始":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}},"最":{"docs":{},"終":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"而":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}},"從":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}},"時":{"docs":{},"點":{"docs":{},"前":{"docs":{},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}},"的":{"docs":{},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}},"動":{"docs":{},"作":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}},"選":{"docs":{},"擇":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"動":{"docs":{},"作":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"能":{"docs":{},"正":{"docs":{},"確":{"docs":{},"的":{"docs":{},"逼":{"docs":{},"近":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}},"間":{"docs":{},"間":{"docs":{},"隔":{"docs":{},"的":{"docs":{},"自":{"docs":{},"由":{"docs":{},"度":{"docs":{},"：":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"要":{"docs":{},"求":{"docs":{},"離":{"docs":{},"散":{"docs":{},"時":{"docs":{},"間":{"docs":{},"時":{"docs":{},"點":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"相":{"docs":{},"隔":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"越":{"docs":{},"會":{"docs":{},"把":{"docs":{},"未":{"docs":{},"來":{"docs":{},"的":{"docs":{},"回":{"docs":{},"報":{"docs":{},"看":{"docs":{},"得":{"docs":{},"和":{"docs":{},"下":{"docs":{},"一":{"docs":{},"期":{"docs":{},"回":{"docs":{},"報":{"docs":{},"一":{"docs":{},"樣":{"docs":{},"重":{"docs":{},"要":{"docs":{},"，":{"docs":{},"更":{"docs":{},"重":{"docs":{},"視":{"docs":{},"未":{"docs":{},"來":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"遵":{"docs":{},"守":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}},"樣":{"docs":{},"本":{"docs":{},"平":{"docs":{},"均":{"docs":{},"法":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}},"透":{"docs":{},"過":{"docs":{},"探":{"docs":{},"索":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"能":{"docs":{},"幫":{"docs":{},"助":{"docs":{},"我":{"docs":{},"們":{"docs":{},"找":{"docs":{},"到":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"可":{"docs":{},"能":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}},"這":{"docs":{},"個":{"docs":{},"方":{"docs":{},"法":{"docs":{},"揭":{"docs":{},"露":{"docs":{},"出":{"docs":{},"來":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"，":{"docs":{},"會":{"docs":{},"使":{"docs":{},"得":{"docs":{},"我":{"docs":{},"們":{"docs":{},"只":{"docs":{},"能":{"docs":{},"採":{"docs":{},"取":{"docs":{},"一":{"docs":{},"種":{"docs":{},"合":{"docs":{},"理":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"採":{"docs":{},"取":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"動":{"docs":{},"作":{"docs":{},"。":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"那":{"docs":{},"麼":{"docs":{},"只":{"docs":{},"要":{"docs":{},"在":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"上":{"docs":{},"採":{"docs":{},"取":{"docs":{},"一":{"docs":{},"次":{"docs":{},"行":{"docs":{},"為":{"docs":{},"，":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{"2-2-動作值方法.html":{"ref":"2-2-動作值方法.html","tf":0.012987012987012988}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{},"時":{"docs":{},"也":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"很":{"docs":{},"小":{"docs":{},"的":{"docs":{},"計":{"docs":{},"算":{"docs":{},"量":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{},"此":{"docs":{},"以":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}},"則":{"docs":{},"前":{"docs":{},"述":{"docs":{},"的":{"docs":{},"條":{"docs":{},"件":{"docs":{},"二":{"docs":{},"會":{"docs":{},"不":{"docs":{},"符":{"docs":{},"合":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}},"為":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"有":{"docs":{},"這":{"docs":{},"個":{"docs":{},"想":{"docs":{},"法":{"docs":{},"呢":{"docs":{},"？":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}},"這":{"docs":{},"能":{"docs":{},"保":{"docs":{},"證":{"docs":{},"我":{"docs":{},"們":{"docs":{},"收":{"docs":{},"斂":{"docs":{},"到":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"的":{"docs":{},"真":{"docs":{},"實":{"docs":{},"數":{"docs":{},"值":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}},"鼓":{"docs":{},"勵":{"docs":{},"他":{"docs":{},"必":{"docs":{},"須":{"docs":{},"給":{"docs":{},"快":{"docs":{},"脫":{"docs":{},"離":{"docs":{},"環":{"docs":{},"境":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}},"個":{"docs":{},"是":{"docs":{},"最":{"docs":{},"簡":{"docs":{},"易":{"docs":{},"的":{"docs":{},"情":{"docs":{},"況":{"docs":{},"。":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}},"會":{"docs":{},"在":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}},"而":{"docs":{},"是":{"docs":{},"讓":{"docs":{},"代":{"docs":{},"理":{"docs":{},"不":{"docs":{},"斷":{"docs":{},"累":{"docs":{},"積":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"這":{"docs":{},"種":{"docs":{},"學":{"docs":{},"習":{"docs":{},"任":{"docs":{},"務":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"持":{"docs":{},"續":{"docs":{},"性":{"docs":{},"任":{"docs":{},"務":{"docs":{},"（":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"u":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.02666666666666667},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703},"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}},"+":{"1":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}},"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.05333333333333334},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.016666666666666666},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.09230769230769231}}},".":{"docs":{},".":{"docs":{},".":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077},"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}},"]":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334},"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}},"中":{"docs":{},"被":{"docs":{},"隱":{"docs":{},"藏":{"docs":{},"了":{"docs":{},"起":{"docs":{},"來":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}},"提":{"docs":{},"到":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"關":{"docs":{},"心":{"docs":{},"的":{"docs":{},"是":{"docs":{},"採":{"docs":{},"取":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"帶":{"docs":{},"給":{"docs":{},"我":{"docs":{},"們":{"docs":{},"的":{"docs":{},"價":{"docs":{},"值":{"docs":{},"為":{"docs":{},"何":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"定":{"docs":{},"義":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}},"做":{"docs":{},"表":{"docs":{},"示":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}},"一":{"docs":{},"點":{"docs":{},"加":{"docs":{},"成":{"docs":{},"，":{"docs":{},"作":{"docs":{},"為":{"docs":{},"每":{"docs":{},"次":{"docs":{},"行":{"docs":{},"為":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"的":{"docs":{},"參":{"docs":{},"考":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}},"其":{"docs":{},"中":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.029411764705882353},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"的":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}},"我":{"docs":{},"們":{"docs":{},"稱":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"則":{"docs":{},"在":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}},"會":{"docs":{},"讓":{"docs":{},"代":{"docs":{},"理":{"docs":{},"只":{"docs":{},"關":{"docs":{},"注":{"docs":{},"下":{"docs":{},"期":{"docs":{},"回":{"docs":{},"報":{"docs":{},"，":{"docs":{},"忽":{"docs":{},"略":{"docs":{},"未":{"docs":{},"來":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"可":{"docs":{},"能":{"docs":{},"回":{"docs":{},"報":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"成":{"docs":{},"是":{"docs":{},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{},"上":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{},"誤":{"docs":{},"差":{"docs":{},"（":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"）":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}},"表":{"docs":{},"示":{"docs":{},"成":{"docs":{},"：":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}},"能":{"docs":{},"也":{"docs":{},"很":{"docs":{},"小":{"docs":{},"）":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"現":{"docs":{},"在":{"docs":{},"我":{"docs":{},"們":{"docs":{},"要":{"docs":{},"來":{"docs":{},"進":{"docs":{},"一":{"docs":{},"步":{"docs":{},"討":{"docs":{},"論":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"如":{"docs":{},"何":{"docs":{},"對":{"docs":{},"樣":{"docs":{},"本":{"docs":{},"平":{"docs":{},"均":{"docs":{},"做":{"docs":{},"更":{"docs":{},"有":{"docs":{},"效":{"docs":{},"率":{"docs":{},"的":{"docs":{},"估":{"docs":{},"算":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"理":{"docs":{},"論":{"docs":{},"的":{"docs":{},"基":{"docs":{},"礎":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}},"而":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}},"其":{"docs":{},"中":{"docs":{},"的":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}},"我":{"docs":{},"們":{"docs":{},"對":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"定":{"docs":{},"義":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"應":{"docs":{},"該":{"docs":{},"是":{"docs":{},"與":{"docs":{},"我":{"docs":{},"們":{"docs":{},"想":{"docs":{},"要":{"docs":{},"實":{"docs":{},"現":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"標":{"docs":{},"盡":{"docs":{},"可":{"docs":{},"能":{"docs":{},"相":{"docs":{},"關":{"docs":{},"聯":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"整":{"docs":{},"個":{"docs":{},"乘":{"docs":{},"起":{"docs":{},"來":{"docs":{},"越":{"docs":{},"小":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}},"在":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}},"式":{"docs":{},"子":{"docs":{},"中":{"docs":{},"的":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}},"贏":{"docs":{},"棋":{"docs":{},"則":{"docs":{},"記":{"docs":{},"為":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}},"當":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}},"是":{"docs":{},"會":{"docs":{},"希":{"docs":{},"望":{"docs":{},"盡":{"docs":{},"可":{"docs":{},"能":{"docs":{},"地":{"docs":{},"關":{"docs":{},"注":{"docs":{},"如":{"docs":{},"何":{"docs":{},"建":{"docs":{},"立":{"docs":{},"能":{"docs":{},"對":{"docs":{},"應":{"docs":{},"任":{"docs":{},"何":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"狀":{"docs":{},"態":{"docs":{},"轉":{"docs":{},"移":{"docs":{},"的":{"docs":{},"機":{"docs":{},"率":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"表":{"docs":{},"示":{"docs":{},"為":{"docs":{},"：":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}}}}}},"舉":{"docs":{},"例":{"docs":{},"來":{"docs":{},"說":{"docs":{},"，":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"對":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}},"觀":{"docs":{},"察":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{},"式":{"docs":{},"子":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"到":{"docs":{},"更":{"docs":{},"多":{"docs":{},"有":{"docs":{},"意":{"docs":{},"思":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"。":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}},"遞":{"docs":{},"增":{"docs":{},"式":{"docs":{},"的":{"docs":{},"算":{"docs":{},"法":{"docs":{},"實":{"docs":{},"作":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":0.013333333333333334}}}}}}},"算":{"docs":{},"法":{"docs":{},"實":{"docs":{},"作":{"docs":{"2-3-遞增式的算法實作.html":{"ref":"2-3-遞增式的算法實作.html","tf":3.333333333333333}}}}}}}}},"*":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.025},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886},"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.03076923076923077}}},"[":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"h":{"docs":{},"a":{"docs":{},"_":{"docs":{},"n":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},"]":{"docs":{},"^":{"2":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}},"docs":{}}}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}},"}":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}},"之":{"docs":{},"間":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}},"前":{"docs":{},"，":{"docs":{},"你":{"docs":{},"並":{"docs":{},"未":{"docs":{},"採":{"docs":{},"取":{"docs":{},"任":{"docs":{},"何":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}},"的":{"docs":{},"總":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"平":{"docs":{},"均":{"docs":{},"。":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}},"事":{"docs":{},"實":{"docs":{},"上":{"docs":{},"多":{"docs":{},"數":{"docs":{},"問":{"docs":{},"題":{"docs":{},"面":{"docs":{},"對":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"，":{"docs":{},"是":{"docs":{},"會":{"docs":{},"不":{"docs":{},"斷":{"docs":{},"變":{"docs":{},"化":{"docs":{},"，":{"docs":{},"這":{"docs":{},"樣":{"docs":{},"前":{"docs":{},"面":{"docs":{},"討":{"docs":{},"論":{"docs":{},"的":{"docs":{},"內":{"docs":{},"容":{"docs":{},"就":{"docs":{},"會":{"docs":{},"不":{"docs":{},"太":{"docs":{},"適":{"docs":{},"用":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"表":{"docs":{},"在":{"docs":{},"第":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}},"代":{"docs":{},"理":{"docs":{},"在":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}},"理":{"docs":{},"可":{"docs":{},"以":{"docs":{},"採":{"docs":{},"取":{"docs":{},"什":{"docs":{},"麼":{"docs":{},"行":{"docs":{},"為":{"docs":{},"（":{"docs":{},"動":{"docs":{},"作":{"docs":{},"）":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}},"透":{"docs":{},"過":{"docs":{},"自":{"docs":{},"己":{"docs":{},"學":{"docs":{},"習":{"docs":{},"到":{"docs":{},"的":{"docs":{},"經":{"docs":{},"驗":{"docs":{},"改":{"docs":{},"變":{"docs":{},"其":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"基":{"docs":{},"本":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"標":{"docs":{},"就":{"docs":{},"是":{"docs":{},"在":{"docs":{},"長":{"docs":{},"期":{"docs":{},"能":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"從":{"docs":{},"環":{"docs":{},"境":{"docs":{},"去":{"docs":{},"歸":{"docs":{},"納":{"docs":{},"、":{"docs":{},"學":{"docs":{},"習":{"docs":{},"，":{"docs":{},"但":{"docs":{},"我":{"docs":{},"們":{"docs":{},"定":{"docs":{},"義":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"不":{"docs":{},"能":{"docs":{},"直":{"docs":{},"接":{"docs":{},"保":{"docs":{},"證":{"docs":{},"未":{"docs":{},"來":{"docs":{},"特":{"docs":{},"定":{"docs":{},"情":{"docs":{},"況":{"docs":{},"會":{"docs":{},"發":{"docs":{},"生":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"理":{"docs":{},"解":{"docs":{},"環":{"docs":{},"境":{"docs":{},"（":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"）":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}},"知":{"docs":{},"道":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"標":{"docs":{},"（":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"）":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}},"很":{"docs":{},"有":{"docs":{},"可":{"docs":{},"能":{"docs":{},"能":{"docs":{},"理":{"docs":{},"解":{"docs":{},"環":{"docs":{},"境":{"docs":{},"如":{"docs":{},"何":{"docs":{},"給":{"docs":{},"予":{"docs":{},"他":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"但":{"docs":{},"仍":{"docs":{},"舊":{"docs":{},"無":{"docs":{},"法":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"他":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"一":{"docs":{},"些":{"docs":{},"環":{"docs":{},"境":{"docs":{},"資":{"docs":{},"訊":{"docs":{},"，":{"docs":{},"用":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"表":{"docs":{},"示":{"docs":{},"為":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}},"環":{"docs":{},"境":{"docs":{},"交":{"docs":{},"互":{"docs":{},"示":{"docs":{},"意":{"docs":{},"圖":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"界":{"docs":{},"限":{"docs":{},"，":{"docs":{},"並":{"docs":{},"不":{"docs":{},"是":{"docs":{},"以":{"docs":{},"代":{"docs":{},"理":{"docs":{},"和":{"docs":{},"環":{"docs":{},"境":{"docs":{},"本":{"docs":{},"身":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"邊":{"docs":{},"界":{"docs":{},"做":{"docs":{},"區":{"docs":{},"隔":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}},"介":{"docs":{},"面":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}},"的":{"docs":{},"界":{"docs":{},"限":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":3.3627450980392153}}}}}}}},"人":{"docs":{},"的":{"docs":{},"內":{"docs":{},"在":{"docs":{},"獎":{"docs":{},"勵":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}},"的":{"docs":{},"目":{"docs":{},"標":{"docs":{},"就":{"docs":{},"是":{"docs":{},"要":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"本":{"docs":{},"身":{"docs":{},"的":{"docs":{},"期":{"docs":{},"望":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"進":{"docs":{},"而":{"docs":{},"能":{"docs":{},"使":{"docs":{},"其":{"docs":{},"本":{"docs":{},"身":{"docs":{},"累":{"docs":{},"積":{"docs":{},"到":{"docs":{},"最":{"docs":{},"高":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"去":{"docs":{},"掌":{"docs":{},"握":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"規":{"docs":{},"則":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"docs":{},"個":{"docs":{},"學":{"docs":{},"習":{"docs":{},"回":{"docs":{},"合":{"docs":{},"中":{"docs":{},"，":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"是":{"docs":{},"一":{"docs":{},"個":{"docs":{},"數":{"docs":{},"字":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"到":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333},"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"常":{"docs":{},"數":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}},"，":{"docs":{},"介":{"docs":{},"在":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"意":{"docs":{},"思":{"docs":{},"是":{"docs":{},"：":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}},"為":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"一":{"docs":{},"個":{"docs":{},"常":{"docs":{},"數":{"docs":{},"。":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"整":{"docs":{},"體":{"docs":{},"所":{"docs":{},"有":{"docs":{},"動":{"docs":{},"作":{"docs":{},"在":{"docs":{},"時":{"docs":{},"點":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}},"所":{"docs":{},"有":{"docs":{},"代":{"docs":{},"理":{"docs":{},"能":{"docs":{},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"資":{"docs":{},"訊":{"docs":{},"集":{"docs":{},"合":{"docs":{},"，":{"docs":{},"並":{"docs":{},"且":{"docs":{},"在":{"docs":{},"此":{"docs":{},"基":{"docs":{},"礎":{"docs":{},"上":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"一":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"了":{"docs":{},"使":{"docs":{},"得":{"docs":{},"近":{"docs":{},"似":{"docs":{},"能":{"docs":{},"更":{"docs":{},"精":{"docs":{},"確":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"們":{"docs":{},"必":{"docs":{},"須":{"docs":{},"充":{"docs":{},"分":{"docs":{},"的":{"docs":{},"提":{"docs":{},"供":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"，":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"數":{"docs":{},"學":{"docs":{},"表":{"docs":{},"示":{"docs":{},"上":{"docs":{},"的":{"docs":{},"方":{"docs":{},"便":{"docs":{},"，":{"docs":{},"在":{"docs":{},"此":{"docs":{},"我":{"docs":{},"們":{"docs":{},"先":{"docs":{},"考":{"docs":{},"慮":{"docs":{},"環":{"docs":{},"境":{"docs":{},"有":{"docs":{},"限":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"獎":{"docs":{},"勵":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}},"達":{"docs":{},"到":{"docs":{},"這":{"docs":{},"個":{"docs":{},"目":{"docs":{},"的":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"在":{"docs":{},"本":{"docs":{},"節":{"docs":{},"中":{"docs":{},"對":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"做":{"docs":{},"一":{"docs":{},"些":{"docs":{},"限":{"docs":{},"制":{"docs":{},"與":{"docs":{},"規":{"docs":{},"範":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}},"狀":{"docs":{},"態":{"docs":{},"動":{"docs":{},"作":{"docs":{},"對":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}}}}}}}},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"（":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"總":{"docs":{},"和":{"docs":{},"也":{"docs":{},"要":{"docs":{},"無":{"docs":{},"限":{"docs":{},"大":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"要":{"docs":{},"收":{"docs":{},"斂":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}},"處":{"docs":{},"理":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"問":{"docs":{},"題":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":3.3416666666666663}}}}}}}}},"被":{"docs":{},"定":{"docs":{},"義":{"docs":{},"成":{"docs":{},"一":{"docs":{},"個":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}}}}}}},"越":{"docs":{},"小":{"docs":{},"於":{"docs":{"2-4-處理非平穩問題.html":{"ref":"2-4-處理非平穩問題.html","tf":0.008333333333333333}}},"）":{"docs":{},"則":{"docs":{},"帶":{"docs":{},"根":{"docs":{},"號":{"docs":{},"那":{"docs":{},"一":{"docs":{},"項":{"docs":{},"就":{"docs":{},"會":{"docs":{},"越":{"docs":{},"大":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}},"大":{"docs":{},"）":{"docs":{},"中":{"docs":{},"，":{"docs":{},"採":{"docs":{},"取":{"docs":{},"到":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}},"接":{"docs":{},"近":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.03773584905660377},"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333},"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.0625}}},"並":{"docs":{},"且":{"docs":{},"在":{"docs":{},"盡":{"docs":{},"可":{"docs":{},"能":{"docs":{},"多":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"上":{"docs":{},"面":{"docs":{},"進":{"docs":{},"行":{"docs":{},"探":{"docs":{},"索":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"最":{"docs":{},"後":{"docs":{},"就":{"docs":{},"算":{"docs":{},"開":{"docs":{},"始":{"docs":{},"不":{"docs":{},"斷":{"docs":{},"的":{"docs":{},"做":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"動":{"docs":{},"作":{"docs":{},"，":{"docs":{},"也":{"docs":{},"有":{"docs":{},"足":{"docs":{},"夠":{"docs":{},"的":{"docs":{},"探":{"docs":{},"索":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"新":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"環":{"docs":{},"境":{"docs":{},"資":{"docs":{},"訊":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}},"得":{"docs":{},"到":{"docs":{},"獎":{"docs":{},"勵":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}},"不":{"docs":{},"能":{"docs":{},"用":{"docs":{},"此":{"docs":{},"來":{"docs":{},"代":{"docs":{},"表":{"docs":{},"，":{"docs":{},"你":{"docs":{},"就":{"docs":{},"很":{"docs":{},"有":{"docs":{},"信":{"docs":{},"心":{"docs":{},"這":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"是":{"docs":{},"不":{"docs":{},"值":{"docs":{},"得":{"docs":{},"被":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"（":{"docs":{},"因":{"docs":{},"為":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"動":{"docs":{},"作":{"docs":{},"執":{"docs":{},"行":{"docs":{},"後":{"docs":{},"的":{"docs":{},"時":{"docs":{},"間":{"docs":{},"，":{"docs":{},"接":{"docs":{},"收":{"docs":{},"動":{"docs":{},"作":{"docs":{},"產":{"docs":{},"生":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"稱":{"docs":{},"做":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}},"但":{"docs":{},"是":{"docs":{},"理":{"docs":{},"解":{"docs":{},"這":{"docs":{},"些":{"docs":{},"觀":{"docs":{},"念":{"docs":{},"是":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"，":{"docs":{},"許":{"docs":{},"多":{"docs":{},"人":{"docs":{},"會":{"docs":{},"在":{"docs":{},"使":{"docs":{},"用":{"docs":{},"複":{"docs":{},"雜":{"docs":{},"高":{"docs":{},"端":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"後":{"docs":{},"忘":{"docs":{},"記":{"docs":{},"這":{"docs":{},"些":{"docs":{},"基":{"docs":{},"本":{"docs":{},"觀":{"docs":{},"念":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"們":{"docs":{},"如":{"docs":{},"何":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"每":{"docs":{},"個":{"docs":{},"動":{"docs":{},"作":{"docs":{},"相":{"docs":{},"對":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"關":{"docs":{},"係":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"如":{"docs":{},"何":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"我":{"docs":{},"們":{"docs":{},"更":{"docs":{},"想":{"docs":{},"選":{"docs":{},"貪":{"docs":{},"婪":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"呢":{"docs":{},"？":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"果":{"docs":{},"我":{"docs":{},"們":{"docs":{},"假":{"docs":{},"設":{"docs":{},"，":{"docs":{},"你":{"docs":{},"可":{"docs":{},"以":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"到":{"docs":{},"這":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}},"這":{"docs":{},"不":{"docs":{},"代":{"docs":{},"表":{"docs":{},"代":{"docs":{},"理":{"docs":{},"人":{"docs":{},"本":{"docs":{},"身":{"docs":{},"不":{"docs":{},"能":{"docs":{},"有":{"docs":{},"一":{"docs":{},"個":{"docs":{},"內":{"docs":{},"在":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"計":{"docs":{},"算":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"理":{"docs":{},"可":{"docs":{},"不":{"docs":{},"可":{"docs":{},"以":{"docs":{},"從":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"出":{"docs":{},"「":{"docs":{},"下":{"docs":{},"一":{"docs":{},"張":{"docs":{},"牌":{"docs":{},"是":{"docs":{},"紅":{"docs":{},"心":{"docs":{},"q":{"docs":{},"」":{"docs":{},"？":{"docs":{},"當":{"docs":{},"然":{"docs":{},"可":{"docs":{},"以":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"不":{"docs":{},"能":{"docs":{},"超":{"docs":{},"過":{"docs":{},"過":{"docs":{},"去":{"docs":{},"所":{"docs":{},"有":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"的":{"docs":{},"歷":{"docs":{},"史":{"docs":{},"紀":{"docs":{},"錄":{"docs":{},"，":{"docs":{},"這":{"docs":{},"就":{"docs":{},"是":{"docs":{},"所":{"docs":{},"謂":{"docs":{},"的":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"（":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"k":{"docs":{},"o":{"docs":{},"v":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"又":{"docs":{},"或":{"docs":{},"者":{"docs":{},"反":{"docs":{},"過":{"docs":{},"來":{"docs":{},"說":{"docs":{},"，":{"docs":{},"你":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"對":{"docs":{},"環":{"docs":{},"境":{"docs":{},"不":{"docs":{},"做":{"docs":{},"任":{"docs":{},"何":{"docs":{},"假":{"docs":{},"設":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"給":{"docs":{},"值":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"飛":{"docs":{},"彈":{"docs":{},"發":{"docs":{},"射":{"docs":{},"後":{"docs":{},"的":{"docs":{},"當":{"docs":{},"前":{"docs":{},"座":{"docs":{},"標":{"docs":{},"與":{"docs":{},"速":{"docs":{},"度":{"docs":{},"，":{"docs":{},"總":{"docs":{},"結":{"docs":{},"了":{"docs":{},"過":{"docs":{},"去":{"docs":{},"從":{"docs":{},"發":{"docs":{},"射":{"docs":{},"到":{"docs":{},"現":{"docs":{},"在":{"docs":{},"的":{"docs":{},"飛":{"docs":{},"彈":{"docs":{},"飛":{"docs":{},"行":{"docs":{},"情":{"docs":{},"況":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"實":{"docs":{},"際":{"docs":{},"問":{"docs":{},"題":{"docs":{},"中":{"docs":{},"，":{"docs":{},"這":{"docs":{},"種":{"docs":{},"偏":{"docs":{},"誤":{"docs":{},"（":{"docs":{},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{},"s":{"docs":{},"）":{"docs":{},"不":{"docs":{},"一":{"docs":{},"定":{"docs":{},"不":{"docs":{},"好":{"docs":{},"，":{"docs":{},"有":{"docs":{},"時":{"docs":{},"候":{"docs":{},"也":{"docs":{},"是":{"docs":{},"非":{"docs":{},"常":{"docs":{},"有":{"docs":{},"幫":{"docs":{},"助":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"對":{"docs":{},"環":{"docs":{},"境":{"docs":{},"能":{"docs":{},"先":{"docs":{},"做":{"docs":{},"些":{"docs":{},"有":{"docs":{},"用":{"docs":{},"的":{"docs":{},"假":{"docs":{},"設":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"樂":{"docs":{},"觀":{"docs":{},"初":{"docs":{},"始":{"docs":{},"值":{"docs":{},"的":{"docs":{},"設":{"docs":{},"置":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":3.352201257861635}}}}}}}}}},"無":{"docs":{},"論":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}},"較":{"docs":{},"大":{"docs":{},"的":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}},"通":{"docs":{},"常":{"docs":{},"環":{"docs":{},"境":{"docs":{},"都":{"docs":{},"是":{"docs":{},"複":{"docs":{},"雜":{"docs":{},"且":{"docs":{},"不":{"docs":{},"確":{"docs":{},"定":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"在":{"docs":{},"前":{"docs":{},"期":{"docs":{},"鼓":{"docs":{},"勵":{"docs":{},"探":{"docs":{},"索":{"docs":{},"是":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"通":{"docs":{},"常":{"docs":{},"我":{"docs":{},"們":{"docs":{},"會":{"docs":{},"給":{"docs":{},"予":{"docs":{},"一":{"docs":{},"個":{"docs":{},"較":{"docs":{},"大":{"docs":{},"的":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"顯":{"docs":{},"得":{"docs":{},"較":{"docs":{},"不":{"docs":{},"重":{"docs":{},"要":{"docs":{},"。":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}}}}}}},"然":{"docs":{},"在":{"docs":{},"非":{"docs":{},"平":{"docs":{},"穩":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"，":{"docs":{},"q":{"docs":{},"_":{"1":{"docs":{"2-5-樂觀初始值的設置.html":{"ref":"2-5-樂觀初始值的設置.html","tf":0.018867924528301886}}},"docs":{}}}}}}}}}},"一":{"docs":{},"連":{"docs":{},"串":{"docs":{},"的":{"docs":{},"學":{"docs":{},"習":{"docs":{},"過":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"值":{"docs":{},"和":{"docs":{},"動":{"docs":{},"作":{"docs":{},"值":{"docs":{},"函":{"docs":{},"數":{"docs":{},"可":{"docs":{},"以":{"docs":{},"從":{"docs":{},"經":{"docs":{},"驗":{"docs":{},"中":{"docs":{},"進":{"docs":{},"行":{"docs":{},"估":{"docs":{},"計":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"當":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"非":{"docs":{},"常":{"docs":{},"多":{"docs":{},"的":{"docs":{},"時":{"docs":{},"候":{"docs":{},"，":{"docs":{},"每":{"docs":{},"個":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"都":{"docs":{},"十":{"docs":{},"分":{"docs":{},"稀":{"docs":{},"疏":{"docs":{},"，":{"docs":{},"用":{"docs":{},"平":{"docs":{},"均":{"docs":{},"來":{"docs":{},"計":{"docs":{},"算":{"docs":{},"就":{"docs":{},"顯":{"docs":{},"得":{"docs":{},"不":{"docs":{},"太":{"docs":{},"合":{"docs":{},"適":{"docs":{},"。":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},",":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}},"u":{"docs":{},"c":{"docs":{},"b":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}},"信":{"docs":{},"賴":{"docs":{},"區":{"docs":{},"間":{"docs":{},"上":{"docs":{},"緣":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.04}},"(":{"docs":{},"u":{"docs":{},"c":{"docs":{},"b":{"docs":{},")":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":3.333333333333333}}}}}}}}}}}}},"值":{"docs":{},"做":{"docs":{},"一":{"docs":{},"個":{"docs":{},"加":{"docs":{},"權":{"docs":{},"再":{"docs":{},"來":{"docs":{},"做":{"docs":{},"動":{"docs":{},"作":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}},"函":{"docs":{},"數":{"docs":{},"的":{"docs":{},"估":{"docs":{},"計":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}},"根":{"docs":{},"號":{"docs":{},"後":{"docs":{},"面":{"docs":{},"那":{"docs":{},"一":{"docs":{},"項":{"docs":{},"，":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"的":{"docs":{},"是":{"docs":{},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}},"據":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{},"前":{"docs":{},"一":{"docs":{},"章":{"docs":{},"探":{"docs":{},"討":{"docs":{},"到":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"能":{"docs":{},"會":{"docs":{},"犧":{"docs":{},"牲":{"docs":{},"短":{"docs":{},"期":{"docs":{},"可":{"docs":{},"能":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"來":{"docs":{},"換":{"docs":{},"取":{"docs":{},"長":{"docs":{},"期":{"docs":{},"可":{"docs":{},"以":{"docs":{},"累":{"docs":{},"積":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"機":{"docs":{},"會":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"每":{"docs":{},"次":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"的":{"docs":{},"不":{"docs":{},"確":{"docs":{},"定":{"docs":{},"性":{"docs":{},"。":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}},"說":{"docs":{},"明":{"docs":{},"你":{"docs":{},"沒":{"docs":{},"有":{"docs":{},"足":{"docs":{},"夠":{"docs":{},"的":{"docs":{},"信":{"docs":{},"心":{"docs":{},"可":{"docs":{},"以":{"docs":{},"認":{"docs":{},"為":{"docs":{},"動":{"docs":{},"作":{"docs":{"2-6-UCB-信賴區間上緣.html":{"ref":"2-6-UCB-信賴區間上緣.html","tf":0.02}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"表":{"docs":{},"示":{"docs":{},"成":{"docs":{},"：":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"h":{"docs":{},"_":{"1":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},"=":{"0":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"docs":{}}}}}},"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"_":{"docs":{},"t":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.028169014084507043}}}}}}},"+":{"1":{"docs":{},"(":{"docs":{},"a":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}},"_":{"docs":{},"t":{"docs":{},")":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}},"docs":{}}}},"y":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{},"s":{"docs":{},"）":{"docs":{},"：":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}},"參":{"docs":{},"數":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}},"否":{"docs":{},"則":{"docs":{},"偏":{"docs":{},"好":{"docs":{},"不":{"docs":{},"會":{"docs":{},"提":{"docs":{},"升":{"docs":{},"。":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}},"表":{"docs":{},"達":{"docs":{},"了":{"docs":{},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}},"選":{"docs":{},"擇":{"docs":{},"偏":{"docs":{},"好":{"docs":{},"把":{"docs":{},"動":{"docs":{},"作":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"用":{"docs":{},"機":{"docs":{},"率":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"透":{"docs":{},"過":{"docs":{},"或":{"docs":{},"波":{"docs":{},"茲":{"docs":{},"曼":{"docs":{},"分":{"docs":{},"布":{"docs":{},"（":{"docs":{},"b":{"docs":{},"o":{"docs":{},"l":{"docs":{},"t":{"docs":{},"z":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"n":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"與":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"演":{"docs":{},"算":{"docs":{},"法":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":3.3474178403755865}}}}}}}}}}}},"隨":{"docs":{},"機":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"上":{"docs":{},"升":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}},"頁":{"docs":{},"的":{"docs":{},"證":{"docs":{},"明":{"docs":{},"，":{"docs":{},"在":{"docs":{},"此":{"docs":{},"不":{"docs":{},"再":{"docs":{},"多":{"docs":{},"做":{"docs":{},"贅":{"docs":{},"述":{"docs":{},"。":{"docs":{"2-7-選擇偏好與梯度演算法.html":{"ref":"2-7-選擇偏好與梯度演算法.html","tf":0.014084507042253521}}}}}}}}}}}}}}}},"例":{"docs":{},"如":{"docs":{},"藍":{"docs":{},"色":{"docs":{},"機":{"docs":{},"台":{"docs":{},"的":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}},"一":{"docs":{},"個":{"docs":{},"機":{"docs":{},"器":{"docs":{},"人":{"docs":{},"除":{"docs":{},"了":{"docs":{},"他":{"docs":{},"本":{"docs":{},"身":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"配":{"docs":{},"置":{"docs":{},"在":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"的":{"docs":{},"傳":{"docs":{},"感":{"docs":{},"器":{"docs":{},"蒐":{"docs":{},"集":{"docs":{},"的":{"docs":{},"資":{"docs":{},"訊":{"docs":{},"，":{"docs":{},"顯":{"docs":{},"然":{"docs":{},"外":{"docs":{},"部":{"docs":{},"的":{"docs":{},"傳":{"docs":{},"感":{"docs":{},"器":{"docs":{},"不":{"docs":{},"屬":{"docs":{},"於":{"docs":{},"機":{"docs":{},"器":{"docs":{},"人":{"docs":{},"個":{"docs":{},"體":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"面":{"docs":{},"的":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"例":{"docs":{},"子":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"可":{"docs":{},"以":{"docs":{},"將":{"docs":{},"「":{"docs":{},"對":{"docs":{},"弈":{"docs":{},"的":{"docs":{},"主":{"docs":{},"控":{"docs":{},"權":{"docs":{},"」":{"docs":{},"當":{"docs":{},"作":{"docs":{},"是":{"docs":{},"代":{"docs":{},"理":{"docs":{},"主":{"docs":{},"觀":{"docs":{},"理":{"docs":{},"解":{"docs":{},"環":{"docs":{},"境":{"docs":{},"後":{"docs":{},"，":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"中":{"docs":{},"，":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"在":{"docs":{},"對":{"docs":{},"弈":{"docs":{},"中":{"docs":{},"的":{"docs":{},"主":{"docs":{},"控":{"docs":{},"權":{"docs":{},"是":{"docs":{},"贏":{"docs":{},"得":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"手":{"docs":{},"段":{"docs":{},"，":{"docs":{},"但":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"的":{"docs":{},"最":{"docs":{},"終":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"為":{"docs":{},"了":{"docs":{},"勝":{"docs":{},"利":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"說":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"考":{"docs":{},"慮":{"docs":{},"把":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"上":{"docs":{},"當":{"docs":{},"前":{"docs":{},"排":{"docs":{},"列":{"docs":{},"組":{"docs":{},"合":{"docs":{},"當":{"docs":{},"作":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"台":{"docs":{},"的":{"docs":{},"多":{"docs":{},"臂":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{},"和":{"docs":{},"採":{"docs":{},"取":{"docs":{},"的":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"編":{"docs":{},"號":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"關":{"docs":{},"係":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}},"，":{"docs":{},"你":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"必":{"docs":{},"須":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"拉":{"docs":{},"霸":{"docs":{},"機":{"docs":{},"前":{"docs":{},"做":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"，":{"docs":{},"並":{"docs":{},"且":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"之":{"docs":{},"後":{"docs":{},"要":{"docs":{},"再":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"拉":{"docs":{},"桿":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"始":{"docs":{},"終":{"docs":{},"給":{"docs":{},"予":{"docs":{},"零":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"你":{"docs":{},"能":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"到":{"docs":{},"這":{"docs":{},"些":{"docs":{},"線":{"docs":{},"索":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}},"策":{"docs":{},"略":{"docs":{},"（":{"docs":{},"p":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"y":{"docs":{},"）":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}},"能":{"docs":{},"給":{"docs":{},"予":{"docs":{},"最":{"docs":{},"大":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"、":{"docs":{},"紅":{"docs":{},"色":{"docs":{},"機":{"docs":{},"台":{"docs":{},"的":{"docs":{},"拉":{"docs":{},"桿":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}},"進":{"docs":{},"階":{"docs":{},"問":{"docs":{},"題":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}},"除":{"docs":{},"此":{"docs":{},"之":{"docs":{},"外":{"docs":{},"，":{"docs":{},"目":{"docs":{},"前":{"docs":{},"考":{"docs":{},"慮":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"只":{"docs":{},"會":{"docs":{},"對":{"docs":{},"當":{"docs":{},"前":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"產":{"docs":{},"生":{"docs":{},"影":{"docs":{},"響":{"docs":{},"，":{"docs":{},"但":{"docs":{},"如":{"docs":{},"果":{"docs":{},"行":{"docs":{},"為":{"docs":{},"會":{"docs":{},"對":{"docs":{},"後":{"docs":{},"續":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"報":{"docs":{},"酬":{"docs":{},"產":{"docs":{},"生":{"docs":{},"影":{"docs":{},"響":{"docs":{},"，":{"docs":{},"那":{"docs":{},"問":{"docs":{},"題":{"docs":{},"也":{"docs":{},"會":{"docs":{},"更":{"docs":{},"為":{"docs":{},"複":{"docs":{},"雜":{"docs":{},"。":{"docs":{"2-8-關聯搜索.html":{"ref":"2-8-關聯搜索.html","tf":0.03333333333333333}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"\\":{"docs":{},"i":{"docs":{},"n":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.058823529411764705}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"l":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176},"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"{":{"docs":{},"k":{"docs":{},"=":{"0":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"}":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}},"docs":{}}}}}}}}},"【":{"docs":{},"這":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"代":{"docs":{},"理":{"docs":{},"可":{"docs":{},"以":{"docs":{},"知":{"docs":{},"道":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"隨":{"docs":{},"機":{"docs":{},"程":{"docs":{},"度":{"docs":{},"，":{"docs":{},"卻":{"docs":{},"無":{"docs":{},"法":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"他":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{},"】":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"介":{"docs":{},"面":{"docs":{},"的":{"docs":{},"靈":{"docs":{},"活":{"docs":{},"性":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}},"前":{"docs":{},"述":{"docs":{},"的":{"docs":{},"基":{"docs":{},"礎":{"docs":{},"定":{"docs":{},"義":{"docs":{},"給":{"docs":{},"予":{"docs":{},"我":{"docs":{},"們":{"docs":{},"一":{"docs":{},"個":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"框":{"docs":{},"架":{"docs":{},"，":{"docs":{},"這":{"docs":{},"個":{"docs":{},"框":{"docs":{},"架":{"docs":{},"是":{"docs":{},"非":{"docs":{},"常":{"docs":{},"靈":{"docs":{},"活":{"docs":{},"且":{"docs":{},"抽":{"docs":{},"象":{"docs":{},"的":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"應":{"docs":{},"用":{"docs":{},"到":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"問":{"docs":{},"題":{"docs":{},"裡":{"docs":{},"面":{"docs":{},"。":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"章":{"docs":{},"打":{"docs":{},"過":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}}},"定":{"docs":{},"義":{"docs":{},"：":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"靈":{"docs":{},"活":{"docs":{},"性":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}},"底":{"docs":{},"下":{"docs":{},"是":{"docs":{},"代":{"docs":{},"理":{"docs":{},"環":{"docs":{},"境":{"docs":{},"介":{"docs":{},"面":{"docs":{},"的":{"docs":{},"示":{"docs":{},"意":{"docs":{},"圖":{"docs":{},"：":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"在":{"docs":{},"時":{"docs":{},"點":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}},"每":{"docs":{},"個":{"docs":{},"回":{"docs":{},"合":{"docs":{},"中":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"從":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"到":{"docs":{},"動":{"docs":{},"作":{"docs":{},"的":{"docs":{},"選":{"docs":{},"擇":{"docs":{},"過":{"docs":{},"程":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"一":{"docs":{},"個":{"docs":{},"機":{"docs":{},"率":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"被":{"docs":{},"稱":{"docs":{},"為":{"docs":{},"策":{"docs":{},"略":{"docs":{},"（":{"docs":{},"p":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"y":{"docs":{},"）":{"docs":{},"並":{"docs":{},"寫":{"docs":{},"成":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"輪":{"docs":{},"的":{"docs":{},"結":{"docs":{},"果":{"docs":{},"彼":{"docs":{},"此":{"docs":{},"都":{"docs":{},"是":{"docs":{},"無":{"docs":{},"關":{"docs":{},"，":{"docs":{},"只":{"docs":{},"有":{"docs":{},"累":{"docs":{},"積":{"docs":{},"下":{"docs":{},"來":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"會":{"docs":{},"被":{"docs":{},"保":{"docs":{},"存":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"輪":{"docs":{},"繼":{"docs":{},"續":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"狀":{"docs":{},"態":{"docs":{},"、":{"docs":{},"動":{"docs":{},"作":{"docs":{},"與":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"定":{"docs":{},"義":{"docs":{},"了":{"docs":{},"界":{"docs":{},"限":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"任":{"docs":{},"何":{"docs":{},"有":{"docs":{},"用":{"docs":{},"的":{"docs":{},"資":{"docs":{},"訊":{"docs":{},"：":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"由":{"docs":{},"於":{"docs":{},"是":{"docs":{},"從":{"docs":{},"環":{"docs":{},"境":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"資":{"docs":{},"訊":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"可":{"docs":{},"以":{"docs":{},"細":{"docs":{},"粒":{"docs":{},"度":{"docs":{},"的":{"docs":{},"去":{"docs":{},"規":{"docs":{},"範":{"docs":{},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"內":{"docs":{},"容":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"獎":{"docs":{},"勵":{"docs":{},"的":{"docs":{},"外":{"docs":{},"部":{"docs":{},"性":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}},"首":{"docs":{},"先":{"docs":{},"我":{"docs":{},"們":{"docs":{},"先":{"docs":{},"認":{"docs":{},"識":{"docs":{},"到":{"docs":{},"，":{"docs":{},"由":{"docs":{},"於":{"docs":{},"代":{"docs":{},"理":{"docs":{},"與":{"docs":{},"環":{"docs":{},"境":{"docs":{},"之":{"docs":{},"間":{"docs":{},"是":{"docs":{},"互":{"docs":{},"相":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"彼":{"docs":{},"此":{"docs":{},"互":{"docs":{},"相":{"docs":{},"的":{"docs":{},"影":{"docs":{},"響":{"docs":{},"是":{"docs":{},"以":{"docs":{},"離":{"docs":{},"散":{"docs":{},"時":{"docs":{},"間":{"docs":{},"表":{"docs":{},"達":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"說":{"docs":{},"：":{"docs":{"3-1-代理與環境的界限.html":{"ref":"3-1-代理與環境的界限.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"區":{"docs":{},"分":{"docs":{},"學":{"docs":{},"習":{"docs":{},"目":{"docs":{},"的":{"docs":{},"與":{"docs":{},"方":{"docs":{},"法":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}},"或":{"docs":{},"是":{"docs":{},"在":{"docs":{},"棋":{"docs":{},"盤":{"docs":{},"遊":{"docs":{},"戲":{"docs":{},"中":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"輸":{"docs":{},"掉":{"docs":{},"一":{"docs":{},"盤":{"docs":{},"棋":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"記":{"docs":{},"為":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}},"簡":{"docs":{},"言":{"docs":{},"之":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"就":{"docs":{},"是":{"docs":{},"要":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"他":{"docs":{},"能":{"docs":{},"收":{"docs":{},"到":{"docs":{},"的":{"docs":{},"總":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"己":{"docs":{},"定":{"docs":{},"義":{"docs":{},"的":{"docs":{},"內":{"docs":{},"在":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"環":{"docs":{},"境":{"docs":{},"給":{"docs":{},"予":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"依":{"docs":{},"舊":{"docs":{},"是":{"docs":{},"從":{"docs":{},"勝":{"docs":{},"負":{"docs":{},"計":{"docs":{},"算":{"docs":{},"而":{"docs":{},"得":{"docs":{},"，":{"docs":{},"代":{"docs":{},"理":{"docs":{},"依":{"docs":{},"舊":{"docs":{},"要":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"環":{"docs":{},"境":{"docs":{},"反":{"docs":{},"饋":{"docs":{},"得":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"。":{"docs":{"3-2-目標與獎勵.html":{"ref":"3-2-目標與獎勵.html","tf":0.03125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"且":{"docs":{},"一":{"docs":{},"旦":{"docs":{},"學":{"docs":{},"習":{"docs":{},"過":{"docs":{},"程":{"docs":{},"抵":{"docs":{},"達":{"docs":{},"後":{"docs":{},"就":{"docs":{},"停":{"docs":{},"止":{"docs":{},"的":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"則":{"docs":{},"稱":{"docs":{},"作":{"docs":{},"情":{"docs":{},"境":{"docs":{},"性":{"docs":{},"任":{"docs":{},"務":{"docs":{},"（":{"docs":{},"e":{"docs":{},"p":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"d":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"像":{"docs":{},"這":{"docs":{},"樣":{"docs":{},"有":{"docs":{},"一":{"docs":{},"個":{"docs":{},"最":{"docs":{},"終":{"docs":{},"時":{"docs":{},"點":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}}}}},"回":{"docs":{},"報":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":3.3487179487179484}}}},"持":{"docs":{},"續":{"docs":{},"性":{"docs":{},"任":{"docs":{},"務":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}},"用":{"docs":{},"數":{"docs":{},"學":{"docs":{},"表":{"docs":{},"示":{"docs":{},"為":{"docs":{},"：":{"docs":{"3-3-回報.html":{"ref":"3-3-回報.html","tf":0.015384615384615385}}}}}}}}},",":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}},"|":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.02702702702702703}}},"依":{"docs":{},"據":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"為":{"docs":{},"基":{"docs":{},"礎":{"docs":{},"所":{"docs":{},"設":{"docs":{},"計":{"docs":{},"的":{"docs":{},"各":{"docs":{},"種":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"演":{"docs":{},"算":{"docs":{},"法":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"一":{"docs":{},"定":{"docs":{},"程":{"docs":{},"度":{"docs":{},"去":{"docs":{},"使":{"docs":{},"用":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"想":{"docs":{},"當":{"docs":{},"然":{"docs":{},"爾":{"docs":{},"，":{"docs":{},"真":{"docs":{},"實":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"和":{"docs":{},"動":{"docs":{},"作":{"docs":{},"之":{"docs":{},"間":{"docs":{},"的":{"docs":{},"關":{"docs":{},"係":{"docs":{},"，":{"docs":{},"不":{"docs":{},"可":{"docs":{},"能":{"docs":{},"完":{"docs":{},"全":{"docs":{},"只":{"docs":{},"取":{"docs":{},"決":{"docs":{},"於":{"docs":{},"前":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{},"與":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"接":{"docs":{},"下":{"docs":{},"來":{"docs":{},"我":{"docs":{},"們":{"docs":{},"並":{"docs":{},"不":{"docs":{},"會":{"docs":{},"討":{"docs":{},"論":{"docs":{},"怎":{"docs":{},"麼":{"docs":{},"從":{"docs":{},"環":{"docs":{},"境":{"docs":{},"中":{"docs":{},"觀":{"docs":{},"察":{"docs":{},"和":{"docs":{},"設":{"docs":{},"計":{"docs":{},"出":{"docs":{},"合":{"docs":{},"理":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}},"會":{"docs":{},"說":{"docs":{},"明":{"docs":{},"增":{"docs":{},"強":{"docs":{},"學":{"docs":{},"習":{"docs":{},"中":{"docs":{},"的":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"如":{"docs":{},"何":{"docs":{},"表":{"docs":{},"示":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"節":{"docs":{},"會":{"docs":{},"來":{"docs":{},"討":{"docs":{},"一":{"docs":{},"種":{"docs":{},"特":{"docs":{},"別":{"docs":{},"有":{"docs":{},"意":{"docs":{},"義":{"docs":{},"的":{"docs":{},"狀":{"docs":{},"態":{"docs":{},"，":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{},"（":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"k":{"docs":{},"o":{"docs":{},"v":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"棋":{"docs":{},"盤":{"docs":{},"上":{"docs":{},"當":{"docs":{},"前":{"docs":{},"的":{"docs":{},"排":{"docs":{},"列":{"docs":{},"組":{"docs":{},"合":{"docs":{},"，":{"docs":{},"總":{"docs":{},"結":{"docs":{},"了":{"docs":{},"過":{"docs":{},"去":{"docs":{},"每":{"docs":{},"一":{"docs":{},"回":{"docs":{},"合":{"docs":{},"的":{"docs":{},"彼":{"docs":{},"此":{"docs":{},"下":{"docs":{},"棋":{"docs":{},"的":{"docs":{},"結":{"docs":{},"果":{"docs":{},"。":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"環":{"docs":{},"境":{"docs":{},"狀":{"docs":{},"態":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}},"真":{"docs":{},"實":{"docs":{},"環":{"docs":{},"境":{"docs":{},"的":{"docs":{},"近":{"docs":{},"似":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}},"要":{"docs":{},"避":{"docs":{},"免":{"docs":{},"這":{"docs":{},"個":{"docs":{},"問":{"docs":{},"題":{"docs":{},"的":{"docs":{},"話":{"docs":{},"，":{"docs":{},"我":{"docs":{},"們":{"docs":{},"傾":{"docs":{},"向":{"docs":{},"於":{"docs":{},"讓":{"docs":{},"代":{"docs":{},"理":{"docs":{},"能":{"docs":{},"察":{"docs":{},"覺":{"docs":{},"到":{"docs":{},"當":{"docs":{},"前":{"docs":{},"環":{"docs":{},"境":{"docs":{},"訊":{"docs":{},"息":{"docs":{},"，":{"docs":{},"然":{"docs":{},"後":{"docs":{},"立":{"docs":{},"刻":{"docs":{},"忘":{"docs":{},"記":{"docs":{},"他":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":0.013513513513513514}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"馬":{"docs":{},"可":{"docs":{},"夫":{"docs":{},"性":{"docs":{},"質":{"docs":{"3-4-馬可夫性質.html":{"ref":"3-4-馬可夫性質.html","tf":3.3603603603603602}}}},"決":{"docs":{},"策":{"docs":{},"過":{"docs":{},"程":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":3.3603603603603602}}}}}}}}},"他":{"docs":{},"幾":{"docs":{},"乎":{"docs":{},"是":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703}}}}}},"採":{"docs":{},"取":{"docs":{},"動":{"docs":{},"作":{"docs":{"3-5-馬可夫決策過程.html":{"ref":"3-5-馬可夫決策過程.html","tf":0.02702702702702703},"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"）":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}},"v":{"docs":{},"_":{"docs":{},"p":{"docs":{},"i":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.04}}}}}}}},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.02666666666666667}}}}}},"下":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"動":{"docs":{},"作":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}},"根":{"docs":{},"據":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}},"獲":{"docs":{},"得":{"docs":{},"的":{"docs":{},"獎":{"docs":{},"勵":{"docs":{},"平":{"docs":{},"均":{"docs":{},"值":{"docs":{},"會":{"docs":{},"收":{"docs":{},"斂":{"docs":{},"到":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}},"和":{"docs":{},"動":{"docs":{},"作":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}},"正":{"docs":{},"如":{"docs":{},"我":{"docs":{},"們":{"docs":{},"在":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}},"考":{"docs":{},"慮":{"docs":{},"一":{"docs":{},"個":{"docs":{},"策":{"docs":{},"略":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}},"貝":{"docs":{},"爾":{"docs":{},"曼":{"docs":{},"方":{"docs":{},"程":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}},"（":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{"3-6-動作值函數.html":{"ref":"3-6-動作值函數.html","tf":0.013333333333333334}}}}}}}}}}}}}}}},"length":771},"corpusTokens":["&","(","(1","(1/n)[","(s,a)","(sampl","(stochast","(ucb)","(upper",")","*","+","+1",",","...","/","0","1","1,","1/n","1000","2","2，而選擇到紅色機台時不要選擇拉桿","3","39","4","41","5","6","7","8","90%","=",">",">inf","@fatfingererr","[","[alpha_n(a)]^2","\\in","\\real","\\sum_{k=0}^{inf}","]","a(s_t)","a)","a\\ina(s)","a_0,","a_t","a_t=a)","a_t=argmax_a(q_t(a))","action","alpha","alpha(r_t","alpha)^(n","alpha)^n","alpha_n(a)","argmax_a(q_t(a)+c*\\sqrt(log_t","ascent,","averag","average)","average）：","avg_r_t","avg_r_t)(","avg_r_t)*pi_t(a)","bound,","c","case","confid","decis","distribution）表示成：","e(r|a=a)","e^(h_t(a))/(sum(b=1)(k){e^(h_t(b))})","e_pi","e_pi(g_t|s_t=s)","epsilon","equation）","exploit","explor","exploration）係數，而整項的公式則叫做信賴區間上緣。","function","function）","g_t","gamma","gamma=0","gamma^2","gamma^k","gradient","greedi","h_1(a)=0","h_t(a)","h_t(a_t)","h_t+1(a)","h_t+1(a_t)","hypothesis）：","i)","independent）。","inf","introduction〉","issu","k","learning:","log_t","make","mdp","mdp）","method","n","n_t(a)","n_t(a)))","newestim","next","nonstationari","oldestim","optim","p(","p(s',r|s,a)","p(s',r|s,a)=p(s_t+1","p(s'|s,a)=p(s_t+1=s'|s_t=s,a_t=a)","p(s_t+1=s',","p_r(a_t","pairs）","part1","part2","pi","pi(a|s)","pi_t","pi_t(a)","pi_t(a_t))","pi_t(a|s)","pi）","polici","process,","property）","q","q(a)","q*","q*(a)","q_1","q_n","q_n+1","q_pi","q_pi(s,a)","q_pi(s,a)=e_pi(g_t|s_t=s,at=a)","q_t(a)","q_t(a_t)=max_a(q_t(a))","r","r(s,a)=e(r_t+1|s_t=s,","r(s,a,s')=e(r_t+1|s_t=s,a_t=a,s_t+1=s')=","r_1","r_1,","r_2","r_i","r_n","r_t","r_t+1","r_t+1=r","r_t+2","r_t+3","r_t+k+1","r_t,","rate），他決定了未來各時點的回報對於現在時點的價值。","return）","reward","reward）為","s","s',","s,","s_0,","s_t","s_t+1","s_t,","sga)","size","state","step","stepsiz","stepsize=1/n","studi","sum(i=1)(n){","sum(n=1)(inf)","t","t+1","t=0,1,2,3...","tasks）","tasks）的範疇。","task），這個任務可以被簡化到極致，變成三個子任務：","tbd:","triples）重寫我們的預期獎勵，並且將預期獎勵的條件期望值展開為：","ucb)","v_pi","v_pi(s)","valu","weight","|","}","。","「利用」行為能最大化你的預期報酬，使你盡可能地提高你每個行為給予的回饋。","【這很重要，例如代理可以知道環境給予的獎勵的隨機程度，卻無法最大化他的獎勵。】","一個簡單的平均報酬計算方法，就是透過每一次採取該動作之後的總報酬，除以採取該動作的總次數。","上式中的","上式的操作就是所謂的","下不同的動作","下根據策略","下獲得的獎勵平均值會收斂到","不會受制於初始的","不會收斂，可能代表不同的動作個別有各自的動作值函數。","不確定性","且一旦學習過程抵達後就停止的，我們則稱作情境性任務（episod","並不能用此來代表，你就很有信心這個動作是不值得被採取的（因為","並且在盡可能多的動作上面進行探索，使得最後就算開始不斷的做貪婪動作，也有足夠的探索。","並且得到獎勵","並且接收到新一回合的環境資訊","並在動作執行後的時間，接收動作產生的獎勵，稱做","中提到的動作值方法，我們關心的是採取每個動作帶給我們的價值為何","中被隱藏了起來。","中，我們會定義","之前的總報酬平均。","之前，你並未採取任何動作，也就是說","之間。","也可以寫作：","也因此","也就是你相信應該根據環境的變化，採取對應的動作，不會有哪個動作值得一直執行","也就是說我們要做的是去學習如何在特定情境中，做出符合該情境的最佳動作。","也就是說樂觀初始值的設置方法，並非是一個很有用的一般性提升探索行為的技巧。","也就是說每個動作的期望報酬都是存在。","也就是說越久以前所獲得的報酬，對於當前採取的動作能參考的價值越小。","也就是說，在遵守策略","也就是說，我們不能說代理處於「下一張牌是紅心q」的狀態。","也就是說，我們可以假定一個很小的機率","也就是說，我們在","也就是說，我們都沒有考慮的動作與環境之間可能有所關聯，並且面對特定環境可能存在特定動作能獲得最大報酬。","也就是說，當","也就是說，當你用常數的","事實上多數問題面對的環境，是會不斷變化，這樣前面討論的內容就會不太適用。","什麼時候應該使用","介面的靈活性","他幾乎是","代理人的內在獎勵","代理可以從環境去歸納、學習，但我們定義的狀態不能直接保證未來特定情況會發生。","代理可以採取什麼行為（動作）","代理可以透過自己學習到的經驗改變其策略，基本的學習目標就是在長期能獲得最大的總獎勵。","代理如何理解環境（狀態）","代理如何知道學習目標（獎勵）","代理很有可能能理解環境如何給予他獎勵，但仍舊無法最大化他的獎勵。","代理接收到一些環境資訊，用狀態（state）表示為","代理環境交互示意圖","代理的目標就是要最大化本身的期望獎勵，進而能使其本身累積到最高的總獎勵","代理的目標是去掌握環境給予獎勵的規則，在每個學習回合中，獎勵是一個數字","代理與環境之間的界限，並不是以代理和環境本身的物理邊界做區隔。","代理與環境介面","代理與環境的界限","代表代理在狀態","代表在第","但不能超過過去所有訊息的歷史紀錄，這就是所謂的馬可夫性質（markov","但是代理可不可以從環境中觀察出「下一張牌是紅心q」？當然可以。","但是如果我們假設，你可以獲得到這","但是我們如何衡量每個動作相對之間的關係呢？如何衡量我們更想選貪婪選擇呢？","但是理解這些觀念是很重要的，許多人會在使用複雜高端的模型後忘記這些基本觀念。","但是這不代表代理人本身不能有一個內在獎勵的計算方式。","你也可以注意到，我們是用「代理」這個詞，意思就是它可以是不屬於代理個體本身的其他元件。","你如何在這","你就可以學習到一個策略，在選擇到藍色機台時選擇拉桿","你某種程度就放棄認為你採取的每個動作都會有一個對應的期望報酬","你現在有","使得所有動作的初始選擇偏好相同。","使得行為有機會隨機選擇非貪婪的其他動作。","來得適合。","來表示。","來面對非平穩問題時","例如一個機器人除了他本身，也可以接收到配置在環境中的傳感器蒐集的資訊，顯然外部的傳感器不屬於機器人個體。","例如前面的棋盤遊戲例子中，我們可以將「對弈的主控權」當作是代理主觀理解環境後，","例如在棋盤遊戲中，獲得在對弈中的主控權是贏得遊戲的重要手段，但遊戲的最終目的是為了勝利。","例如藍色機台的拉桿","例如說棋盤遊戲中，我們考慮把棋盤上當前排列組合當作狀態。","依據馬可夫性質為基礎所設計的各種增強學習演算法，也就可以在一定程度去使用","信賴區間上緣","信賴區間上緣(ucb)","個拉桿的拉霸機，每當你拉下其中一個拉桿的時候，拉霸機就會給你一串數字。","值做一個加權再來做動作選擇。","值函數的估計","假如你不採取一個能得到更高期望報酬的動作，而採取任何一個其他動作，都屬於非貪婪（nongreedy）動作。","假如我們定義獎勵是以對弈中的主控權表示，最大化獎勵就變成最大化自己的主控權。","假如我們能知道每個拉桿的期望報酬，對於","假如狀態和能採取的動作是離散有限的，也被稱作有限馬可夫決策過程（finit","假如現在在","假設你面前擺著有","假設我們面對","假設拉桿","做一點加成，作為每次行為選擇的參考。","做表示。","像這樣有一個最終時點","其中","其中我們稱","其中的","函數則為每個動作","利用與探索","到","則在","則會讓代理只關注下期回報，忽略未來的所有可能回報。","前一章打過","前述的基礎定義給予我們一個增強學習框架，這個框架是非常靈活且抽象的，可以用不同的方式應用到不同的問題裡面。","動作值函數","動作值方法","動作選擇的抽象程度：代理可以根據基礎的條件動作，也可以根據定義的高級抽象狀態條件採取行為","動態","區分學習目的與方法","參數","又或是飛彈發射後的當前座標與速度，總結了過去從發射到現在的飛彈飛行情況。","又或者反過來說，你也可以對環境不做任何假設，使得給值","反之，如果採取不同動作的報酬變異數接近","反饋不一定要有外顯影響：當環境給予代理反饋時，代理可以是內在性的調整（例如修正選擇機率）","可以看成是我們在上一回合的估計誤差（error）。","可以表示成：","可能也很小）","台的多臂拉霸機和採取的拉桿編號之間的關係。","台的多臂拉霸機，你每一次必須在不同的拉霸機前做選擇，並且選擇之後要再選擇拉桿。","同時棋盤上當前的排列組合，沒有對未來可能發生的特定情況做出任何保證。","同時這個方法也被稱作","同時飛彈當前的座標與速度，也沒有保證未來飛彈可能落於任何地方的保證。","同樣的道理，假設在這個狀態","同樣的，這邊我們可以發現這一項對於非平穩問題仍舊不會有太有幫助。","否則偏好不會提升。","告知和指教","呢？","和動作","回報","因此假如我們令","因此我們再一次地透過「狀態－動作－下次狀態」元組（state","因此我們在增強學習中，迎來了第一個假設，也就是獎勵獎設（reward","因此我們就更往前一步，從平穩問題到非平穩問題，從非關聯性的處理到關聯搜索。","因此我們要引入一個觀念，也就是選擇偏好（preference）h_t(a)","因此這邊我們會引入一個概念，叫做折扣（discount）也就是說，對於持續性任務而言，我們是要最大化我們的折扣回報（discount","因此馬可夫性質只是一種逼近、近似的方法，也不是增強學習唯一的近似方法","因此，我們會先假設每個拉桿會給予我們個別的【期望報酬】，用","因為代理不能從環境中的狀態，直接推論出下一張牌是什麼。","因為你可以使用部分時間進行「探索」，並在最後的時間發現一個更高的總報酬。","因為你始終可以拉動有","因為你抱持一個「樂觀」態度開始，對學習有較高的期待。","因為你正在利用你學習到的知識，進而採取一個能得到最直接與你有利的結果。","因為原本我們使用的","因為在非平穩問題中，每一次採取相同的動作而得到的報酬，並不能等同而論。","因為獎勵的高低變化的規則與邏輯，不能被代理任意的改變與調整，這才能定義成代理需要學習的任務。","圖","在","在「利用」與「探索」之間，這兩者是有著根本性的矛盾問題，你無法充分同好這兩件事。","在一般的增強學習任務之中，我們面對的就是多元變化的情境，因此我們的真正目標是去學習一種","在下一回合的","在代理—環境的增強學習框架中，代理會根據環境的狀態來選擇動作。","在前一節我們提到，獎勵應該是屬於代理外部的環境範疇。","在前一節我們談到了動作值","在前面","在動態的練習過程中，每一回合勢必都會有個動作，會對應到最高的期望報酬。","在增強學習理論中，學習與動作決策者被稱作代理（agent）而與代理互動的其他的事物，都被稱作環境（environment）代理選擇的動作會影響環境，而環境會給予代理獎勵，代理嘗試最大化獲得的獎勵則稱為學習（learning），因此如何完整規範環境，並且定義一個學習任務，增強學習就必須先給予一個基礎框架。","在定義獎勵的時候，務必留意我們是要讓代理學習如何實現學習目標，而不是僅僅為了獲得最高獎勵。","在實際應用中，我們往往是透過定義狀態、動作與獎勵之後，就確定了代理與環境之間的界限，因此就確定了一個決策任務（decis","在模擬的環境中，獎勵的計算方法可以透過一些系統性的定義來做計算，但是他仍舊屬於環境範疇。","在此僅針對該書中的","在每一回合我們得到新的行為","在每次離散時間","在狀態","在給定的狀態","在這一章，我們將會從最基本的學習問題開始討論，最後連結到","增強學習。","多台多臂拉霸機","多臂拉霸機","多臂拉霸機的學習問題","如何定義環境給予的獎勵，在增強學習中給予很大的操作空間，這也是增強學習理論的特徵之一。","如果一個環境狀態是具有馬可夫性質的，意思就是說","如果在越長的時間（log_t","如果您對本專案有興趣或疑問，歡迎提","如果我們說增強學習任務是滿足馬可夫性質的話，這個學習任務就被叫做馬可夫決策過程（markov","如果我們說狀態具有馬可夫性質的話，那上式可以寫成","始終給予零報酬，假如你能觀察到這些線索。","定義獎勵的靈活性","定義：策略","容易中獎，代表拉動拉桿","實際問題中，這種偏誤（bias）不一定不好，有時候也是非常有幫助，如果你對環境能先做些有用的假設。","對你來說，每一回合所採取的動作，和你獲得的報酬之間的關係變得更為複雜。","對應的價值函數，簡稱動作值函數。","對於某個特定動作","對於狀態值函數的估計，可以看成是遵守策略","對於這個第","就是所謂的折扣率（discount","就是未來所有時點獲得的獎勵總和。","就會比","就能知道所有動作的真實價值。","常數","常數，介在","底下是代理環境介面的示意圖：","很合理的可以發現，會隨時間變化的環境，更重要的是如何把握當前的可能獲得的報酬。","很大時，我們會需要很多的資源空間存放前","很大程度取決於初始動作值的估計，也就是","很簡單一個想法就是，如果存在一個動作","後續將會開始介紹許多數學方法，來幫助我們決定如何採取更合適的行為，以達到更好的學習成果。","想當然爾，真實環境中的狀態和動作之間的關係，不可能完全只取決於前一回合的動作與狀態。","意思是：","我們可以舉機器人走迷宮的例子，如果機器人要走出迷宮，我們可以定義每一步獎勵都要","我們在此將這種遞增式的算法實作，表達成一個更廣義的通式：","我們已經做過了","我們已經知道貪婪行為是目前看起來最好的決策選擇方式，我們也知道不能一直貪婪。","我們已經知道這個價值可以用預期獎勵來表示，現在我們要為每一個策略定義動作值函數","我們接著會來嘗試評估採取一個動作的價值，正如前面所提到，動作的正確評估來自於採取該動作之後獲取的平均報酬。","我們有一個方法來更新我們的偏好","我們能根據當前的環境狀態和行動來選擇動作，並預期我們下一個狀態和獎勵為何。","或是在棋盤遊戲中，如果輸掉一盤棋獎勵記為","所以一種更好的方法，就是對於非貪婪的其他選擇，做一點挑選或處理。","所以可能有一個動作在很長時間沒有被選取，但單純只是因為當時的環境不適合採取該動作。","所以如何將你的學習目標，切割成環境反饋的獎勵和代理內在的獎勵，是處理代理與環境界限的重要問題。","所以對於","所以我們很清楚可能","所以我們必須先了解，狀態（state）不可以對未來的訊息作保證。","所以我們理想的狀態設計原則，應該是他能總結過去觀察到的環境訊息，","所以我們能選到最佳動作的機率是大於","所以這才是我們需要一個更進階且完備的數學理論去處理他，因為我們必須時時刻刻去平衡探索與利用之間的問題。","才會發現這件事情，所以我們的期望報酬可以表達成：","持續性任務","指的是在時點","採取動作","探索與利用之間的平衡","接下來我們並不會討論怎麼從環境中觀察和設計出合理的狀態","接下來我們會說明增強學習中的馬可夫性質如何表示","換個角度來說，你也可能因為探索而做白工，因為你每次只能選擇一個動作，做錯一步都是浪費。","換句話說，剛開始的每一回合的學習得到的反饋，都會使你「失望」。","換句話說，環境都可能潛藏各種能揭露未來的訊息，但是我們不能將其設計為一種狀態","既然無法充分做好這兩件事，我們可以試著在這兩者之間進行一個權衡。","是","是一個探索度（degre","是一個需要先驗給定的。","是一種動作值函數的估計。","是不值得採取的，因此我們對他的原始","是常數還是變數，我們都可以從上式發現一件事。","是從狀態","是最終的總獎勵，而","是策略","是鼓勵探索行為的。","時我們的動作值函數能正確的逼近每個動作的期望報酬。","時接收到的環境狀態","時間間隔的自由度：沒有要求離散時間時點之間的相隔","時點前採取動作","時點前的採取動作","時點採取動作","時點採取的動作","時點選擇動作","時點，我們可以選擇動作","時，代理越會把未來的回報看得和下一期回報一樣重要，更重視未來的可能獎勵。","時，遵守策略","最基本的界線判斷就是，代理人無法依照自己想要的規則改變的事物，就屬於其外部。","最常用的方法之一，就是定義","最後會收斂到","最高期望報酬","會使得學習剛開始的過程中，前期的","會很小，而","會收斂到動作值函數","會更好一點，但是強迫一個隨機機率採取非貪婪的行為，似乎也不太有道理。","會為我們帶來較高的期望報酬。","會符合：","會變成一個過往獲得報酬的指數加權平均（exponeti","會讓上式存在一個固定的數值，而","會隨著","有時候我們可以在每一回合動態調整我們的","有時候我們定義的代理環境框架中，可以不設定一個最終時點","有興趣者請自行閱讀","有限馬可夫過程對於增強學習理論來說十分的重要","期望報酬","本節會來討一種特別有意義的狀態，叫做馬可夫性質（markov","根據","根據我們在前一章探討到的問題，我們可能會犧牲短期可能獲得的獎勵，來換取長期可以累積更高的總獎勵的機會。","根號後面那一項，衡量的是採取動作","棋盤上當前的排列組合，總結了過去每一回合的彼此下棋的結果。","樂觀初始值的設置","樣本平均法","次來計算觀察到的平均報酬：","次動作。","次採取動作","次是否要做，我們可以透過前","次的每次報酬才能計算平均報酬。","次盡己所能，在看似隨機的問題上面做最充分的準備？","次練習之後將迎來正式的賭博機會。","次練習的機會，在","次，接著要評估是否適合採取第","正如我們在","此外，以狀態動作對來重新描述預期獎勵（expect","此外，先掌握馬可夫性質與相關演算法之後，是往非馬可夫性質的增強學習建模的基礎","此時如果你有很多時間可以不斷嘗試的話，你就可以對於要採取貪婪或非貪婪有更多的信心。","此時就是說明你正在探索更多可能，這個行為也被稱作「探索（exploring）」。","每一輪的結果彼此都是無關，只有累積下來的策略會被保存到下一輪繼續使用。","每個回合中，代理從狀態到動作的選擇過程，可以用一個機率表示，被稱為策略（policy）並寫成","為","為一個常數。","為了使得近似能更精確，所以我們必須充分的提供環境中的可能的狀態訊息，","為了數學表示上的方便，在此我們先考慮環境有限的狀態和獎勵","為了達到這個目的，我們會在本節中對狀態做一些限制與規範","為動作值函數（action","為所有代理能接收到的環境資訊集合，並且在此基礎上選擇一個動作","為整體所有動作在時點","為狀態動作對（state","無論","然後調整參數來產生正確的估計，這很大程度取決於我們參數化的方式","然而「探索」行為可能會帶給你更大的總報酬，從長遠來說也可能是更值得嘗試的動作。","然而如果一個固定的狀態下，v_pi(s)","然而真實世界中，我們採取的每個動作其中的真實價值往往會隨時間而改變。","然而這樣子總報酬可能會趨近於正負無限大，我們希望最大總獎勵就算在持續任務中，應該也要能收斂到一個數值。","然而隨著時間變化，真實世界中的環境往往會隨著你的動作而有所更新，也就是說環境中的情境可能不只一種。","特別紀錄筆記","狀態、動作與獎勵，定義了界限","狀態可以是任何有用的資訊：狀態由於是從環境得到的資訊，因此可以細粒度的去規範獲得的狀態內容","獎勵的外部性","現代增強學習理論的基礎","現在我們要來進一步討論，我們如何對樣本平均做更有效率的估算。","環境狀態","用數學表示為：","由於原本的貪婪動作能保證：","由於我們必須拉動拉桿","由於環境的不確定性，你無法確定是否有其他動作能在最終帶給你比貪婪動作更高的報酬。","由於當","由於這個動作中完全沒有一絲的「探索」行為，所以我們可以為這個方法再添增一點探索行為。","當代理在玩二十一點的時候，代理不能知道下一張牌為何。","當你透過你學習到的知識，進而採取了一個能得到更高期望報酬的動作，這個行為被稱作「利用（exploiting）」。","當回合執行次數趨近於無限大，則採取動作","當學習過程從最初到最終結束，我們稱之為情境（episodes）。","當我們在說要在每一回合最大化預期的總獎勵，那每一回合具體要最大化什麼呢？","當每一輪結束之後，我們會利用這一輪中學習到的知識，重新開始一次學習過程。","的","的。","的動作次數越少（n_t(a)","的動作選擇方法","的大小作為動作選擇的依據，的確是一個很不錯的方法。","的平均報酬比其他動作高非常多，而只是欠缺探索的話。","的式子中是","的情況中，我們表示下個狀態和獲得的獎勵為","的更好的計算方法，應該是每次有新獲得的報酬時，就直接更新平均報酬。","的期望回報，這裡的","的機率。","的機率函數","的機率，同時我們也可以設定","的狀態值函數（state","的總報酬","的總次數","的設定不會有太多幫助。","的過程中在狀態","的過程中無論採取什麼動作，","的遞增式的算法實作架構，其中","的那根拉桿。","的預期回報可以寫作","目前我們對於動作值函數的估計，是採取對觀察到的獲得報酬進行樣本平均。","目前本專案的規劃配合","目前為止我們可慮的所有動作選擇方法，都屬於非關聯性任務（nonassoci","目前為止討論的問題，在穩定的環境中是沒有什麼問題。","目標與獎勵","目錄與說明","真實環境的近似","策略（policy）","簡言之，代理就是要最大化他能收到的總獎勵。","給予的每次報酬的不確定性。","總和也要無限大","總和要收斂","考慮一個策略","而","而其中我們對獎勵的定義方式，應該是與我們想要實現的學習目標盡可能相關聯。","而其中的","而在","而式子中的","而整個乘起來越小。","而是會希望盡可能地關注如何建立能對應任何狀態的動作選擇策略","而狀態轉移的機率也可以表示為：","而當","而贏棋則記為","能給予最大報酬、紅色機台的拉桿","臂拉霸機的問題中，我們唯一能賭的就是去找到有哪根拉桿被拉動時，中獎機率是比較高的。","臂拉霸機的問題也就迎刃而解了。","臂拉霸機的學習問題","自己定義的內在獎勵，但是環境給予的獎勵依舊是從勝負計算而得，代理依舊要最大化環境反饋得獎勵。","與","與新的回報","與朋友的讀書會持續進行","與次數","舉例來說，target","舉例來說，我們可以對","處理非平穩問題","表達了我們在","被定義成一個","要避免這個問題的話，我們傾向於讓代理能察覺到當前環境訊息，然後立刻忘記他","觀察","觀察上面的式子，我們可以觀察到更多有意思的事情。","說明你沒有足夠的信心可以認為動作","貝爾曼方程","貝爾曼方程（bellman","貪婪動作","貪婪動作永遠都是利用我們學習到的當前所有知識。","越大）中，採取到","越小於","越小）則帶根號那一項就會越大。","越接近","較大的","透過探索行為，可能能幫助我們找到更大的總報酬可能。","透過這個方法揭露出來的動作值，會使得我們只能採取一種合理行為，就是採取貪婪動作。","這串數字如果全部相同，則說明你中了大獎，反之就是什麼獎都沒有。","這些進階的處理，我們將會在後續幾章到結束不斷地深入進行探討。","這個公式中我們可以發現，除非報酬顯著高於平均總報酬","這個公式完全如同我們在","這個式子中可以留意，alpha","這個我們稱","這個條件主要是為了限制動作","這個條件主要是要保證","這個靈活性體現在幾個面向：","這兩個條件很像大數法則的條件，因為他就是要確保大數法則能讓","這兩個條件限制了動態","這可能不會導致代理去贏得勝利，而是使得他在棋盤上胡亂移動棋子，以表現出「最大的主控權」。","這就是一個關聯搜索的任務，這個任務的目標首先是要找到報酬與情境之間的關聯性。","這時候我們就會將動作值函數與策略值函數參數化（parameterize），使其參數總數少於狀態總數","這樣子在初期的行為選擇上，動作值函數會更加地鼓勵探索行為，這就是所謂的「樂觀初始值」設置。","這樣子我們只需要每次存放當前的報酬","這樣子我們可以改寫增量式算法實作架構變成：","這樣就可以在每一個回合更聚焦在當前環境，與前幾次環境給予的反饋來做決定。","這樣會隨時間變化的學習問題，我們稱為非平穩（nonstationary）問題。","這種性質也叫做路徑獨立（path","這種方法我們叫做蒙地卡羅法。","這邊我們就要定義報酬（return），也就是未來總獎勵為：","這邊的","這邊要特別提到，如果使用常數的","通常環境都是複雜且不確定，所以在前期鼓勵探索是很重要的事情，因此通常我們會給予一個較大的","進階問題","遞增式的算法實作","遞增式算法實作","選擇偏好把動作選擇用機率表示，透過或波茲曼分布（boltzmann","選擇偏好與梯度演算法","那","那我們怎麼區分代理人與環境呢？","那每一次都選擇最高的期望報酬的話，就是所謂的貪婪（greedy）動作。","那麼要如何確保他的收斂性呢？他必須符合兩個條件式：","那麼選擇該動作的機率可以表示為：","閱讀的書籍是〈reinforc","關於公式的由來，可以閱讀書籍中的","關於起頭的綜述與結尾的","關於非平穩問題","關於非平穩環境","關聯搜索","除此之外，目前考慮的動作只會對當前報酬產生影響，但如果行為會對後續回合的報酬產生影響，那問題也會更為複雜。","隨機梯度上升","頁的證明，在此不再多做贅述。","顯得較不重要。","顯然在一連串的學習過程中，狀態值和動作值函數可以從經驗中進行估計","顯然在非平穩環境中，q_1","顯然當狀態非常多的時候，每個狀態得到的獎勵都十分稀疏，用平均來計算就顯得不太合適。","首先我們先認識到，由於代理與環境之間是互相反饋，所以彼此互相的影響是以離散時間表達，也就是說：","馬可夫性質","馬可夫決策過程","，則前述的條件二會不符合","，同時也只需要很小的計算量。","，我們在此以","，會在","，為什麼有這個想法呢？","，而是讓代理不斷累積總報酬，這種學習任務稱作持續性任務（continu","，這個是最簡易的情況。","，這能保證我們收斂到動作值的真實數值。","，這鼓勵他必須給快脫離環境。","，那麼只要在每個動作上採取一次行為，greedi"],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"目錄與說明","keywords":"","body":"目錄與說明\n目前本專案的規劃配合 @fatfingererr 與朋友的讀書會持續進行\n如果您對本專案有興趣或疑問，歡迎提 Issue 告知和指教\n閱讀的書籍是〈Reinforcement Learning: An Introduction〉\n在此僅針對該書中的 Part1 與 Part2 特別紀錄筆記\n關於起頭的綜述與結尾的 Case Studies 有興趣者請自行閱讀\n"},"2-1-多臂拉霸機的學習問題.html":{"url":"2-1-多臂拉霸機的學習問題.html","title":"2-1 多臂拉霸機的學習問題","keywords":"","body":"多臂拉霸機\n在這一章，我們將會從最基本的學習問題開始討論，最後連結到 增強學習。\nK 臂拉霸機的學習問題\n假設你面前擺著有 K 個拉桿的拉霸機，每當你拉下其中一個拉桿的時候，拉霸機就會給你一串數字。\n這串數字如果全部相同，則說明你中了大獎，反之就是什麼獎都沒有。\n你現在有 1000 次練習的機會，在 1000 次練習之後將迎來正式的賭博機會。\n你如何在這 1000 次盡己所能，在看似隨機的問題上面做最充分的準備？\n期望報酬\n在 K 臂拉霸機的問題中，我們唯一能賭的就是去找到有哪根拉桿被拉動時，中獎機率是比較高的。\n因此，我們會先假設每個拉桿會給予我們個別的【期望報酬】，用 Q 來表示。\n假設拉桿 a 容易中獎，代表拉動拉桿 a 會為我們帶來較高的期望報酬。\n由於我們必須拉動拉桿 a 才會發現這件事情，所以我們的期望報酬可以表達成：\nQ(a) = E(R|A=a)\n假如我們能知道每個拉桿的期望報酬，對於 K 臂拉霸機的問題也就迎刃而解了。\n因為你始終可以拉動有 最高期望報酬 的那根拉桿。\n貪婪動作 greedy actions\n在動態的練習過程中，每一回合勢必都會有個動作，會對應到最高的期望報酬。\n那每一次都選擇最高的期望報酬的話，就是所謂的貪婪（Greedy）動作。\n當你透過你學習到的知識，進而採取了一個能得到更高期望報酬的動作，這個行為被稱作「利用（exploiting）」。\n因為你正在利用你學習到的知識，進而採取一個能得到最直接與你有利的結果。\n利用與探索 exploiting & exploring\n假如你不採取一個能得到更高期望報酬的動作，而採取任何一個其他動作，都屬於非貪婪（nongreedy）動作。\n此時就是說明你正在探索更多可能，這個行為也被稱作「探索（exploring）」。\n「利用」行為能最大化你的預期報酬，使你盡可能地提高你每個行為給予的回饋。\n然而「探索」行為可能會帶給你更大的總報酬，從長遠來說也可能是更值得嘗試的動作。\n不確定性\n由於環境的不確定性，你無法確定是否有其他動作能在最終帶給你比貪婪動作更高的報酬。\n此時如果你有很多時間可以不斷嘗試的話，你就可以對於要採取貪婪或非貪婪有更多的信心。\n因為你可以使用部分時間進行「探索」，並在最後的時間發現一個更高的總報酬。\n換個角度來說，你也可能因為探索而做白工，因為你每次只能選擇一個動作，做錯一步都是浪費。\n在「利用」與「探索」之間，這兩者是有著根本性的矛盾問題，你無法充分同好這兩件事。\n探索與利用之間的平衡\n既然無法充分做好這兩件事，我們可以試著在這兩者之間進行一個權衡。\n後續將會開始介紹許多數學方法，來幫助我們決定如何採取更合適的行為，以達到更好的學習成果。\n"},"2-2-動作值方法.html":{"url":"2-2-動作值方法.html","title":"2-2 動作值方法","keywords":"","body":"動作值方法\n我們接著會來嘗試評估採取一個動作的價值，正如前面所提到，動作的正確評估來自於採取該動作之後獲取的平均報酬。\n一個簡單的平均報酬計算方法，就是透過每一次採取該動作之後的總報酬，除以採取該動作的總次數。\nQ_t(a) = t 時點前採取動作 a 的總報酬 / t 時點前的採取動作 a 的總次數\n上式中的 Q_t(a) 函數則為每個動作 a 對應的價值函數，簡稱動作值函數。\n同時這個方法也被稱作 樣本平均法 (sample-average) 是一種動作值函數的估計。\n透過這個方法揭露出來的動作值，會使得我們只能採取一種合理行為，就是採取貪婪動作。\n也就是說，我們在 t 時點採取的動作 A_t 會符合：\nQ_t(A_t)=max_a(Q_t(a))\n也可以寫作：\nA_t=argmax_a(Q_t(a))\nepsilon-greedy\n貪婪動作永遠都是利用我們學習到的當前所有知識。\n由於這個動作中完全沒有一絲的「探索」行為，所以我們可以為這個方法再添增一點探索行為。\n透過探索行為，可能能幫助我們找到更大的總報酬可能。\n也就是說，我們可以假定一個很小的機率 epsilon 使得行為有機會隨機選擇非貪婪的其他動作。\n由於原本的貪婪動作能保證：\nQ_t(a) -> q*(a) when t->inf\n所以我們能選到最佳動作的機率是大於 1-epsilon 的。\nTBD: average reward 圖\nTBD: optimal action 圖\n什麼時候應該使用 epsilon-greedy 呢？\n很簡單一個想法就是，如果存在一個動作 k 的平均報酬比其他動作高非常多，而只是欠缺探索的話。\n那 epsilon-greedy 就會比 greedy 來得適合。\n反之，如果採取不同動作的報酬變異數接近 0 ，那麼只要在每個動作上採取一次行為，greedy method 就能知道所有動作的真實價值。\nnonstationary\n然而真實世界中，我們採取的每個動作其中的真實價值往往會隨時間而改變。\n所以這才是我們需要一個更進階且完備的數學理論去處理他，因為我們必須時時刻刻去平衡探索與利用之間的問題。\n"},"2-3-遞增式的算法實作.html":{"url":"2-3-遞增式的算法實作.html","title":"2-3 遞增式算法實作","keywords":"","body":"遞增式的算法實作\n目前我們對於動作值函數的估計，是採取對觀察到的獲得報酬進行樣本平均。\n現在我們要來進一步討論，我們如何對樣本平均做更有效率的估算。\n對於某個特定動作 a 我們已經做過了 n-1 次，接著要評估是否適合採取第 n 次動作。\n對於這個第 n 次是否要做，我們可以透過前 n-1 次來計算觀察到的平均報酬：\nQ_n = ( R_1 + R_2 + ... + R_n-1 ) / ( n-1 )\n由於當 n 很大時，我們會需要很多的資源空間存放前 n-1 次的每次報酬才能計算平均報酬。\n所以對於 Q_n 的更好的計算方法，應該是每次有新獲得的報酬時，就直接更新平均報酬。\nQ_n+1 = Q_n + (1/n)[ R_n - Q_n ]\n這樣子我們只需要每次存放當前的報酬 R_n 與次數 n ，同時也只需要很小的計算量。\n我們在此將這種遞增式的算法實作，表達成一個更廣義的通式：\nNewEstimate 觀察上面的式子，我們可以觀察到更多有意思的事情。\n舉例來說，Target - OldEstimate 可以看成是我們在上一回合的估計誤差（error）。\n而其中的 StepSize 在前面 Q_n+1 的式子中是 1/n ，我們在此以 alpha 做表示。\n其中的 n 則在 alpha 中被隱藏了起來。\n"},"2-4-處理非平穩問題.html":{"url":"2-4-處理非平穩問題.html","title":"2-4 處理非平穩問題","keywords":"","body":"處理非平穩問題\n目前為止討論的問題，在穩定的環境中是沒有什麼問題。\n事實上多數問題面對的環境，是會不斷變化，這樣前面討論的內容就會不太適用。\n這樣會隨時間變化的學習問題，我們稱為非平穩（nonstationary）問題。\n很合理的可以發現，會隨時間變化的環境，更重要的是如何把握當前的可能獲得的報酬。\n最常用的方法之一，就是定義 Stepsize 為一個常數。\n這樣子我們可以改寫增量式算法實作架構變成：\nQ_n+1 = Q_n + alpha * [ R_n - Q_n ]\n其中 Stepsize 被定義成一個 alpha 常數，介在 0 到 1 之間。\n也因此 Q_n+1 會變成一個過往獲得報酬的指數加權平均（exponetial weighted average）：\nQ_n+1 = (1-alpha)^n Q_1 + sum(i=1)(n){ alpha * (1-alpha)^(n-i) R_i }\n這個式子中可以留意，alpha * (1-alpha)^(n-i) 會隨著 i 越小於 n 而整個乘起來越小。\n也就是說越久以前所獲得的報酬，對於當前採取的動作能參考的價值越小。\n這樣就可以在每一個回合更聚焦在當前環境，與前幾次環境給予的反饋來做決定。\n動態 Stepsize\n有時候我們可以在每一回合動態調整我們的 Stepsize ，為什麼有這個想法呢？\n因為原本我們使用的 Stepsize 是 1/n ，這能保證我們收斂到動作值的真實數值。\n也就是說，當 Stepsize=1/n 時我們的動作值函數能正確的逼近每個動作的期望報酬。\n因此假如我們令 alpha_n(a) 代表在第 n 次採取動作 a 的 Stepsize\n那麼要如何確保他的收斂性呢？他必須符合兩個條件式：\nsum(n=1)(inf) alpha_n(a) = inf\nand\nsum(n=1)(inf) [alpha_n(a)]^2 這兩個條件限制了動態 Stepsize 意思是：\n\n當回合執行次數趨近於無限大，則採取動作 a 的 Stepsize 總和也要無限大\n\n這個條件主要是為了限制動作 a 的 Stepsize 不會受制於初始的 Stepsize\n\n當回合執行次數趨近於無限大，則採取動作 a 的 Stepsize 總和要收斂\n\n這個條件主要是要保證 Q_n 最後會收斂到 q* 也就是說每個動作的期望報酬都是存在。\n這兩個條件很像大數法則的條件，因為他就是要確保大數法則能讓 Q_n -> q*\n常數 Stepsize\n這邊要特別提到，如果使用常數的 Stepsize ，則前述的條件二會不符合\n也就是說，當你用常數的 Stepsize 來面對非平穩問題時\n你某種程度就放棄認為你採取的每個動作都會有一個對應的期望報酬\n也就是你相信應該根據環境的變化，採取對應的動作，不會有哪個動作值得一直執行\n"},"2-5-樂觀初始值的設置.html":{"url":"2-5-樂觀初始值的設置.html","title":"2-5 樂觀初始值的設置","keywords":"","body":"樂觀初始值的設置\n在前一節我們談到了動作值 Q_n+1 可以表示成：\nQ_n+1 = (1-alpha)^n Q_1 + sum(i=1)(n){ alpha * (1-alpha)^(n-i) R_i }\n無論 alpha 是常數還是變數，我們都可以從上式發現一件事。\nQ_n+1 很大程度取決於初始動作值的估計，也就是 Q_1 。\n而在 Q_1 之前，你並未採取任何動作，也就是說 Q_1 是一個需要先驗給定的。\n實際問題中，這種偏誤（Bias）不一定不好，有時候也是非常有幫助，如果你對環境能先做些有用的假設。\n又或者反過來說，你也可以對環境不做任何假設，使得給值 Q_1 是鼓勵探索行為的。\n通常環境都是複雜且不確定，所以在前期鼓勵探索是很重要的事情，因此通常我們會給予一個較大的 Q_1 。\n較大的 Q_1 會使得學習剛開始的過程中，前期的 Q_n 在下一回合的 Q_n+1 顯得較不重要。\n換句話說，剛開始的每一回合的學習得到的反饋，都會使你「失望」。\n因為你抱持一個「樂觀」態度開始，對學習有較高的期待。\n這樣子在初期的行為選擇上，動作值函數會更加地鼓勵探索行為，這就是所謂的「樂觀初始值」設置。\n並且在盡可能多的動作上面進行探索，使得最後就算開始不斷的做貪婪動作，也有足夠的探索。\n關於非平穩環境\n顯然在非平穩環境中，Q_1 的設定不會有太多幫助。\n也就是說樂觀初始值的設置方法，並非是一個很有用的一般性提升探索行為的技巧。\n但是理解這些觀念是很重要的，許多人會在使用複雜高端的模型後忘記這些基本觀念。\n"},"2-6-UCB-信賴區間上緣.html":{"url":"2-6-UCB-信賴區間上緣.html","title":"2-6 信賴區間上緣(UCB)","keywords":"","body":"信賴區間上緣 (UCB)\n我們已經知道貪婪行為是目前看起來最好的決策選擇方式，我們也知道不能一直貪婪。\n所以我們很清楚可能 epsilon-greedy 會更好一點，但是強迫一個隨機機率採取非貪婪的行為，似乎也不太有道理。\n所以一種更好的方法，就是對於非貪婪的其他選擇，做一點挑選或處理。\n舉例來說，我們可以對 Q_t(a) 做一點加成，作為每次行為選擇的參考。\nA_t = argmax_a(Q_t(a)+c*\\sqrt(log_t / N_t(a)))\n上式的操作就是所謂的 信賴區間上緣 (Upper Confidence Bound, UCB)  的動作選擇方法\n根號後面那一項，衡量的是採取動作 a 給予的每次報酬的不確定性。\n如果在越長的時間（log_t 越大）中，採取到 a 的動作次數越少（N_t(a) 越小）則帶根號那一項就會越大。\n說明你沒有足夠的信心可以認為動作 a 是不值得採取的，因此我們對他的原始 Q_t(a) 值做一個加權再來做動作選擇。\n而式子中的 c > 0 是一個探索度（degree of exploration）係數，而整項的公式則叫做信賴區間上緣。\n關於非平穩問題\n同樣的，這邊我們可以發現這一項對於非平穩問題仍舊不會有太有幫助。\n因為在非平穩問題中，每一次採取相同的動作而得到的報酬，並不能等同而論。\n所以可能有一個動作在很長時間沒有被選取，但單純只是因為當時的環境不適合採取該動作。\n並不能用此來代表，你就很有信心這個動作是不值得被採取的（因為 log_t / N_t(a) 會很小，而 Q_t(a) 可能也很小）\n"},"2-7-選擇偏好與梯度演算法.html":{"url":"2-7-選擇偏好與梯度演算法.html","title":"2-7 選擇偏好與梯度演算法","keywords":"","body":"選擇偏好與梯度演算法\n根據 Q_t(a) 的大小作為動作選擇的依據，的確是一個很不錯的方法。\n但是我們如何衡量每個動作相對之間的關係呢？如何衡量我們更想選貪婪選擇呢？\n因此我們要引入一個觀念，也就是選擇偏好（preference）H_t(a) \n選擇偏好把動作選擇用機率表示，透過或波茲曼分布（Boltzmann distribution）表示成：\npi_t(a) = P_r(A_t = a) = e^(H_t(a))/(sum(b=1)(k){e^(H_t(b))})\n這邊的 pi_t(a) 表達了我們在 t 時點選擇動作 a 的機率，同時我們也可以設定 H_1(a)=0 使得所有動作的初始選擇偏好相同。\n隨機梯度上升 (stochastic gradient ascent, SGA)\n在每一回合我們得到新的行為 A_t 與新的回報 R_t 我們有一個方法來更新我們的偏好 H_t(A_t)\nH_t+1(A_t) = H_t(A_t) + alpha ( R_t - avg_R_t)( 1 - pi_t(A_t))\nH_t+1(a) = H_t(a) - alpha(R_t - avg_R_t)*pi_t(a)\n這個公式完全如同我們在 2-3 的遞增式的算法實作架構，其中 alpha 是 Step-size 參數\n而 avg_R_t 為整體所有動作在時點 t 之前的總報酬平均。\n這個公式中我們可以發現，除非報酬顯著高於平均總報酬 avg_R_t 否則偏好不會提升。\n關於公式的由來，可以閱讀書籍中的 39 到 41 頁的證明，在此不再多做贅述。\n"},"2-8-關聯搜索.html":{"url":"2-8-關聯搜索.html","title":"2-8 關聯搜索","keywords":"","body":"關聯搜索\n目前為止我們可慮的所有動作選擇方法，都屬於非關聯性任務（nonassociative tasks）的範疇。\n也就是說，我們都沒有考慮的動作與環境之間可能有所關聯，並且面對特定環境可能存在特定動作能獲得最大報酬。\n然而隨著時間變化，真實世界中的環境往往會隨著你的動作而有所更新，也就是說環境中的情境可能不只一種。\n在一般的增強學習任務之中，我們面對的就是多元變化的情境，因此我們的真正目標是去學習一種 策略（policy）\n也就是說我們要做的是去學習如何在特定情境中，做出符合該情境的最佳動作。\n多台多臂拉霸機\n假設我們面對 N 台的多臂拉霸機，你每一次必須在不同的拉霸機前做選擇，並且選擇之後要再選擇拉桿。\n對你來說，每一回合所採取的動作，和你獲得的報酬之間的關係變得更為複雜。\n但是如果我們假設，你可以獲得到這 N 台的多臂拉霸機和採取的拉桿編號之間的關係。\n例如藍色機台的拉桿 2 能給予最大報酬、紅色機台的拉桿 3 始終給予零報酬，假如你能觀察到這些線索。\n你就可以學習到一個策略，在選擇到藍色機台時選擇拉桿 2，而選擇到紅色機台時不要選擇拉桿 3 。\n進階問題\n這就是一個關聯搜索的任務，這個任務的目標首先是要找到報酬與情境之間的關聯性。\n因此我們就更往前一步，從平穩問題到非平穩問題，從非關聯性的處理到關聯搜索。\n除此之外，目前考慮的動作只會對當前報酬產生影響，但如果行為會對後續回合的報酬產生影響，那問題也會更為複雜。\n這些進階的處理，我們將會在後續幾章到結束不斷地深入進行探討。\n"},"3-1-代理與環境的界限.html":{"url":"3-1-代理與環境的界限.html","title":"3-1 代理與環境的界限","keywords":"","body":"代理與環境的界限\n在增強學習理論中，學習與動作決策者被稱作代理（Agent）而與代理互動的其他的事物，都被稱作環境（environment）代理選擇的動作會影響環境，而環境會給予代理獎勵，代理嘗試最大化獲得的獎勵則稱為學習（learning），因此如何完整規範環境，並且定義一個學習任務，增強學習就必須先給予一個基礎框架。\n代理與環境介面\n首先我們先認識到，由於代理與環境之間是互相反饋，所以彼此互相的影響是以離散時間表達，也就是說：\n在每次離散時間 t=0,1,2,3... 代理接收到一些環境資訊，用狀態（State）表示為 S_t \\in S 其中 S 為所有代理能接收到的環境資訊集合，並且在此基礎上選擇一個動作 A_t \\in A(S_t) 並在動作執行後的時間，接收動作產生的獎勵，稱做 R_t+1 \\in R \\in \\real 並且接收到新一回合的環境資訊 S_t+1 底下是代理環境介面的示意圖：\nTBD: 代理環境交互示意圖\n定義：策略 Policy\n每個回合中，代理從狀態到動作的選擇過程，可以用一個機率表示，被稱為策略（Policy）並寫成 PI_t 。\n其中 PI_t(a|s) 指的是在時點 t 時接收到的環境狀態 s ，會在 t+1 時點採取動作 a 的機率。\n代理可以透過自己學習到的經驗改變其策略，基本的學習目標就是在長期能獲得最大的總獎勵。\n介面的靈活性\n前述的基礎定義給予我們一個增強學習框架，這個框架是非常靈活且抽象的，可以用不同的方式應用到不同的問題裡面。\n這個靈活性體現在幾個面向：\n\n時間間隔的自由度：沒有要求離散時間時點之間的相隔\n\n動作選擇的抽象程度：代理可以根據基礎的條件動作，也可以根據定義的高級抽象狀態條件採取行為\n\n反饋不一定要有外顯影響：當環境給予代理反饋時，代理可以是內在性的調整（例如修正選擇機率）\n\n狀態可以是任何有用的資訊：狀態由於是從環境得到的資訊，因此可以細粒度的去規範獲得的狀態內容\n\n\n代理與環境的界限\n代理與環境之間的界限，並不是以代理和環境本身的物理邊界做區隔。\n你也可以注意到，我們是用「代理」這個詞，意思就是它可以是不屬於代理個體本身的其他元件。\n例如一個機器人除了他本身，也可以接收到配置在環境中的傳感器蒐集的資訊，顯然外部的傳感器不屬於機器人個體。\n那我們怎麼區分代理人與環境呢？\n最基本的界線判斷就是，代理人無法依照自己想要的規則改變的事物，就屬於其外部。\n獎勵的外部性\n在模擬的環境中，獎勵的計算方法可以透過一些系統性的定義來做計算，但是他仍舊屬於環境範疇。\n因為獎勵的高低變化的規則與邏輯，不能被代理任意的改變與調整，這才能定義成代理需要學習的任務。\n代理很有可能能理解環境如何給予他獎勵，但仍舊無法最大化他的獎勵。\n【這很重要，例如代理可以知道環境給予的獎勵的隨機程度，卻無法最大化他的獎勵。】\n狀態、動作與獎勵，定義了界限\n在實際應用中，我們往往是透過定義狀態、動作與獎勵之後，就確定了代理與環境之間的界限，因此就確定了一個決策任務（decision-making task），這個任務可以被簡化到極致，變成三個子任務：\n\n代理如何理解環境（狀態）\n\n代理可以採取什麼行為（動作）\n\n代理如何知道學習目標（獎勵）\n\n\n"},"3-2-目標與獎勵.html":{"url":"3-2-目標與獎勵.html","title":"3-2 目標與獎勵","keywords":"","body":"目標與獎勵\n代理的目標是去掌握環境給予獎勵的規則，在每個學習回合中，獎勵是一個數字 R_t in \\real 。\n簡言之，代理就是要最大化他能收到的總獎勵。\n根據我們在前一章探討到的問題，我們可能會犧牲短期可能獲得的獎勵，來換取長期可以累積更高的總獎勵的機會。\n因此我們在增強學習中，迎來了第一個假設，也就是獎勵獎設（reward hypothesis）：\n\n代理的目標就是要最大化本身的期望獎勵，進而能使其本身累積到最高的總獎勵\n\n定義獎勵的靈活性\n如何定義環境給予的獎勵，在增強學習中給予很大的操作空間，這也是增強學習理論的特徵之一。\n我們可以舉機器人走迷宮的例子，如果機器人要走出迷宮，我們可以定義每一步獎勵都要 -1 ，這鼓勵他必須給快脫離環境。\n或是在棋盤遊戲中，如果輸掉一盤棋獎勵記為 -1 而贏棋則記為 +1 。\n區分學習目的與方法\n在定義獎勵的時候，務必留意我們是要讓代理學習如何實現學習目標，而不是僅僅為了獲得最高獎勵。\n而其中我們對獎勵的定義方式，應該是與我們想要實現的學習目標盡可能相關聯。\n例如在棋盤遊戲中，獲得在對弈中的主控權是贏得遊戲的重要手段，但遊戲的最終目的是為了勝利。\n假如我們定義獎勵是以對弈中的主控權表示，最大化獎勵就變成最大化自己的主控權。\n這可能不會導致代理去贏得勝利，而是使得他在棋盤上胡亂移動棋子，以表現出「最大的主控權」。\n代理人的內在獎勵\n在前一節我們提到，獎勵應該是屬於代理外部的環境範疇。\n但是這不代表代理人本身不能有一個內在獎勵的計算方式。\n例如前面的棋盤遊戲例子中，我們可以將「對弈的主控權」當作是代理主觀理解環境後，\n自己定義的內在獎勵，但是環境給予的獎勵依舊是從勝負計算而得，代理依舊要最大化環境反饋得獎勵。\n所以如何將你的學習目標，切割成環境反饋的獎勵和代理內在的獎勵，是處理代理與環境界限的重要問題。\n"},"3-3-回報.html":{"url":"3-3-回報.html","title":"3-3 回報","keywords":"","body":"回報\n當我們在說要在每一回合最大化預期的總獎勵，那每一回合具體要最大化什麼呢？\n這邊我們就要定義報酬（Return），也就是未來總獎勵為：\nG_t = R_t+1 + R_t+2 + R_t+3 + ... R_T\n其中 T 是最終的總獎勵，而 G_t 就是未來所有時點獲得的獎勵總和。\n當學習過程從最初到最終結束，我們稱之為情境（Episodes）。\n當每一輪結束之後，我們會利用這一輪中學習到的知識，重新開始一次學習過程。\n像這樣有一個最終時點 T 且一旦學習過程抵達後就停止的，我們則稱作情境性任務（episodic tasks）\n每一輪的結果彼此都是無關，只有累積下來的策略會被保存到下一輪繼續使用。\n持續性任務\n有時候我們定義的代理環境框架中，可以不設定一個最終時點 T ，而是讓代理不斷累積總報酬，這種學習任務稱作持續性任務（continuing tasks）\n然而這樣子總報酬可能會趨近於正負無限大，我們希望最大總獎勵就算在持續任務中，應該也要能收斂到一個數值。\n因此這邊我們會引入一個概念，叫做折扣（discount）也就是說，對於持續性任務而言，我們是要最大化我們的折扣回報（discount return）\n用數學表示為：\nG_t = R_t+1 + gamma * R_t+2 + gamma^2 + R_t+3 ... = \\sum_{k=0}^{inf} gamma^k * R_t+k+1\n而 gamma 就是所謂的折扣率（discount rate），他決定了未來各時點的回報對於現在時點的價值。\n觀察 0 會讓上式存在一個固定的數值，而 gamma=0 則會讓代理只關注下期回報，忽略未來的所有可能回報。\n而當 gamma 越接近 1 時，代理越會把未來的回報看得和下一期回報一樣重要，更重視未來的可能獎勵。\n"},"3-4-馬可夫性質.html":{"url":"3-4-馬可夫性質.html","title":"3-4 馬可夫性質","keywords":"","body":"馬可夫性質\n在代理—環境的增強學習框架中，代理會根據環境的狀態來選擇動作。\n本節會來討一種特別有意義的狀態，叫做馬可夫性質（Markov property）\n接下來我們並不會討論怎麼從環境中觀察和設計出合理的狀態\n而是會希望盡可能地關注如何建立能對應任何狀態的動作選擇策略\n為了達到這個目的，我們會在本節中對狀態做一些限制與規範\n環境狀態\n當代理在玩二十一點的時候，代理不能知道下一張牌為何。\n也就是說，我們不能說代理處於「下一張牌是紅心Q」的狀態。\n因為代理不能從環境中的狀態，直接推論出下一張牌是什麼。\n所以我們必須先了解，狀態（State）不可以對未來的訊息作保證。\n代理可以從環境去歸納、學習，但我們定義的狀態不能直接保證未來特定情況會發生。\n但是代理可不可以從環境中觀察出「下一張牌是紅心Q」？當然可以。\n換句話說，環境都可能潛藏各種能揭露未來的訊息，但是我們不能將其設計為一種狀態\n要避免這個問題的話，我們傾向於讓代理能察覺到當前環境訊息，然後立刻忘記他\n所以我們理想的狀態設計原則，應該是他能總結過去觀察到的環境訊息，\n但不能超過過去所有訊息的歷史紀錄，這就是所謂的馬可夫性質（Markov property）\n例如說棋盤遊戲中，我們考慮把棋盤上當前排列組合當作狀態。\n棋盤上當前的排列組合，總結了過去每一回合的彼此下棋的結果。\n同時棋盤上當前的排列組合，沒有對未來可能發生的特定情況做出任何保證。\n又或是飛彈發射後的當前座標與速度，總結了過去從發射到現在的飛彈飛行情況。\n同時飛彈當前的座標與速度，也沒有保證未來飛彈可能落於任何地方的保證。\n這種性質也叫做路徑獨立（path independent）。\n馬可夫性質\n接下來我們會說明增強學習中的馬可夫性質如何表示\n為了數學表示上的方便，在此我們先考慮環境有限的狀態和獎勵\n假如現在在 t 時點，我們可以選擇動作 s 並且得到獎勵 r \n那麼選擇該動作的機率可以表示為：\nP(S_t+1=s', R_t+1=r | S_0, A_0, R_1, ... , S_t-1, A_t-1, R_t, S_t, A_t )\n如果我們說狀態具有馬可夫性質的話，那上式可以寫成\nP(s',r|s,a)=P(S_t+1 = s', R_t+1 = r | S_t = s, A_t = a )\n如果一個環境狀態是具有馬可夫性質的，意思就是說\n我們能根據當前的環境狀態和行動來選擇動作，並預期我們下一個狀態和獎勵為何。\n真實環境的近似\n想當然爾，真實環境中的狀態和動作之間的關係，不可能完全只取決於前一回合的動作與狀態。\n因此馬可夫性質只是一種逼近、近似的方法，也不是增強學習唯一的近似方法\n依據馬可夫性質為基礎所設計的各種增強學習演算法，也就可以在一定程度去使用\n為了使得近似能更精確，所以我們必須充分的提供環境中的可能的狀態訊息，\n此外，先掌握馬可夫性質與相關演算法之後，是往非馬可夫性質的增強學習建模的基礎\n"},"3-5-馬可夫決策過程.html":{"url":"3-5-馬可夫決策過程.html","title":"3-5 馬可夫決策過程","keywords":"","body":"馬可夫決策過程\n如果我們說增強學習任務是滿足馬可夫性質的話，這個學習任務就被叫做馬可夫決策過程（Markov decision process, MDP）\n假如狀態和能採取的動作是離散有限的，也被稱作有限馬可夫決策過程（finite MDP）\n有限馬可夫過程對於增強學習理論來說十分的重要\n他幾乎是 90% 現代增強學習理論的基礎\n在給定的狀態 s 採取動作 a 的情況中，我們表示下個狀態和獲得的獎勵為\nP(s',r|s,a) = P( ) 前一章打過\n其中我們稱 (s,a) 為狀態動作對（state-action pairs）\n此外，以狀態動作對來重新描述預期獎勵（expected reward）為\nr(s,a)=E(R_t+1|S_t=s, A_t=a)\n而狀態轉移的機率也可以表示為：\np(s'|s,a)=P(S_t+1=s'|S_t=s,A_t=a)\n因此我們再一次地透過「狀態－動作－下次狀態」元組（state-action-next-state triples）重寫我們的預期獎勵，並且將預期獎勵的條件期望值展開為：\nr(s,a,s')=E(R_t+1|S_t=s,A_t=a,S_t+1=s')=\n"},"3-6-動作值函數.html":{"url":"3-6-動作值函數.html","title":"3-6 動作值函數","keywords":"","body":"動作值函數\n正如我們在 2-2 中提到的動作值方法，我們關心的是採取每個動作帶給我們的價值為何\n我們已經知道這個價值可以用預期獎勵來表示，現在我們要為每一個策略定義動作值函數\n考慮一個策略 PI 是從狀態 s 和動作 a\\inA(s) 的機率函數\nPI(a|s)\n在 MDP 中，我們會定義 V_PI(s) 為\nv_pi(s) = E_pi(G_t|S_t=s)\n其中 E_pi 代表代理在狀態 s 時，遵守策略 pi 的期望回報，這裡的 v_pi 是策略 PI 的狀態值函數（state-value function for policy pi）\n同樣的道理，假設在這個狀態 s 下根據策略 pi 採取動作 a 的預期回報可以寫作\nq_pi(s,a)=E_pi(G_t|S_t=s,At=a)\n這個我們稱 q_pi 為動作值函數（action-value function）\n值函數的估計\n顯然在一連串的學習過程中，狀態值和動作值函數可以從經驗中進行估計\n對於狀態值函數的估計，可以看成是遵守策略 pi 的過程中無論採取什麼動作，\n在狀態 s 下獲得的獎勵平均值會收斂到 v_pi(s) ，這個是最簡易的情況。\n然而如果一個固定的狀態下，v_pi(s) 不會收斂，可能代表不同的動作個別有各自的動作值函數。\n也就是說，在遵守策略 pi 的過程中在狀態 s 下不同的動作 a 會收斂到動作值函數 q_pi(s,a)\n這種方法我們叫做蒙地卡羅法。\n顯然當狀態非常多的時候，每個狀態得到的獎勵都十分稀疏，用平均來計算就顯得不太合適。\n這時候我們就會將動作值函數與策略值函數參數化（parameterize），使其參數總數少於狀態總數\n然後調整參數來產生正確的估計，這很大程度取決於我們參數化的方式\n貝爾曼方程\n貝爾曼方程（Bellman equation）\n"}}}