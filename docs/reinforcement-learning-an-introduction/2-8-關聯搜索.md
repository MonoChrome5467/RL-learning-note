# 關聯搜索

目前為止我們可慮的所有動作選擇方法，都屬於非關聯性任務（nonassociative tasks）的範疇。

也就是說，我們都沒有考慮的動作與環境之間可能有所關聯，並且面對特定環境可能存在特定動作能獲得最大報酬。

然而隨著時間變化，真實世界中的環境往往會隨著你的動作而有所更新，也就是說環境中的情境可能不只一種。

在一般的增強學習任務之中，我們面對的就是多元變化的情境，因此我們的真正目標是去學習一種 **策略（policy）**

也就是說我們要做的是去學習如何在特定情境中，做出符合該情境的最佳動作。

## 多台多臂拉霸機

假設我們面對 N 台的多臂拉霸機，你每一次必須在不同的拉霸機前做選擇，並且選擇之後要再選擇拉桿。

對你來說，每一回合所採取的動作，和你獲得的報酬之間的關係變得更為複雜。

但是如果我們假設，你可以獲得到這 N 台的多臂拉霸機和採取的拉桿編號之間的關係。

例如藍色機台的拉桿 2 能給予最大報酬、紅色機台的拉桿 3 始終給予零報酬，假如你能觀察到這些線索。

你就可以學習到一個策略，在選擇到藍色機台時選擇拉桿 2，而選擇到紅色機台時不要選擇拉桿 3 。

## 進階問題

這就是一個關聯搜索的任務，這個任務的目標首先是要找到報酬與情境之間的關聯性。

因此我們就更往前一步，從平穩問題到非平穩問題，從非關聯性的處理到關聯搜索。

除此之外，目前考慮的動作只會對當前報酬產生影響，但如果行為會對後續回合的報酬產生影響，那問題也會更為複雜。

這些進階的處理，我們將會在後續幾章到結束不斷地深入進行探討。