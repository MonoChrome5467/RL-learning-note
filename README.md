# Reinforcement Learning (RL) 學習筆記

透過學習列表 [aikorea/awesome-rl](https://github.com/aikorea/awesome-rl) 的資源，本專案將學習心得撰寫成簡要的筆記做分享。

## Notice

目前本專案的規劃配合 @fatfingererr 與朋友的讀書會持續進行

如果您對本專案有興趣或疑問，歡迎提 Issue 告知和指教

## 〈[Reinforcement Learning: An Introduction](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262193981)〉閱讀筆記

在此僅針對該書中的 Part1 與 Part2 特別紀錄筆記

關於起頭的綜述與結尾的 Case Studies 有興趣者請自行閱讀

| PART 1 : Tabular Solution Methods          | 　　　　　　 學 習 筆 記 　　　　　　　|
|--------------------------------------------|----------------------------------------|
| Multi-arm Bandits                          | [2.1 多臂拉霸機的學習問題](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-1-多臂拉霸機的學習問題.md)    |
|                                            | [2.2 動作值方法](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-2-動作值方法.md)    |
|                                            | [2.3 遞增式的算法實作](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-3-遞增式的算法實作.md)    |
|                                            | [2.4 處理非平穩問題](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-4-處理非平穩問題.md)    |
|                                            | [2.5 樂觀初始值的設置](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-5-樂觀初始值的設置.md)    |
|                                            | [2.6 信賴區間上緣 (UCB)](https://github.com/sukki/RL-learning-note/blob/master/Reinforcement%20Learning%20An%20Introduction/2-6-UCB-信賴區間上緣.md)    |
| Finite Markov Decision Processes           |                                  |
| Dynamic Programming                        |                                  |
| Monte Carlo Methods                        |                                  |
| Temporal-Difference Learning               |                                  |
| Multi-step Bootstrapping                   |                                  |
| Planning and Learning with Tabular Methods |                                  |

| PART 2 : Approximate Solution Methods      |                                  |
|--------------------------------------------|----------------------------------|
| On-policy Prediction with Approximation    |                                  |
| On-policy Control with Approximation       |                                  |
| Off-policy Methods with Approximation      |                                  |
| Eligibility Traces                         |                                  |
| Policy Gradient Methods                    |                                  |

## 其他筆記

深入了解馬可夫決策問題，是通往分層增強學習的關鍵。

| 〈馬可夫決策問題〉系列       |  　　　　　　　　　　　　　　　　|
|------------------------------|----------------------------------|
| 離散行為空間問題             |                                  |
| 表格型增強學習               |                                  |
| CMAC 直接梯度方法            |                                  |
| 殘差梯度方法    　　　　　　 |                                  |
| RGNP 非平穩策略殘差梯度方法  |                                  |
| 連續行為空間問題             |                                  |
| AHC 方法                     |                                  |
| Fast-AHC 方法                |                                  |
| 混合增強學習                 |                                  |
| 啟發式演算法                 |                                  |
| HERG 混合方法                |                                  |

透過矩陣的一些根本性質，幫助我們處理跨領域資料學習問題。

| 〈從增強學習到遷移學習〉系列 | 　　　　　　　　　　　　　　　　 |
|------------------------------|----------------------------------|
| 譜理論與譜分割               |                                  |
| 譜理論流形學習               |                                  |
| 譜理論度量學習　　　　　　　 |                                  |
| 拉普拉斯特徵映射方法         |                                  |
| 譜理論遷移學習               |                                  |




